{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# BankChurn Predictor â€” Demo\n",
        "Quick run: train small sample, predict, and show simple feature importance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from src.bankchurn.config import BankChurnConfig\n",
        "from src.bankchurn.training import ChurnTrainer\n",
        "from src.bankchurn.prediction import ChurnPredictor\n",
        "\n",
        "print('Imports ready')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load data (expects data/raw/Churn.csv)\n",
        "csv_path = Path('data/raw/Churn.csv')\n",
        "if not csv_path.exists():\n",
        "    # create small synthetic sample if not present\n",
        "    n=500\n",
        "    df = pd.DataFrame({\n",
        "        'RowNumber': range(1,n+1),\n",
        "        'CustomerId': range(10000,10000+n),\n",
        "        'Surname': [f'Customer_{i}' for i in range(n)],\n",
        "        'CreditScore': np.random.randint(350,851,n),\n",
        "        'Geography': np.random.choice(['France','Spain','Germany'], n),\n",
        "        'Gender': np.random.choice(['Male','Female'], n),\n",
        "        'Age': np.random.randint(18,93,n),\n",
        "        'Tenure': np.random.randint(0,11,n),\n",
        "        'Balance': np.random.uniform(0,250000,n),\n",
        "        'NumOfProducts': np.random.randint(1,5,n),\n",
        "        'HasCrCard': np.random.choice([0,1], n),\n",
        "        'IsActiveMember': np.random.choice([0,1], n),\n",
        "        'EstimatedSalary': np.random.uniform(11,200000,n),\n",
        "        'Exited': np.random.choice([0,1], n, p=[0.8,0.2])\n",
        "    })\n",
        "else:\n",
        "    df = pd.read_csv(csv_path)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Initialize Trainer with Config\n",
        "config = BankChurnConfig.from_yaml('configs/config.yaml')\n",
        "# Disable MLflow for demo to avoid clutter\n",
        "config.mlflow.enabled = False \n",
        "\n",
        "trainer = ChurnTrainer(config)\n",
        "\n",
        "# Prepare data\n",
        "X, y = trainer.prepare_features(df)\n",
        "\n",
        "# Split manually for demo purposes (though trainer handles CV internally)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train on training set\n",
        "model, metrics = trainer.train(X_train, y_train, use_cv=False)\n",
        "print(\"Training Metrics:\", metrics)\n",
        "\n",
        "# Predict on test set\n",
        "# We use the trained pipeline directly or create a Predictor wrapper\n",
        "predictor = ChurnPredictor(model)\n",
        "preds_df = predictor.predict(X_test)\n",
        "\n",
        "# Calculate demo metric\n",
        "acc = (preds_df[\"prediction\"].values == y_test.values).mean()\n",
        "print(json.dumps({'accuracy_demo': float(acc)}, indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Simple feature importance snapshot\n",
        "# Note: Since we use a VotingClassifier, we don't have a single \"feature_importances_\" array.\n",
        "# We can look at the RandomForest component if we want.\n",
        "\n",
        "try:\n",
        "    # Access the classifier step\n",
        "    pipeline = trainer.model_\n",
        "    # Access Random Forest from VotingClassifier\n",
        "    # Structure: Pipeline -> 'classifier' (ResampleClassifier) -> 'estimator_' (VotingClassifier) -> 'estimators_' (list)\n",
        "    \n",
        "    # Note: ResampleClassifier wraps the estimator\n",
        "    if hasattr(pipeline.named_steps['classifier'], 'estimator_'):\n",
        "        voting_clf = pipeline.named_steps['classifier'].estimator_\n",
        "        \n",
        "        # Find RF\n",
        "        rf_model = dict(voting_clf.named_estimators_)['rf']\n",
        "        \n",
        "        # Get feature names\n",
        "        # Preprocessor is first step\n",
        "        preprocessor = pipeline.named_steps['preprocessor']\n",
        "        # This is complex with ColumnTransformer, let's just use a simple proxy or try to get names if possible\n",
        "        # For demo simplicity, we'll plot the RF importances against indices or try to map them\n",
        "        \n",
        "        importances = rf_model.feature_importances_\n",
        "        indices = np.argsort(importances)[::-1]\n",
        "        \n",
        "        # Plot top 10\n",
        "        plt.figure(figsize=(10,6))\n",
        "        plt.title(\"Feature Importances (Random Forest component)\")\n",
        "        plt.bar(range(10), importances[indices[:10]])\n",
        "        plt.show()\n",
        "        \n",
        "except Exception as e:\n",
        "    print(f\"Could not extract feature importances directly: {e}\")\n",
        "    # Fallback to variance proxy\n",
        "    imp = X.select_dtypes(include=np.number).var().sort_values(ascending=False).head(10)\n",
        "    imp.plot(kind='bar', title='Feature importance (proxy)');"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
