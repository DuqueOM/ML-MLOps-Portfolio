# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 12: SERVERLESS VS CONTENEDORES
# CuÃ¡ndo Usar Lambda, ECS o Kubernetes
# GuÃ­a MLOps v5.0: Senior Edition | DuqueOM | Noviembre 2025
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

<div align="center">

# ğŸŒ MÃ“DULO 12: Serverless vs Contenedores

### La DecisiÃ³n que Define tu Arquitectura

*"No hay soluciÃ³n universal. Hay trade-offs que debes entender."*

| DuraciÃ³n             | TeorÃ­a               | PrÃ¡ctica             |
| :------------------: | :------------------: | :------------------: |
| **4-5 horas**        | 40%                  | 60%                  |

</div>

---

## ğŸ¯ ADR: Â¿DÃ³nde Desplegar?

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ADR-008: SelecciÃ³n de Plataforma de Despliegue                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  OPCIONES:                                                                    â•‘
â•‘  1. Serverless (AWS Lambda, GCP Cloud Functions)                              â•‘
â•‘  2. Contenedores Managed (ECS, Cloud Run)                                     â•‘
â•‘  3. Kubernetes (EKS, GKE, self-managed)                                       â•‘
â•‘                                                                               â•‘
â•‘  FACTORES DE DECISIÃ“N:                                                        â•‘
â•‘  â€¢ TrÃ¡fico esperado (requests/mes)                                            â•‘
â•‘  â€¢ Requisitos de latencia                                                     â•‘
â•‘  â€¢ TamaÃ±o del equipo de Ops                                                   â•‘
â•‘  â€¢ Presupuesto                                                                â•‘
â•‘  â€¢ Complejidad del modelo (GPU, memoria)                                      â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 12.1 Matriz de DecisiÃ³n

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    MATRIZ DE DECISIÃ“N DE DESPLIEGUE                           â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   Factor              â”‚ Lambda/Serverless â”‚ ECS/Cloud Run â”‚ Kubernetes        â•‘
â•‘   â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â•‘
â•‘   TrÃ¡fico             â”‚ < 1M req/mes      â”‚ 1M-100M       â”‚ > 100M            â•‘
â•‘   Latencia            â”‚ Variable (cold)   â”‚ Consistente   â”‚ Consistente       â•‘
â•‘   Costo bajo trÃ¡fico  â”‚ ğŸ’° Muy bajo       â”‚ ğŸ’°ğŸ’° Medio    â”‚ ğŸ’°ğŸ’°ğŸ’° Alto      â•‘
â•‘   Costo alto trÃ¡fico  â”‚ ğŸ’°ğŸ’°ğŸ’° Caro       â”‚ ğŸ’°ğŸ’° Medio    â”‚ ğŸ’° Barato        â•‘
â•‘   Complejidad Ops     â”‚ â­ Baja           â”‚ â­â­ Media   â”‚ â­â­â­â­ Alta  â•‘
â•‘   Equipo necesario    â”‚ 1 persona         â”‚ 2-3 personas  â”‚ 5+ personas       â•‘
â•‘   GPU Support         â”‚ âŒ                â”‚ âœ…           â”‚ âœ…               â•‘
â•‘   Max memoria         â”‚ 10GB              â”‚ 120GB+        â”‚ Ilimitado         â•‘
â•‘   Max timeout         â”‚ 15 min            â”‚ Ilimitado     â”‚ Ilimitado         â•‘
â•‘   Modelo size lÃ­mite  â”‚ ~250MB pkg        â”‚ Sin lÃ­mite    â”‚ Sin lÃ­mite        â•‘
â•‘   Auto-scaling        â”‚ AutomÃ¡tico        â”‚ AutomÃ¡tico    â”‚ Configurable      â•‘
â•‘   Vendor lock-in      â”‚ Alto              â”‚ Medio         â”‚ Bajo              â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 12.2 OpciÃ³n 1: Serverless (AWS Lambda)

### CuÃ¡ndo Usar

```
âœ… USA LAMBDA SI:
â€¢ TrÃ¡fico bajo o esporÃ¡dico (< 1M requests/mes)
â€¢ Modelo pequeÃ±o (< 250MB empaquetado)
â€¢ Latencia variable es aceptable
â€¢ No tienes equipo de DevOps
â€¢ Quieres minimizar costos en bajo trÃ¡fico

âŒ NO USES LAMBDA SI:
â€¢ Necesitas GPU
â€¢ Modelo > 250MB
â€¢ Cold starts son inaceptables (< 100ms requerido)
â€¢ TrÃ¡fico constante y alto
```

### Estructura para Lambda

```
lambda_function/
â”œâ”€â”€ handler.py          # Entry point
â”œâ”€â”€ model/
â”‚   â””â”€â”€ pipeline.pkl    # Modelo (< 250MB)
â”œâ”€â”€ src/
â”‚   â””â”€â”€ inference.py    # LÃ³gica
â””â”€â”€ requirements.txt
```

### handler.py

```python
# handler.py - AWS Lambda Handler
import json
import joblib
import pandas as pd
from pathlib import Path

# Cargar modelo al inicio (fuera del handler para reutilizar)
MODEL_PATH = Path(__file__).parent / "model" / "pipeline.pkl"
model = joblib.load(MODEL_PATH)

def lambda_handler(event, context):
    """AWS Lambda handler."""
    try:
        # Parse input
        if isinstance(event.get("body"), str):
            body = json.loads(event["body"])
        else:
            body = event.get("body", event)
        
        # Crear DataFrame
        df = pd.DataFrame([body])
        
        # Predecir
        proba = model.predict_proba(df)[0, 1]
        prediction = "churn" if proba >= 0.5 else "no_churn"
        
        return {
            "statusCode": 200,
            "headers": {"Content-Type": "application/json"},
            "body": json.dumps({
                "churn_probability": round(proba, 4),
                "prediction": prediction,
            })
        }
    except Exception as e:
        return {
            "statusCode": 500,
            "body": json.dumps({"error": str(e)})
        }
```

### serverless.yml (Serverless Framework)

```yaml
# serverless.yml
service: bankchurn-predictor

provider:
  name: aws
  runtime: python3.11
  region: us-east-1
  memorySize: 1024
  timeout: 30

functions:
  predict:
    handler: handler.lambda_handler
    events:
      - http:
          path: predict
          method: post
          cors: true

plugins:
  - serverless-python-requirements

custom:
  pythonRequirements:
    dockerizePip: true
    slim: true
```

---

## 12.3 OpciÃ³n 2: Contenedores Managed (AWS ECS / GCP Cloud Run)

### CuÃ¡ndo Usar

```
âœ… USA ECS/CLOUD RUN SI:
â€¢ TrÃ¡fico medio-alto (1M-100M requests/mes)
â€¢ Necesitas latencia consistente
â€¢ Modelo de cualquier tamaÃ±o
â€¢ Quieres balance entre control y simplicidad
â€¢ Equipo pequeÃ±o de DevOps (2-3 personas)

âŒ NO USES SI:
â€¢ Necesitas control granular de networking
â€¢ Multi-cloud es requisito
â€¢ TrÃ¡fico extremadamente alto (> 100M)
```

### AWS ECS Task Definition

```json
{
  "family": "bankchurn-api",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "containerDefinitions": [
    {
      "name": "api",
      "image": "123456789.dkr.ecr.us-east-1.amazonaws.com/bankchurn:latest",
      "portMappings": [
        {
          "containerPort": 8000,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {"name": "LOG_LEVEL", "value": "INFO"}
      ],
      "healthCheck": {
        "command": ["CMD-SHELL", "curl -f http://localhost:8000/health || exit 1"],
        "interval": 30,
        "timeout": 5,
        "retries": 3
      },
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/bankchurn",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "api"
        }
      }
    }
  ]
}
```

### GCP Cloud Run (mÃ¡s simple)

```bash
# Deploy a Cloud Run
gcloud run deploy bankchurn-api \
  --image gcr.io/my-project/bankchurn:latest \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --memory 1Gi \
  --cpu 1 \
  --min-instances 0 \
  --max-instances 10 \
  --port 8000
```

---

## 12.4 OpciÃ³n 3: Kubernetes

### CuÃ¡ndo Usar

```
âœ… USA KUBERNETES SI:
â€¢ TrÃ¡fico muy alto (> 100M requests/mes)
â€¢ MÃºltiples servicios ML que escalan diferente
â€¢ Necesitas GPU para inferencia
â€¢ Multi-cloud o hybrid cloud
â€¢ Equipo de Ops experimentado (5+ personas)
â€¢ Ya tienes inversiÃ³n en K8s

âŒ NO USES SI:
â€¢ Un solo modelo simple
â€¢ Equipo pequeÃ±o sin experiencia K8s
â€¢ Presupuesto limitado para Ops
```

### Manifiestos BÃ¡sicos

```yaml
# k8s/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: bankchurn-api
  labels:
    app: bankchurn-api
spec:
  replicas: 3
  selector:
    matchLabels:
      app: bankchurn-api
  template:
    metadata:
      labels:
        app: bankchurn-api
    spec:
      containers:
      - name: api
        image: ghcr.io/username/bankchurn:latest
        ports:
        - containerPort: 8000
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        readinessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 10
          periodSeconds: 5
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 15
          periodSeconds: 10
        env:
        - name: LOG_LEVEL
          value: "INFO"
---
# k8s/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: bankchurn-api
spec:
  selector:
    app: bankchurn-api
  ports:
  - port: 80
    targetPort: 8000
  type: ClusterIP
---
# k8s/hpa.yaml
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: bankchurn-api
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: bankchurn-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

---

## 12.5 AnÃ¡lisis de Costos (FinOps)

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ANÃLISIS DE COSTOS MENSUAL                                 â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   ESCENARIO: 1M requests/mes, ~1 req/seg promedio                             â•‘
â•‘                                                                               â•‘
â•‘   AWS Lambda:                                                                 â•‘
â•‘   â€¢ 1M requests Ã— $0.20/1M = $0.20                                            â•‘
â•‘   â€¢ 1M Ã— 200ms Ã— 1GB = 200K GB-s Ã— $0.0000166 = $3.32                         â•‘
â•‘   â€¢ Total: ~$4/mes âœ… (bajo trÃ¡fico es barato)                                â•‘
â•‘                                                                               â•‘
â•‘   ECS Fargate:                                                                â•‘
â•‘   â€¢ 0.5 vCPU Ã— 730h Ã— $0.04 = $14.60                                          â•‘
â•‘   â€¢ 1GB RAM Ã— 730h Ã— $0.004 = $2.92                                           â•‘
â•‘   â€¢ Total: ~$18/mes (consistente)                                             â•‘
â•‘                                                                               â•‘
â•‘   EKS (3 nodos t3.small):                                                     â•‘
â•‘   â€¢ 3 Ã— $15/mes (EC2) = $45                                                   â•‘
â•‘   â€¢ EKS fee: $72/mes                                                          â•‘
â•‘   â€¢ Total: ~$120/mes (overkill para este volumen)                             â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   ESCENARIO: 100M requests/mes, ~40 req/seg promedio                          â•‘
â•‘                                                                               â•‘
â•‘   AWS Lambda:                                                                 â•‘
â•‘   â€¢ 100M Ã— $0.20/1M = $20                                                     â•‘
â•‘   â€¢ 100M Ã— 200ms Ã— 1GB = 20M GB-s Ã— $0.0000166 = $332                         â•‘
â•‘   â€¢ Total: ~$350/mes (ya no tan barato)                                       â•‘
â•‘                                                                               â•‘
â•‘   ECS Fargate (auto-scaling):                                                 â•‘
â•‘   â€¢ ~5 tareas promedio                                                        â•‘
â•‘   â€¢ Total: ~$90/mes âœ…                                                        â•‘
â•‘                                                                               â•‘
â•‘   EKS (auto-scaling):                                                         â•‘
â•‘   â€¢ 5 nodos t3.medium promedio                                                â•‘
â•‘   â€¢ Total: ~$200/mes                                                          â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 12.6 DecisiÃ³n para BankChurn

### RecomendaciÃ³n por Fase

| Fase | Plataforma | RazÃ³n |
| :--- | :--------- | :---- |
| **MVP/Desarrollo** | Cloud Run o Lambda | Simplicidad, bajo costo inicial |
| **ProducciÃ³n inicial** | ECS/Cloud Run | Balance costo-control |
| **Escala enterprise** | Kubernetes | Control total, multi-service |

### ADR para BankChurn

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ADR-009: Despliegue de BankChurn en Cloud Run                                â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  DECISIÃ“N: Usar Google Cloud Run para el MVP                                  â•‘
â•‘                                                                               â•‘
â•‘  RAZONES:                                                                     â•‘
â•‘  â€¢ Escala a cero cuando no hay trÃ¡fico (costo mÃ­nimo)                         â•‘
â•‘  â€¢ Sin gestiÃ³n de infraestructura                                             â•‘
â•‘  â€¢ Latencia consistente (mejor que Lambda para ML)                            â•‘
â•‘  â€¢ Soporta contenedores Docker estÃ¡ndar                                       â•‘
â•‘  â€¢ FÃ¡cil migraciÃ³n a GKE si necesario                                         â•‘
â•‘                                                                               â•‘
â•‘  TRADE-OFFS ACEPTADOS:                                                        â•‘
â•‘  â€¢ Vendor lock-in medio (GCP)                                                 â•‘
â•‘  â€¢ Menos control que K8s                                                      â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## ğŸ§¨ Errores habituales y cÃ³mo depurarlos en despliegue ML

En despliegue ML es muy fÃ¡cil elegir mal la plataforma o romper detalles como puertos, healthchecks o tamaÃ±os de imagen.

### 1) Elegir la plataforma equivocada (costos o latencia inesperados)

**SÃ­ntomas tÃ­picos**

- Con Lambda: facturas altas al subir el trÃ¡fico o latencias variables por cold starts.
- Con K8s: infraestructura sobredimensionada para un solo modelo simple.

**CÃ³mo identificarlo**

- Compara tu caso con la **matriz de decisiÃ³n** del mÃ³dulo (trÃ¡fico, latencia, equipo Ops, presupuesto).

**CÃ³mo corregirlo**

- Para MVPs y trÃ¡fico moderado, prefiere **Cloud Run/ECS** en lugar de K8s.
- Reserva K8s para escenarios enterprise con mÃºltiples servicios y trÃ¡fico muy alto.

---

### 2) Lambdas que no despliegan o fallan al importar el modelo

**SÃ­ntomas tÃ­picos**

- Errores como `Unable to import module 'handler'`.
- Deployment fallido por paquete demasiado grande (> 250MB).

**CÃ³mo identificarlo**

- Revisa el tamaÃ±o del zip y la estructura de `lambda_function/`.

**CÃ³mo corregirlo**

- Empaqueta solo lo necesario (`model/`, `src/`, `handler.py`, `requirements.txt`).
- Usa capas o reduce dependencias pesadas si es posible.

---

### 3) Contenedores que arrancan pero nunca pasan el healthcheck

**SÃ­ntomas tÃ­picos**

- En ECS/Cloud Run/K8s el servicio queda en estado `UNHEALTHY` o se reinicia en bucle.

**CÃ³mo identificarlo**

- Compara el `healthCheck`/`readinessProbe` con los endpoints reales (`/health`, puerto 8000). 

**CÃ³mo corregirlo**

- Asegura que tu API expone exactamente el endpoint y puerto que la plataforma espera.
- Ajusta `initialDelaySeconds`/`timeout` si el modelo tarda en cargar.

---

### 4) Puertos y rutas inconsistentes entre Docker y la plataforma

**SÃ­ntomas tÃ­picos**

- Funciona en `docker run -p 8000:8000` pero falla al desplegar en Cloud Run/ECS.

**CÃ³mo identificarlo**

- Verifica que el `EXPOSE` del Dockerfile, el puerto del servidor (uvicorn) y el puerto configurado en la plataforma coincidan.

**CÃ³mo corregirlo**

- Usa un puerto estÃ¡ndar (8000) y mantÃ©n el mismo valor en Dockerfile y manifiestos.

---

### 5) PatrÃ³n general de debugging en despliegue ML

1. Verifica primero que la imagen Docker funciona **en local** (`docker run` + `curl /health`).
2. Revisa logs de la plataforma (Lambda logs, Cloud Run logs, ECS/K8s events) para ver errores reales.
3. Comprueba healthchecks, puertos y variables de entorno.
4. Ajusta la plataforma elegida si tus patrones de trÃ¡fico o equipo no encajan con la decisiÃ³n inicial.

Con esta disciplina, pasar de local a producciÃ³n se vuelve un proceso repetible y menos doloroso.

---

## 12.7 Ejercicio: Deploy a Cloud Run

```bash
# 1. Build imagen
docker build -t gcr.io/my-project/bankchurn:v1 .

# 2. Push a GCR
docker push gcr.io/my-project/bankchurn:v1

# 3. Deploy
gcloud run deploy bankchurn \
  --image gcr.io/my-project/bankchurn:v1 \
  --platform managed \
  --region us-central1 \
  --memory 1Gi \
  --allow-unauthenticated

# 4. Test
curl -X POST https://bankchurn-xxx.run.app/api/v1/predict \
  -H "Content-Type: application/json" \
  -d '{"credit_score": 650, "age": 35, ...}'
```

---

## ğŸ“‹ Operaciones y Runbooks

### Estructura de un Runbook ML

```markdown
# Runbook: [Nombre del Servicio]

## InformaciÃ³n del Servicio
- **PropÃ³sito**: PredicciÃ³n de churn
- **Owner**: ML Team
- **Criticality**: Tier 2

## Endpoints
| Endpoint | DescripciÃ³n | SLO |
|----------|-------------|-----|
| /health | Health check | 99.9% |
| /predict | PredicciÃ³n | p99 < 200ms |

## Alertas Comunes

### Alta Latencia (> 500ms)
1. Verificar mÃ©tricas: `kubectl top pods`
2. Revisar logs: `kubectl logs -f deploy/bankchurn-api`
3. Escalar si es necesario: `kubectl scale deploy/bankchurn-api --replicas=5`

### Error Rate > 5%
1. Verificar modelo: Â¿CambiÃ³ la distribuciÃ³n de inputs?
2. Revisar logs de errores
3. Rollback si es necesario: `kubectl rollout undo deploy/bankchurn-api`

## Procedimientos de Emergencia
- **Rollback**: `make rollback VERSION=v1.0.0`
- **Escalar**: `kubectl scale deploy/bankchurn-api --replicas=10`
- **Deshabilitar**: `kubectl scale deploy/bankchurn-api --replicas=0`
```

### SLOs para APIs ML

```yaml
# Ejemplo de SLOs
slos:
  availability:
    target: 99.5%
    window: 30d
  
  latency:
    p50: 50ms
    p95: 150ms
    p99: 300ms
  
  error_rate:
    target: < 1%
    
  prediction_quality:
    accuracy_drift: < 5%  # vs baseline
```

### Checklist de Operaciones

- [ ] **Monitoreo activo**: Dashboards y alertas configurados
- [ ] **Runbook documentado**: Procedimientos de respuesta
- [ ] **Rollback probado**: Capacidad de volver a versiÃ³n anterior
- [ ] **Escalado automÃ¡tico**: HPA configurado
- [ ] **Logs centralizados**: Acceso a logs histÃ³ricos
- [ ] **On-call definido**: RotaciÃ³n y escalamiento

> ğŸ“– Ver ejemplo completo en el [Runbook del Portafolio](../OPERATIONS_PORTFOLIO.md).

---

## ğŸ’¼ Consejos Profesionales

> **Recomendaciones para destacar en entrevistas y proyectos reales**

### Para Entrevistas

1. **Deployment Strategies**: Blue-green, canary, rolling. Pros y cons de cada uno.

2. **A/B Testing**: CÃ³mo evaluar modelos en producciÃ³n con trÃ¡fico real.

3. **Rollback**: Siempre ten plan de rollback automÃ¡tico.

### Para Proyectos Reales

| SituaciÃ³n | Consejo |
|-----------|---------|
| Nuevo modelo | Canary deployment con 5% de trÃ¡fico |
| Alta disponibilidad | MÃºltiples rÃ©plicas + load balancer |
| Modelo grande | Considera serverless o batch serving |
| Costos | Autoscaling basado en trÃ¡fico real |

### Checklist Pre-Deployment

- [ ] Tests pasando en staging
- [ ] MÃ©tricas baseline documentadas
- [ ] Runbook actualizado
- [ ] Rollback probado
- [ ] Alertas configuradas
- [ ] ComunicaciÃ³n a stakeholders


---

## ğŸ“º Recursos Externos Recomendados

> Ver [RECURSOS_POR_MODULO.md](RECURSOS_POR_MODULO.md) para la lista completa.

| ğŸ·ï¸ | Recurso | Tipo |
|:--:|:--------|:-----|
| ğŸ”´ | [Docker Deploy - TechWorld Nana](https://www.youtube.com/watch?v=3c-iBn73dDE) | Video |
| ğŸŸ¡ | [Cloud Run Tutorial](https://www.youtube.com/watch?v=3OP-q55hOUI) | Video |

---

## ğŸ”— Referencias del Glosario

Ver [21_GLOSARIO.md](21_GLOSARIO.md) para definiciones de:
- **Multi-stage Build**: OptimizaciÃ³n de imÃ¡genes Docker
- **Cloud Run**: Serverless containers de GCP
- **Non-root user**: Seguridad en contenedores

---

## âœ… Ejercicios

Ver [EJERCICIOS.md](EJERCICIOS.md) - MÃ³dulo 17:
- **17.1**: Dockerfile multi-stage
- **17.2**: Docker Compose para stack ML

---

## ğŸ”œ Siguiente Paso

Con la plataforma elegida, es hora de gestionar **infraestructura como cÃ³digo**.

**[Ir a MÃ³dulo 18: Infraestructura como CÃ³digo â†’](18_INFRAESTRUCTURA.md)**

---

<div align="center">

[â† Observabilidad](16_OBSERVABILIDAD.md) | [Siguiente: Infraestructura â†’](18_INFRAESTRUCTURA.md)

</div>
