# 05 â€” MLflow & DVC

> **Tiempo estimado**: 3 dÃ­as (24 horas)
> 
> **Prerrequisitos**: MÃ³dulos 01-04 completados

---

## ğŸ¯ Objetivos del MÃ³dulo

Al completar este mÃ³dulo serÃ¡s capaz de:

1. âœ… Configurar **MLflow** para tracking local
2. âœ… Registrar **experimentos, mÃ©tricas y artefactos**
3. âœ… Usar **DVC** para versionado de datos
4. âœ… Crear **pipelines DVC** reproducibles

---

## ğŸ“– Contenido TeÃ³rico

### 1. MLflow BÃ¡sico

#### InstalaciÃ³n y Setup

```bash
pip install mlflow
```

#### Tracking de Experimentos

```python
"""mlflow_tracking.py â€” Tracking con MLflow."""
import mlflow
from mlflow.models import infer_signature
import pandas as pd


def setup_mlflow(
    experiment_name: str = "default",
    tracking_uri: str = "file:./mlruns",
) -> None:
    """Configura MLflow para tracking local."""
    mlflow.set_tracking_uri(tracking_uri)
    mlflow.set_experiment(experiment_name)


def train_with_tracking(
    pipeline,
    X_train: pd.DataFrame,
    y_train: pd.Series,
    X_val: pd.DataFrame,
    y_val: pd.Series,
    params: dict,
) -> str:
    """Entrena modelo con tracking de MLflow.
    
    Returns:
        run_id del experimento
    """
    with mlflow.start_run() as run:
        # Log parÃ¡metros
        mlflow.log_params(params)
        
        # Entrenar
        pipeline.fit(X_train, y_train)
        
        # Evaluar
        y_pred = pipeline.predict(X_val)
        y_proba = pipeline.predict_proba(X_val)[:, 1]
        
        from sklearn.metrics import accuracy_score, roc_auc_score, f1_score
        
        metrics = {
            "accuracy": accuracy_score(y_val, y_pred),
            "roc_auc": roc_auc_score(y_val, y_proba),
            "f1": f1_score(y_val, y_pred),
        }
        
        # Log mÃ©tricas
        mlflow.log_metrics(metrics)
        
        # Log modelo
        signature = infer_signature(X_train, y_pred)
        mlflow.sklearn.log_model(
            pipeline,
            artifact_path="model",
            signature=signature,
        )
        
        # Log artefactos adicionales
        # mlflow.log_artifact("reports/metrics.json")
        
        return run.info.run_id


# Uso
setup_mlflow("churn_prediction")
run_id = train_with_tracking(pipeline, X_train, y_train, X_val, y_val, params)
print(f"Run ID: {run_id}")
```

#### Iniciar UI de MLflow

```bash
# En terminal
mlflow ui --port 5000

# Abrir en navegador: http://localhost:5000
```

---

### 2. MLflow Model Registry

```python
"""registry.py â€” Registro de modelos."""
import mlflow
from mlflow.tracking import MlflowClient


def register_model(run_id: str, model_name: str) -> str:
    """Registra un modelo en el registry.
    
    Returns:
        VersiÃ³n del modelo registrado
    """
    model_uri = f"runs:/{run_id}/model"
    result = mlflow.register_model(model_uri, model_name)
    return result.version


def transition_model_stage(
    model_name: str,
    version: str,
    stage: str = "Production",
) -> None:
    """Cambia el stage de un modelo."""
    client = MlflowClient()
    client.transition_model_version_stage(
        name=model_name,
        version=version,
        stage=stage,
    )


def load_production_model(model_name: str):
    """Carga el modelo en producciÃ³n."""
    model_uri = f"models:/{model_name}/Production"
    return mlflow.sklearn.load_model(model_uri)
```

---

### 3. DVC BÃ¡sico

#### InicializaciÃ³n

```bash
# Inicializar DVC en el proyecto
dvc init

# Agregar remote local (o S3, GCS, etc.)
dvc remote add -d local_remote /tmp/dvc-storage

# Estructura creada
# .dvc/
# â”œâ”€â”€ config
# â””â”€â”€ .gitignore
```

#### Versionado de Datos

```bash
# Agregar archivo a DVC
dvc add data/raw/customers.csv

# Esto crea:
# data/raw/customers.csv.dvc  (metadatos)
# data/raw/.gitignore         (ignora el CSV)

# Commit los metadatos a Git
git add data/raw/customers.csv.dvc data/raw/.gitignore
git commit -m "feat: add customers dataset v1"

# Push datos al remote
dvc push
```

#### dvc.yaml â€” Pipeline Reproducible

```yaml
# dvc.yaml
stages:
  prepare:
    cmd: python src/prepare.py
    deps:
      - src/prepare.py
      - data/raw/customers.csv
    outs:
      - data/processed/train.parquet
      - data/processed/test.parquet

  train:
    cmd: python src/train.py
    deps:
      - src/train.py
      - data/processed/train.parquet
    params:
      - model.n_estimators
      - model.max_depth
    outs:
      - models/pipeline.pkl
    metrics:
      - reports/metrics.json:
          cache: false

  evaluate:
    cmd: python src/evaluate.py
    deps:
      - src/evaluate.py
      - models/pipeline.pkl
      - data/processed/test.parquet
    metrics:
      - reports/evaluation.json:
          cache: false
```

#### Comandos DVC

```bash
# Ejecutar pipeline
dvc repro

# Ver estado del pipeline
dvc status

# Ver mÃ©tricas
dvc metrics show

# Comparar experimentos
dvc metrics diff

# Ver grÃ¡fico del pipeline
dvc dag
```

---

### 4. IntegraciÃ³n MLflow + DVC

```python
"""train.py â€” Training con MLflow y DVC."""
import mlflow
import yaml
import json
from pathlib import Path


def load_params(params_file: str = "params.yaml") -> dict:
    """Carga parÃ¡metros desde params.yaml (DVC)."""
    with open(params_file) as f:
        return yaml.safe_load(f)


def main():
    # Cargar parÃ¡metros (versionados por DVC)
    params = load_params()
    model_params = params.get("model", {})
    
    # Setup MLflow
    mlflow.set_tracking_uri("file:./mlruns")
    mlflow.set_experiment("churn_prediction")
    
    with mlflow.start_run():
        # Log params
        mlflow.log_params(model_params)
        
        # Cargar datos (versionados por DVC)
        train_df = pd.read_parquet("data/processed/train.parquet")
        
        # Entrenar
        # ...
        
        # Guardar mÃ©tricas (DVC las rastrea)
        metrics = {"accuracy": 0.85, "f1": 0.78}
        Path("reports").mkdir(exist_ok=True)
        with open("reports/metrics.json", "w") as f:
            json.dump(metrics, f)
        
        # Log a MLflow tambiÃ©n
        mlflow.log_metrics(metrics)
        
        # Guardar modelo (DVC lo rastrea)
        joblib.dump(pipeline, "models/pipeline.pkl")
        mlflow.sklearn.log_model(pipeline, "model")


if __name__ == "__main__":
    main()
```

---

## ğŸ”§ Mini-Proyecto: Tracking Local

### Objetivo

1. Configurar MLflow tracking local
2. Entrenar modelo con logging
3. Inicializar DVC
4. Crear pipeline reproducible

### Estructura

```
work/05_mlflow_dvc/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ prepare.py
â”‚   â”œâ”€â”€ train.py
â”‚   â””â”€â”€ evaluate.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/
â”‚   â””â”€â”€ processed/
â”œâ”€â”€ models/
â”œâ”€â”€ reports/
â”œâ”€â”€ mlruns/           # MLflow tracking
â”œâ”€â”€ dvc.yaml          # Pipeline DVC
â”œâ”€â”€ params.yaml       # ParÃ¡metros
â””â”€â”€ .dvc/             # Config DVC
```

### Criterios de Ã‰xito

- [ ] `mlflow ui` muestra experimentos
- [ ] `dvc repro` ejecuta pipeline
- [ ] MÃ©tricas en `reports/metrics.json`
- [ ] Modelo en `models/pipeline.pkl`

---

## âœ… ValidaciÃ³n

```bash
make check-05
```

---

## â¡ï¸ Siguiente MÃ³dulo

**[06 â€” Despliegue API](../06_despliegue_api/index.md)**

---

*Ãšltima actualizaciÃ³n: 2024-12*
