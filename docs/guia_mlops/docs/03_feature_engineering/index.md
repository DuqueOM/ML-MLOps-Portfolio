# 03 â€” Feature Engineering

> **Tiempo estimado**: 3 dÃ­as (24 horas)
> 
> **Prerrequisitos**: MÃ³dulos 01-02 completados

---

## ğŸ¯ Objetivos del MÃ³dulo

Al completar este mÃ³dulo serÃ¡s capaz de:

1. âœ… Crear **pipelines de transformaciÃ³n** serializables
2. âœ… Implementar **custom transformers** con sklearn
3. âœ… Evitar **data leakage** en feature engineering
4. âœ… Persistir y cargar **transformadores entrenados**

---

## ğŸ“– Contenido TeÃ³rico

### 1. Pipelines Serializables

#### Â¿Por quÃ© usar pipelines?

```python
# âŒ Mal: Transformaciones manuales (no reproducible)
X_train_scaled = scaler.fit_transform(X_train)
X_train_encoded = encoder.fit_transform(X_train_scaled)
# En producciÃ³n: Â¿cÃ³mo reproducir?

# âœ… Bien: Pipeline unificado (serializable)
pipeline = Pipeline([
    ("scaler", StandardScaler()),
    ("encoder", OneHotEncoder()),
])
pipeline.fit(X_train)
joblib.dump(pipeline, "pipeline.pkl")
```

#### Estructura de Pipeline sklearn

```python
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.impute import SimpleImputer

# Definir columnas
numeric_features = ["age", "balance", "tenure"]
categorical_features = ["gender", "country"]

# Pipeline numÃ©rico
numeric_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler()),
])

# Pipeline categÃ³rico
categorical_pipeline = Pipeline([
    ("imputer", SimpleImputer(strategy="constant", fill_value="missing")),
    ("encoder", OneHotEncoder(handle_unknown="ignore", sparse_output=False)),
])

# Combinar en ColumnTransformer
preprocessor = ColumnTransformer(
    transformers=[
        ("num", numeric_pipeline, numeric_features),
        ("cat", categorical_pipeline, categorical_features),
    ],
    remainder="drop",  # Ignorar columnas no especificadas
)
```

---

### 2. Custom Transformers

#### Transformer BÃ¡sico

```python
from sklearn.base import BaseEstimator, TransformerMixin
import pandas as pd
import numpy as np


class AgeGroupTransformer(BaseEstimator, TransformerMixin):
    """Transforma edad en grupos categÃ³ricos."""
    
    def __init__(self, bins: list[int] = None, labels: list[str] = None):
        self.bins = bins or [0, 25, 35, 50, 65, 120]
        self.labels = labels or ["young", "adult", "middle", "senior", "elderly"]
    
    def fit(self, X: pd.DataFrame, y=None):
        """No aprende nada, solo valida."""
        return self
    
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """Aplica la transformaciÃ³n."""
        X = X.copy()
        X["age_group"] = pd.cut(
            X["age"], 
            bins=self.bins, 
            labels=self.labels,
            include_lowest=True
        )
        return X
```

#### FeatureEngineer Class Completo

```python
"""features.py â€” FeatureEngineer centralizado."""
from sklearn.base import BaseEstimator, TransformerMixin
import pandas as pd
import numpy as np
from typing import Optional


class FeatureEngineer(BaseEstimator, TransformerMixin):
    """Ingeniero de features centralizado para el proyecto.
    
    Esta clase encapsula toda la lÃ³gica de feature engineering,
    garantizando consistencia entre entrenamiento e inferencia.
    """
    
    def __init__(
        self,
        create_ratios: bool = True,
        create_bins: bool = True,
        drop_originals: bool = False,
    ):
        self.create_ratios = create_ratios
        self.create_bins = create_bins
        self.drop_originals = drop_originals
        
        # EstadÃ­sticas aprendidas durante fit
        self._fitted = False
        self._feature_names: list[str] = []
    
    def fit(self, X: pd.DataFrame, y=None) -> "FeatureEngineer":
        """Aprende estadÃ­sticas necesarias de los datos.
        
        En este caso, solo almacenamos los nombres de features.
        Para transformaciones mÃ¡s complejas, aquÃ­ calcularÃ­amos
        estadÃ­sticas (medias, percentiles, etc.)
        """
        self._feature_names = list(X.columns)
        self._fitted = True
        return self
    
    def transform(self, X: pd.DataFrame) -> pd.DataFrame:
        """Aplica todas las transformaciones de features.
        
        IMPORTANTE: Esta funciÃ³n debe ser idempotente y
        no modificar el DataFrame original.
        """
        if not self._fitted:
            raise RuntimeError("FeatureEngineer no ha sido entrenado. Llama fit() primero.")
        
        X = X.copy()
        
        if self.create_ratios:
            X = self._add_ratios(X)
        
        if self.create_bins:
            X = self._add_bins(X)
        
        if self.drop_originals:
            X = self._drop_original_columns(X)
        
        return X
    
    def _add_ratios(self, X: pd.DataFrame) -> pd.DataFrame:
        """Agrega ratios calculados."""
        # Ejemplo: ratio balance/tenure
        if "balance" in X.columns and "tenure" in X.columns:
            # Evitar divisiÃ³n por cero
            X["balance_per_tenure"] = X["balance"] / X["tenure"].replace(0, 1)
        
        return X
    
    def _add_bins(self, X: pd.DataFrame) -> pd.DataFrame:
        """Agrega variables binned."""
        if "age" in X.columns:
            X["age_group"] = pd.cut(
                X["age"],
                bins=[0, 30, 50, 120],
                labels=["young", "middle", "senior"],
                include_lowest=True
            )
        
        return X
    
    def _drop_original_columns(self, X: pd.DataFrame) -> pd.DataFrame:
        """Elimina columnas originales si se solicita."""
        # Implementar segÃºn necesidad
        return X
    
    def get_feature_names_out(self) -> list[str]:
        """Retorna nombres de features de salida."""
        return self._feature_names
```

---

### 3. PrevenciÃ³n de Data Leakage

#### âš ï¸ QuÃ© es Data Leakage

Data leakage ocurre cuando informaciÃ³n del conjunto de test "filtra" hacia el entrenamiento, resultando en mÃ©tricas irreales.

```python
# âŒ INCORRECTO: Fit en todo el dataset
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)  # Usa estadÃ­sticas de TODO X
X_train, X_test = train_test_split(X_scaled)  # Test "contaminado"

# âœ… CORRECTO: Fit solo en train
X_train, X_test = train_test_split(X)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # Solo train
X_test_scaled = scaler.transform(X_test)  # Sin fit!
```

#### Features que causan leakage

```python
# âŒ LEAKAGE: Features derivadas del target
df["avg_churn_by_country"] = df.groupby("country")["churn"].transform("mean")

# âŒ LEAKAGE: Features del futuro
df["next_month_balance"] = df["balance"].shift(-1)

# âœ… CORRECTO: Solo usar informaciÃ³n disponible en producciÃ³n
df["balance_change"] = df["balance"] - df["previous_balance"]
```

---

### 4. Persistencia de Transformadores

```python
"""persistence.py â€” Guardar y cargar pipelines."""
import joblib
from pathlib import Path
from typing import Any


def save_pipeline(pipeline: Any, path: str | Path) -> None:
    """Guarda un pipeline serializado."""
    path = Path(path)
    path.parent.mkdir(parents=True, exist_ok=True)
    joblib.dump(pipeline, path)
    print(f"Pipeline guardado en {path}")


def load_pipeline(path: str | Path) -> Any:
    """Carga un pipeline serializado."""
    path = Path(path)
    if not path.exists():
        raise FileNotFoundError(f"Pipeline no encontrado: {path}")
    return joblib.load(path)


# Uso
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler

pipeline = Pipeline([("scaler", StandardScaler())])
pipeline.fit(X_train)

# Guardar
save_pipeline(pipeline, "models/preprocessor.pkl")

# Cargar (en otro script/sesiÃ³n)
pipeline = load_pipeline("models/preprocessor.pkl")
X_new_transformed = pipeline.transform(X_new)
```

---

## ğŸ”§ Mini-Proyecto: FeatureEngineer Serializable

### Objetivo

Crear una clase `FeatureEngineer` que:
1. Implemente transformaciones de features
2. Sea compatible con sklearn Pipeline
3. Se pueda serializar con joblib
4. Tenga tests unitarios

### Estructura

```
work/03_feature_engineering/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ features.py        # FeatureEngineer
â”‚   â””â”€â”€ persistence.py     # Guardar/cargar
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_features.py
â”œâ”€â”€ artifacts/
â”‚   â””â”€â”€ .gitkeep
â””â”€â”€ pyproject.toml
```

### Criterios de Ã‰xito

- [ ] FeatureEngineer funciona en pipeline sklearn
- [ ] Se puede serializar y deserializar
- [ ] No hay data leakage (fit solo en train)
- [ ] Tests pasan: `pytest tests/ -v`

---

## âœ… ValidaciÃ³n

```bash
make check-03
```

---

## â¡ï¸ Siguiente MÃ³dulo

**[04 â€” Modelado](../04_modelado/index.md)**

---

*Ãšltima actualizaciÃ³n: 2024-12*
