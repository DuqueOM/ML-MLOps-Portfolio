# üéØ Simulacro de Entrevista Junior ML Engineer
## Portafolio MLOps ‚Äî 50 Preguntas Fundamentales

**Autor del Portafolio**: Daniel Duque (DuqueOM)  
**Versi√≥n**: 1.0  
**Fecha**: Diciembre 2025  
**Nivel**: Junior (0-2 a√±os de experiencia)

---

## üìã √çndice

1. [Python B√°sico](#1-python-b√°sico-preguntas-1-10)
2. [Machine Learning Fundamentos](#2-machine-learning-fundamentos-preguntas-11-20)
3. [Datos y Preprocesamiento](#3-datos-y-preprocesamiento-preguntas-21-30)
4. [Git y Herramientas](#4-git-y-herramientas-preguntas-31-40)
5. [Pr√°ctica con el Portafolio](#5-pr√°ctica-con-el-portafolio-preguntas-41-50)

---

## üéØ Antes de Empezar

### ¬øQu√© se espera de un Junior?

| Lo que S√ç se espera | Lo que NO se espera |
|---------------------|---------------------|
| Fundamentos s√≥lidos de Python | Dise√±o de arquitecturas complejas |
| Entender train/test split | Optimizaci√≥n de hiperpar√°metros avanzada |
| Saber qu√© es overfitting | Implementar MLOps completo |
| Usar Git b√°sico | CI/CD avanzado |
| Leer y modificar c√≥digo existente | Escribir c√≥digo de producci√≥n desde cero |
| Hacer preguntas inteligentes | Tener todas las respuestas |

### Consejos para la Entrevista

1. **S√© honesto**: "No lo s√©, pero lo investigar√≠a as√≠..." es mejor que inventar
2. **Muestra curiosidad**: Haz preguntas sobre el c√≥digo que ves
3. **Relaciona con el portafolio**: "En BankChurn aprend√≠ que..."
4. **Piensa en voz alta**: El proceso importa m√°s que la respuesta perfecta

---

# 1. Python B√°sico (Preguntas 1-10)

## Pregunta 1: Tipos de Datos
**¬øCu√°l es la diferencia entre lista, tupla y diccionario?**

### Respuesta:
```python
# Lista: mutable, ordenada
features = ["age", "salary", "tenure"]
features.append("score")  # OK

# Tupla: inmutable, ordenada
coordinates = (40.7, -74.0)
# coordinates[0] = 41.0  # ERROR

# Diccionario: mutable, key-value
customer = {"id": 123, "name": "John", "churn": False}
customer["score"] = 0.85  # OK
```

**Cu√°ndo usar cada uno**:
- **Lista**: Colecci√≥n que cambiar√° (features a seleccionar)
- **Tupla**: Datos que no deben cambiar (coordenadas, constantes)
- **Diccionario**: Acceso por clave (configuraci√≥n, datos de cliente)

---

## Pregunta 2: List Comprehension
**Reescribe este c√≥digo con list comprehension:**
```python
result = []
for x in range(10):
    if x % 2 == 0:
        result.append(x**2)
```

### Respuesta:
```python
result = [x**2 for x in range(10) if x % 2 == 0]
# [0, 4, 16, 36, 64]
```

**Ventajas**:
- M√°s conciso
- M√°s r√°pido (optimizado internamente)
- M√°s "pyth√≥nico"

---

## Pregunta 3: Funciones y Argumentos
**¬øQu√© hace `*args` y `**kwargs`?**

### Respuesta:
```python
def log_experiment(*args, **kwargs):
    # args: tupla de argumentos posicionales
    # kwargs: diccionario de argumentos con nombre
    print(f"Metrics: {args}")
    print(f"Config: {kwargs}")

log_experiment(0.85, 0.82, model="rf", n_estimators=100)
# Metrics: (0.85, 0.82)
# Config: {'model': 'rf', 'n_estimators': 100}
```

**En el portafolio** (`BankChurn/trainer.py`):
```python
def __init__(self, config: BankChurnConfig, **kwargs):
    self.config = config
    self.extra_params = kwargs  # Flexibilidad para params adicionales
```

---

## Pregunta 4: Manejo de Errores
**¬øPor qu√© usamos try/except?**

### Respuesta:
```python
def load_data(path: str) -> pd.DataFrame:
    try:
        df = pd.read_csv(path)
        return df
    except FileNotFoundError:
        print(f"Error: {path} no existe")
        raise
    except pd.errors.EmptyDataError:
        print("Error: archivo vac√≠o")
        raise
```

**Buenas pr√°cticas**:
- Capturar excepciones espec√≠ficas, no gen√©ricas
- Hacer logging del error
- Re-lanzar si no puedes manejarlo

---

## Pregunta 5: Import y M√≥dulos
**¬øCu√°l es la diferencia entre estas formas de import?**

### Respuesta:
```python
# Importar m√≥dulo completo
import pandas as pd
df = pd.read_csv("data.csv")

# Importar funci√≥n espec√≠fica
from sklearn.model_selection import train_test_split
X_train, X_test = train_test_split(X)

# Importar todo (‚ö†Ô∏è evitar en producci√≥n)
from math import *  # Contamina el namespace
```

**Best practice**: Importar lo que necesitas, usar alias est√°ndar (`pd`, `np`, `plt`).

---

## Pregunta 6: Type Hints
**¬øQu√© significan los type hints y por qu√© usarlos?**

### Respuesta:
```python
def predict_churn(
    credit_score: int,
    age: int,
    is_active: bool
) -> float:
    """Retorna probabilidad de churn."""
    ...
```

**Beneficios**:
1. **Documentaci√≥n**: Claro qu√© espera y retorna
2. **IDE support**: Autocompletado, detecci√≥n de errores
3. **Tooling**: `mypy` puede verificar tipos

**En el portafolio**: Todos los archivos usan type hints (`config.py`, `training.py`).

---

## Pregunta 7: Clases B√°sicas
**¬øQu√© es `__init__` y `self`?**

### Respuesta:
```python
class BankChurnTrainer:
    def __init__(self, config):
        # Constructor: se ejecuta al crear instancia
        self.config = config  # self = esta instancia
        self.model_ = None
    
    def train(self, X, y):
        # self permite acceder a atributos de la instancia
        if self.config.model_type == "rf":
            self.model_ = RandomForestClassifier()
        self.model_.fit(X, y)

# Uso
trainer = BankChurnTrainer(config)  # __init__ se llama aqu√≠
trainer.train(X, y)
```

---

## Pregunta 8: Lectura de Archivos
**¬øC√≥mo lees un archivo CSV con pandas?**

### Respuesta:
```python
import pandas as pd

# B√°sico
df = pd.read_csv("data/raw/Churn.csv")

# Con opciones
df = pd.read_csv(
    "data/raw/Churn.csv",
    sep=",",
    encoding="utf-8",
    na_values=["", "NA", "null"],
    dtype={"customer_id": str}
)

# Verificar
print(df.shape)       # (10000, 14)
print(df.info())      # Tipos y nulls
print(df.head())      # Primeras filas
```

---

## Pregunta 9: Entornos Virtuales
**¬øPor qu√© usamos entornos virtuales?**

### Respuesta:
```bash
# Crear entorno
python -m venv .venv

# Activar
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows

# Instalar dependencias
pip install -r requirements.txt
```

**Razones**:
1. **Aislamiento**: Cada proyecto tiene sus propias versiones
2. **Reproducibilidad**: Mismo entorno en cualquier m√°quina
3. **Evita conflictos**: sklearn 1.3 en proyecto A, sklearn 1.2 en proyecto B

---

## Pregunta 10: Debugging B√°sico
**¬øC√≥mo depuras c√≥digo en Python?**

### Respuesta:
```python
# 1. Print statements (b√°sico pero √∫til)
print(f"X shape: {X.shape}, y shape: {y.shape}")

# 2. Usar assert
assert X.shape[0] == y.shape[0], "Mismatch en filas"

# 3. Breakpoints en IDE (recomendado)
# Poner breakpoint y usar F5 para debugear

# 4. pdb (en terminal)
import pdb; pdb.set_trace()

# 5. Logging (producci√≥n)
import logging
logging.debug(f"Loaded {len(df)} rows")
```

---

# 2. Machine Learning Fundamentos (Preguntas 11-20)

## Pregunta 11: Train/Test Split
**¬øPor qu√© separamos datos en train y test?**

### Respuesta:
```python
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X, y, 
    test_size=0.2,      # 80/20 split
    random_state=42,    # Reproducibilidad
    stratify=y          # Mantener proporci√≥n de clases
)
```

**Raz√≥n**: Evaluar c√≥mo el modelo generaliza a datos **nunca vistos**.
- **Train**: Aprende patrones
- **Test**: Simula producci√≥n, mide rendimiento real

**Error com√∫n**: Usar test para ajustar modelo ‚Üí overfitting al test.

---

## Pregunta 12: Overfitting vs Underfitting
**Explica overfitting y underfitting.**

### Respuesta:

| Concepto | S√≠ntomas | Causa | Soluci√≥n |
|----------|----------|-------|----------|
| **Overfitting** | Train acc: 99%, Test acc: 70% | Modelo muy complejo | Regularizaci√≥n, m√°s datos, simplificar |
| **Underfitting** | Train acc: 60%, Test acc: 58% | Modelo muy simple | M√°s features, modelo m√°s complejo |

```python
# Detectar en el portafolio
print(f"Train accuracy: {model.score(X_train, y_train):.2%}")
print(f"Test accuracy: {model.score(X_test, y_test):.2%}")

# Si diferencia > 10%, posible overfitting
```

---

## Pregunta 13: Clasificaci√≥n vs Regresi√≥n
**¬øCu√°ndo usar clasificaci√≥n y cu√°ndo regresi√≥n?**

### Respuesta:

| Problema | Tipo | Target | M√©trica |
|----------|------|--------|---------|
| ¬øCliente har√° churn? | Clasificaci√≥n | S√≠/No (0/1) | Accuracy, F1, AUC |
| ¬øCu√°nto cuesta el auto? | Regresi√≥n | Precio ($) | RMSE, MAE, R¬≤ |
| ¬øQu√© plan elegir√°? | Clasificaci√≥n multiclase | A/B/C | Accuracy, F1 macro |

**En el portafolio**:
- **BankChurn**: Clasificaci√≥n binaria (churn: 0/1)
- **CarVision**: Regresi√≥n (precio continuo)
- **TelecomAI**: Clasificaci√≥n multiclase (tipo de plan)

---

## Pregunta 14: Cross-Validation
**¬øQu√© es cross-validation y por qu√© usarla?**

### Respuesta:
```python
from sklearn.model_selection import cross_val_score

scores = cross_val_score(model, X, y, cv=5)
print(f"Accuracy: {scores.mean():.3f} (+/- {scores.std()*2:.3f})")
```

**Proceso K-Fold (K=5)**:
1. Divide datos en 5 partes iguales
2. Entrena en 4, valida en 1
3. Repite 5 veces (cada parte es validaci√≥n una vez)
4. Promedia resultados

**Ventajas**:
- Usa todos los datos para entrenar y validar
- Estimaci√≥n m√°s robusta del rendimiento
- Detecta variabilidad del modelo

---

## Pregunta 15: Feature Scaling
**¬øPor qu√© normalizamos features?**

### Respuesta:
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X_train)

# Antes: age=[18-92], salary=[20000-200000]
# Despu√©s: ambas con media=0, std=1
```

**Razones**:
1. **Algoritmos sensibles a escala**: SVM, KNN, redes neuronales
2. **Gradiente descent**: Converge m√°s r√°pido
3. **Interpretaci√≥n**: Coeficientes comparables

**Algoritmos que NO necesitan scaling**: Random Forest, Decision Tree, XGBoost.

---

## Pregunta 16: One-Hot Encoding
**¬øC√≥mo manejas variables categ√≥ricas?**

### Respuesta:
```python
from sklearn.preprocessing import OneHotEncoder

encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')
X_encoded = encoder.fit_transform(df[['Geography', 'Gender']])

# Geography: France, Germany, Spain
# ‚Üí Geography_France, Geography_Germany, Geography_Spain
```

**Alternativas**:
- **Label Encoding**: Para ordinales (Bajo < Medio < Alto)
- **Target Encoding**: Codifica con la media del target (‚ö†Ô∏è riesgo de leakage)

---

## Pregunta 17: Missing Values
**¬øC√≥mo manejas valores faltantes?**

### Respuesta:
```python
from sklearn.impute import SimpleImputer

# Num√©ricos: media o mediana
imputer_num = SimpleImputer(strategy='median')

# Categ√≥ricos: moda o valor constante
imputer_cat = SimpleImputer(strategy='constant', fill_value='Unknown')
```

**Estrategias**:
| Caso | Estrategia |
|------|------------|
| Pocos missing (<5%) | Imputar con media/moda |
| Muchos missing | Considerar eliminar columna |
| Missing tiene significado | Crear feature `is_missing` |

---

## Pregunta 18: Random Forest
**Explica c√≥mo funciona Random Forest.**

### Respuesta:
```python
from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(
    n_estimators=100,  # 100 √°rboles
    max_depth=10,      # Profundidad m√°xima
    random_state=42
)
```

**Concepto simple**:
1. Crea N √°rboles de decisi√≥n
2. Cada √°rbol usa subset aleatorio de datos y features
3. Predicci√≥n final = voto mayoritario (clasificaci√≥n) o promedio (regresi√≥n)

**Ventajas**: Robusto, pocas configuraciones, maneja bien missing values.

---

## Pregunta 19: M√©tricas de Clasificaci√≥n
**¬øQu√© es accuracy, precision, recall y F1?**

### Respuesta:
```python
from sklearn.metrics import classification_report

print(classification_report(y_test, y_pred))
```

| M√©trica | F√≥rmula | Cu√°ndo priorizar |
|---------|---------|------------------|
| **Accuracy** | Correctos / Total | Clases balanceadas |
| **Precision** | TP / (TP + FP) | Costo alto de falsos positivos |
| **Recall** | TP / (TP + FN) | Costo alto de falsos negativos |
| **F1** | 2 √ó (P √ó R) / (P + R) | Balance entre P y R |

**En BankChurn**: Priorizo **Recall** (no queremos perder clientes que har√°n churn).

---

## Pregunta 20: Curva ROC y AUC
**¬øQu√© es AUC-ROC?**

### Respuesta:
```python
from sklearn.metrics import roc_auc_score, roc_curve

# AUC: √Årea bajo la curva ROC
auc = roc_auc_score(y_test, y_pred_proba[:, 1])
print(f"AUC: {auc:.3f}")
```

**Interpretaci√≥n**:
- **AUC = 1.0**: Clasificador perfecto
- **AUC = 0.5**: Clasificador aleatorio
- **AUC > 0.8**: Generalmente bueno

**Ventaja**: Funciona bien con clases desbalanceadas.

---

# 3. Datos y Preprocesamiento (Preguntas 21-30)

## Pregunta 21: Exploraci√≥n de Datos
**¬øQu√© haces primero cuando recibes un dataset?**

### Respuesta:
```python
import pandas as pd

df = pd.read_csv("data.csv")

# 1. Dimensiones
print(f"Shape: {df.shape}")  # (filas, columnas)

# 2. Tipos de datos
print(df.dtypes)

# 3. Missing values
print(df.isnull().sum())

# 4. Estad√≠sticas b√°sicas
print(df.describe())

# 5. Primeras filas
print(df.head())

# 6. Target distribution
print(df['target'].value_counts(normalize=True))
```

---

## Pregunta 22: Detecci√≥n de Outliers
**¬øC√≥mo detectas outliers?**

### Respuesta:
```python
import numpy as np

# M√©todo IQR
Q1 = df['Balance'].quantile(0.25)
Q3 = df['Balance'].quantile(0.75)
IQR = Q3 - Q1

lower = Q1 - 1.5 * IQR
upper = Q3 + 1.5 * IQR

outliers = df[(df['Balance'] < lower) | (df['Balance'] > upper)]
print(f"Outliers: {len(outliers)}")
```

**Qu√© hacer con outliers**:
1. Verificar si son errores de datos ‚Üí corregir
2. Si son leg√≠timos ‚Üí considerar winsorization o mantener
3. Para modelos sensibles ‚Üí eliminar o transformar

---

## Pregunta 23: Correlaci√≥n
**¬øC√≥mo identificas features correlacionadas?**

### Respuesta:
```python
import seaborn as sns
import matplotlib.pyplot as plt

# Matriz de correlaci√≥n
corr = df.corr()

# Heatmap
plt.figure(figsize=(10, 8))
sns.heatmap(corr, annot=True, cmap='coolwarm')
plt.show()

# Features altamente correlacionadas (>0.9)
high_corr = (corr.abs() > 0.9) & (corr != 1.0)
```

**¬øPor qu√© importa?** Features muy correlacionadas son redundantes ‚Üí considerar eliminar una.

---

## Pregunta 24: Desbalance de Clases
**¬øQu√© haces cuando tienes 95% clase A y 5% clase B?**

### Respuesta:
```python
# 1. Cambiar m√©trica (no usar accuracy)
from sklearn.metrics import f1_score, recall_score

# 2. Class weights
from sklearn.linear_model import LogisticRegression
model = LogisticRegression(class_weight='balanced')

# 3. Oversampling (SMOTE)
from imblearn.over_sampling import SMOTE
X_res, y_res = SMOTE().fit_resample(X, y)

# 4. Undersampling
from imblearn.under_sampling import RandomUnderSampler
```

**En BankChurn**: 80/20 balance ‚Üí usamos `class_weight='balanced'` y F1.

---

## Pregunta 25: Feature Selection
**¬øC√≥mo seleccionas features importantes?**

### Respuesta:
```python
from sklearn.ensemble import RandomForestClassifier

# 1. Feature importance de RF
rf = RandomForestClassifier().fit(X, y)
importances = pd.DataFrame({
    'feature': X.columns,
    'importance': rf.feature_importances_
}).sort_values('importance', ascending=False)

# 2. Correlaci√≥n con target
correlations = df.corr()['target'].abs().sort_values(ascending=False)

# 3. SelectKBest
from sklearn.feature_selection import SelectKBest, f_classif
selector = SelectKBest(f_classif, k=10)
X_selected = selector.fit_transform(X, y)
```

---

## Pregunta 26: Data Leakage
**¬øQu√© es data leakage y c√≥mo evitarlo?**

### Respuesta:
Data leakage = cuando informaci√≥n del futuro o del target filtra al entrenamiento.

```python
# ‚ùå MAL: fit scaler en TODO antes de split
scaler.fit(X)  # Ve datos de test
X_train, X_test = train_test_split(X)

# ‚úÖ BIEN: fit solo en train
X_train, X_test = train_test_split(X)
scaler.fit(X_train)  # Solo ve train
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
```

**En el portafolio**: Usamos Pipeline de sklearn que maneja esto autom√°ticamente.

---

## Pregunta 27: Pipelines de sklearn
**¬øPor qu√© usar Pipeline?**

### Respuesta:
```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

pipe = Pipeline([
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier())
])

# Un solo fit/predict
pipe.fit(X_train, y_train)
y_pred = pipe.predict(X_test)
```

**Beneficios**:
1. **Evita leakage**: fit solo en train autom√°ticamente
2. **C√≥digo limpio**: Todo en un objeto
3. **F√°cil deploy**: `joblib.dump(pipe, 'model.joblib')`
4. **Reproducibilidad**: Mismo proceso siempre

---

## Pregunta 28: Guardado de Modelos
**¬øC√≥mo guardas y cargas un modelo entrenado?**

### Respuesta:
```python
import joblib

# Guardar
joblib.dump(model, 'artifacts/model.joblib')

# Cargar
model = joblib.load('artifacts/model.joblib')

# Usar
prediction = model.predict(new_data)
```

**En producci√≥n** (FastAPI):
```python
@lru_cache()
def load_model():
    return joblib.load("artifacts/pipeline.joblib")
```

---

## Pregunta 29: Validaci√≥n de Datos
**¬øC√≥mo validas que los datos de entrada son correctos?**

### Respuesta:
```python
from pydantic import BaseModel, Field, validator

class CustomerInput(BaseModel):
    credit_score: int = Field(ge=300, le=850)
    age: int = Field(ge=18, le=100)
    geography: str
    
    @validator('geography')
    def geography_valid(cls, v):
        valid = ['France', 'Germany', 'Spain']
        if v not in valid:
            raise ValueError(f'Must be one of {valid}')
        return v
```

**Beneficios**: Errores claros antes de llegar al modelo.

---

## Pregunta 30: Reproducibilidad
**¬øC√≥mo garantizas que tu experimento sea reproducible?**

### Respuesta:
```python
import random
import numpy as np

# 1. Fijar seeds
SEED = 42
random.seed(SEED)
np.random.seed(SEED)

# 2. En modelos
model = RandomForestClassifier(random_state=SEED)

# 3. En split
train_test_split(X, y, random_state=SEED)

# 4. Documentar versiones
# requirements.txt o pyproject.toml con versiones fijas
```

---

# 4. Git y Herramientas (Preguntas 31-40)

## Pregunta 31: Git B√°sico
**¬øCu√°l es el flujo b√°sico de Git?**

### Respuesta:
```bash
# 1. Ver estado
git status

# 2. A√±adir cambios
git add .                     # Todo
git add archivo.py            # Espec√≠fico

# 3. Commit
git commit -m "feat: add preprocessing step"

# 4. Push
git push origin main

# 5. Pull (obtener cambios)
git pull origin main
```

---

## Pregunta 32: Branches
**¬øPor qu√© usar branches?**

### Respuesta:
```bash
# Crear branch
git checkout -b feature/add-validation

# Trabajar...
git add .
git commit -m "feat: add pydantic validation"

# Push branch
git push origin feature/add-validation

# Crear Pull Request en GitHub
# Despu√©s de aprobar, merge a main
```

**Razones**:
- Aislar cambios
- Revisar c√≥digo antes de merge
- Mantener main siempre funcional

---

## Pregunta 33: .gitignore
**¬øQu√© debe ir en .gitignore?**

### Respuesta:
```gitignore
# Datos (grandes, sensibles)
data/
*.csv
*.parquet

# Artefactos
artifacts/
*.joblib
*.pkl

# Entornos
.venv/
__pycache__/

# IDEs
.vscode/
.idea/

# Logs
*.log
mlruns/
```

**Regla**: No subir datos grandes, artefactos binarios, ni secretos.

---

## Pregunta 34: Requirements
**¬øC√≥mo manejas dependencias?**

### Respuesta:
```bash
# Crear requirements.txt
pip freeze > requirements.txt

# Mejor: usar pip-tools
pip-compile requirements.in > requirements.txt

# Instalar
pip install -r requirements.txt

# Moderno: pyproject.toml
pip install -e ".[dev]"
```

---

## Pregunta 35: Makefile
**¬øPara qu√© sirve un Makefile?**

### Respuesta:
```makefile
.PHONY: install test train

install:
	pip install -e ".[dev]"

test:
	pytest tests/ -v --cov=src

train:
	python main.py --config configs/config.yaml

lint:
	ruff check src/
```

**Uso**:
```bash
make install
make test
make train
```

**Beneficio**: Comandos est√°ndar, documentados, f√°ciles de recordar.

---

## Pregunta 36: pytest B√°sico
**¬øC√≥mo escribes un test b√°sico?**

### Respuesta:
```python
# tests/test_data.py
import pytest
import pandas as pd

def test_load_data():
    df = pd.read_csv("data/raw/sample.csv")
    assert len(df) > 0
    assert "target" in df.columns

def test_no_nulls_in_target():
    df = pd.read_csv("data/raw/sample.csv")
    assert df["target"].isnull().sum() == 0

# Ejecutar
# pytest tests/test_data.py -v
```

---

## Pregunta 37: Estructura de Proyecto
**¬øC√≥mo organizas un proyecto ML?**

### Respuesta:
```
mi-proyecto/
‚îú‚îÄ‚îÄ src/miproyecto/     # C√≥digo fuente
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ config.py       # Configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ data.py         # Carga de datos
‚îÇ   ‚îú‚îÄ‚îÄ features.py     # Feature engineering
‚îÇ   ‚îî‚îÄ‚îÄ training.py     # Entrenamiento
‚îú‚îÄ‚îÄ app/                # APIs
‚îú‚îÄ‚îÄ tests/              # Tests
‚îú‚îÄ‚îÄ configs/            # YAML configs
‚îú‚îÄ‚îÄ data/raw/           # Datos
‚îú‚îÄ‚îÄ artifacts/          # Modelos guardados
‚îú‚îÄ‚îÄ pyproject.toml      # Dependencias
‚îú‚îÄ‚îÄ Makefile           
‚îî‚îÄ‚îÄ README.md
```

---

## Pregunta 38: README
**¬øQu√© debe tener un buen README?**

### Respuesta:
```markdown
# Nombre del Proyecto

## Descripci√≥n
Qu√© hace el proyecto, problema que resuelve.

## Instalaci√≥n
```bash
pip install -e .
```

## Uso R√°pido
```python
from miproyecto import predict
result = predict(data)
```

## Estructura
√Årbol de directorios.

## Tests
```bash
make test
```

## Autor
Nombre, contacto.
```

---

## Pregunta 39: Docker B√°sico
**¬øQu√© es Docker y por qu√© usarlo?**

### Respuesta:
Docker empaqueta tu aplicaci√≥n con todas sus dependencias.

```dockerfile
FROM python:3.11-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
CMD ["python", "main.py"]
```

```bash
# Construir
docker build -t mi-app .

# Ejecutar
docker run mi-app
```

**Beneficio**: "Funciona en mi m√°quina" ‚Üí Funciona en cualquier m√°quina.

---

## Pregunta 40: APIs B√°sicas
**¬øQu√© es una API REST?**

### Respuesta:
API = Interfaz para que otros programas usen tu c√≥digo.

```python
from fastapi import FastAPI

app = FastAPI()

@app.get("/health")
def health():
    return {"status": "ok"}

@app.post("/predict")
def predict(data: dict):
    # Usar modelo
    return {"prediction": result}
```

```bash
# Ejecutar
uvicorn app:app --reload

# Probar
curl http://localhost:8000/health
```

---

# 5. Pr√°ctica con el Portafolio (Preguntas 41-50)

## Pregunta 41: Describir el Portafolio
**Cu√©ntame sobre el portafolio.**

### Respuesta:
"Es un portafolio de MLOps con 3 proyectos production-ready:

1. **BankChurn-Predictor**: Clasificaci√≥n binaria para predecir churn de clientes bancarios. Pipeline sklearn unificado, FastAPI, 79% coverage.

2. **CarVision-Market-Intelligence**: Regresi√≥n para predecir precios de autos usados. FeatureEngineer centralizado, Streamlit dashboard.

3. **TelecomAI**: Clasificaci√≥n multiclase para segmentaci√≥n de clientes de telecom.

Todos siguen las mismas pr√°cticas: estructura src/, Pydantic para configs, pytest, GitHub Actions CI."

---

## Pregunta 42: Ejecutar el Proyecto
**¬øC√≥mo ejecuto BankChurn?**

### Respuesta:
```bash
# 1. Clonar
git clone https://github.com/duqueom/ML-MLOps-Portfolio.git
cd ML-MLOps-Portfolio/BankChurn-Predictor

# 2. Crear entorno
python -m venv .venv
source .venv/bin/activate

# 3. Instalar
pip install -e ".[dev]"

# 4. Entrenar
python main.py --config configs/config.yaml

# 5. API
uvicorn app.fastapi_app:app --reload

# 6. Tests
pytest tests/ -v
```

---

## Pregunta 43: Entender el Pipeline
**¬øC√≥mo funciona el pipeline de BankChurn?**

### Respuesta:
```python
# 1. Cargar config
config = BankChurnConfig.from_yaml("configs/config.yaml")

# 2. Cargar datos
df = pd.read_csv(config.data.raw_path)

# 3. Crear trainer
trainer = Trainer(config)

# 4. Entrenar (dentro crea Pipeline sklearn)
trainer.fit(X, y)
# Pipeline = [preprocessor, model]
# preprocessor = ColumnTransformer(numeric_pipe, categorical_pipe)

# 5. Evaluar
metrics = trainer.evaluate(X_test, y_test)

# 6. Guardar
trainer.save("artifacts/")
```

---

## Pregunta 44: Modificar el C√≥digo
**¬øC√≥mo a√±adir√≠as una nueva feature?**

### Respuesta:
```python
# 1. En config.yaml, a√±adir columna
features:
  numerical:
    - CreditScore
    - Age
    - NewFeature  # Nueva

# 2. Si requiere transformaci√≥n, editar FeatureEngineer
class FeatureEngineer:
    def transform(self, X):
        X['NewFeature'] = X['Col1'] / X['Col2']
        return X

# 3. Agregar test
def test_new_feature():
    fe = FeatureEngineer()
    result = fe.transform(sample_df)
    assert 'NewFeature' in result.columns

# 4. Ejecutar tests
pytest tests/test_features.py -v
```

---

## Pregunta 45: Leer un Error
**Este c√≥digo falla. ¬øPor qu√©?**
```python
X_train = scaler.fit_transform(X_train)
X_test = scaler.fit_transform(X_test)
```

### Respuesta:
**Problema**: `fit_transform` en test causa data leakage.

```python
# ‚úÖ Correcto
X_train = scaler.fit_transform(X_train)  # fit + transform
X_test = scaler.transform(X_test)        # solo transform
```

El scaler debe aprender (fit) solo de training data.

---

## Pregunta 46: Interpretar M√©tricas
**El modelo tiene accuracy 95% pero el negocio no est√° contento. ¬øPor qu√©?**

### Respuesta:
Posibles razones:

1. **Clases desbalanceadas**: Si 95% son clase 0, predecir siempre 0 da 95% accuracy pero es in√∫til.

2. **M√©trica incorrecta**: El negocio necesita recall (no perder churners) pero optimizaste accuracy.

3. **Falsos negativos costosos**: Cada cliente que hace churn y no detectamos cuesta $X.

**Soluci√≥n**: Usar F1, recall, o una m√©trica de negocio (costo).

---

## Pregunta 47: Configuraci√≥n YAML
**¬øPor qu√© usar archivos YAML para configuraci√≥n?**

### Respuesta:
```yaml
# configs/config.yaml
model:
  type: "random_forest"
  n_estimators: 100
  max_depth: 10

data:
  raw_path: "data/raw/Churn.csv"
  test_size: 0.2

training:
  random_state: 42
```

**Ventajas**:
1. **Separaci√≥n**: Cambiar par√°metros sin tocar c√≥digo
2. **Versionable**: Git puede trackear cambios
3. **Legible**: F√°cil de entender
4. **Reproducibilidad**: Guardar config de cada experimento

---

## Pregunta 48: CI/CD B√°sico
**¬øQu√© hace el workflow de GitHub Actions?**

### Respuesta:
```yaml
# .github/workflows/ci.yml
name: CI
on: [push, pull_request]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
      - run: pip install -e ".[dev]"
      - run: pytest tests/ -v
```

**Flujo**:
1. Push c√≥digo ‚Üí GitHub Actions se activa
2. Crea m√°quina virtual limpia
3. Instala dependencias
4. Ejecuta tests
5. Reporta pass/fail

---

## Pregunta 49: Debugging en Producci√≥n
**El API retorna error 500. ¬øC√≥mo lo depuras?**

### Respuesta:
```python
# 1. Ver logs
uvicorn app:app --log-level debug

# 2. A√±adir logging
import logging
logging.basicConfig(level=logging.DEBUG)

@app.post("/predict")
def predict(data: Input):
    logging.debug(f"Input: {data}")
    try:
        result = model.predict(...)
        logging.debug(f"Result: {result}")
        return result
    except Exception as e:
        logging.error(f"Error: {e}")
        raise

# 3. Probar localmente
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"credit_score": 650, ...}'
```

---

## Pregunta 50: Pr√≥ximos Pasos
**¬øQu√© aprender√≠as despu√©s de este portafolio?**

### Respuesta:
"Con las bases del portafolio, me gustar√≠a profundizar en:

1. **MLflow/Experiment Tracking**: Ya est√° configurado, pero quiero usarlo m√°s para comparar experimentos sistem√°ticamente.

2. **Docker avanzado**: Optimizar im√°genes, multi-stage builds.

3. **Testing m√°s robusto**: A√±adir tests de integraci√≥n, property-based testing.

4. **Kubernetes b√°sico**: Entender c√≥mo escalar los servicios.

5. **Monitoreo en producci√≥n**: Detectar drift, alertas.

El portafolio me dio la base; ahora quiero profundizar en cada √°rea."

---

# üìö Recursos para Preparaci√≥n

## M√≥dulos de la Gu√≠a Relacionados

| Pregunta | M√≥dulo |
|----------|--------|
| Python b√°sico | [01_PYTHON_MODERNO.md](01_PYTHON_MODERNO.md) |
| ML fundamentos | [07_SKLEARN_PIPELINES.md](07_SKLEARN_PIPELINES.md), [08_INGENIERIA_FEATURES.md](08_INGENIERIA_FEATURES.md) |
| Git | [05_GIT_PROFESIONAL.md](05_GIT_PROFESIONAL.md) |
| Testing | [11_TESTING_ML.md](11_TESTING_ML.md) |
| APIs | [14_FASTAPI.md](14_FASTAPI.md) |

## Checklist Pre-Entrevista

- [ ] Puedo ejecutar `make install && make test` en BankChurn
- [ ] Entiendo qu√© hace cada archivo en `src/bankchurn/`
- [ ] S√© explicar train/test split y por qu√© importa
- [ ] Puedo leer y modificar el `config.yaml`
- [ ] Entiendo el flujo Git b√°sico

---

<div align="center">

**¬°√âxito en tu entrevista! üöÄ**

*Recuerda: ser Junior significa estar aprendiendo. Muestra curiosidad y ganas de aprender.*

[‚Üê √çndice](00_INDICE.md) | [Simulacro Mid ‚Üí](SIMULACRO_ENTREVISTA_MID.md) | [Simulacro Senior ‚Üí](SIMULACRO_ENTREVISTA_SENIOR_PARTE1.md)

</div>
