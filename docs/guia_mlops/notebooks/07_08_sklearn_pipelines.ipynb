{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üîß Notebook Interactivo: sklearn Pipelines y Feature Engineering\n",
    "\n",
    "> **M√≥dulos 07-08 de la Gu√≠a MLOps**\n",
    "\n",
    "Este notebook te permite experimentar con los conceptos de:\n",
    "- sklearn Pipelines\n",
    "- ColumnTransformer\n",
    "- Custom Transformers\n",
    "- Detecci√≥n de Data Leakage\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalaci√≥n de dependencias (ejecutar solo si es necesario)\n",
    "# !pip install pandas scikit-learn numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "print(\"‚úÖ Librer√≠as cargadas correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crear Dataset de Ejemplo\n",
    "\n",
    "Simulamos un dataset de **Bank Churn** similar al del portafolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataset sint√©tico\n",
    "np.random.seed(42)\n",
    "n_samples = 1000\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'CreditScore': np.random.randint(300, 850, n_samples),\n",
    "    'Age': np.random.randint(18, 92, n_samples),\n",
    "    'Tenure': np.random.randint(0, 10, n_samples),\n",
    "    'Balance': np.random.uniform(0, 250000, n_samples),\n",
    "    'NumOfProducts': np.random.randint(1, 4, n_samples),\n",
    "    'HasCrCard': np.random.randint(0, 2, n_samples),\n",
    "    'IsActiveMember': np.random.randint(0, 2, n_samples),\n",
    "    'EstimatedSalary': np.random.uniform(10000, 200000, n_samples),\n",
    "    'Geography': np.random.choice(['France', 'Germany', 'Spain'], n_samples),\n",
    "    'Gender': np.random.choice(['Male', 'Female'], n_samples),\n",
    "    'Exited': np.random.randint(0, 2, n_samples)  # Target\n",
    "})\n",
    "\n",
    "# Introducir algunos NaN para hacerlo m√°s realista\n",
    "data.loc[np.random.choice(n_samples, 50), 'Balance'] = np.nan\n",
    "data.loc[np.random.choice(n_samples, 30), 'CreditScore'] = np.nan\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(f\"\\nMissing values:\\n{data.isnull().sum()}\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pipeline B√°sico (M√≥dulo 07)\n",
    "\n",
    "### 3.1 El problema SIN Pipeline\n",
    "\n",
    "‚ùå **C√≥digo fr√°gil y con riesgo de data leakage:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå MAL ENFOQUE - No hacer esto en producci√≥n\n",
    "\n",
    "# Separar features y target\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "# ‚ö†Ô∏è LEAKAGE: fit en TODO el dataset antes del split\n",
    "scaler = StandardScaler()\n",
    "numeric_cols = ['CreditScore', 'Age', 'Balance', 'EstimatedSalary']\n",
    "\n",
    "# Imputar valores nulos (en todo X)\n",
    "X[numeric_cols] = X[numeric_cols].fillna(X[numeric_cols].mean())\n",
    "\n",
    "# Escalar (en todo X) - ¬°DATA LEAKAGE!\n",
    "X[numeric_cols] = scaler.fit_transform(X[numeric_cols])\n",
    "\n",
    "# Ahora hacer el split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "print(\"‚ö†Ô∏è Este c√≥digo tiene DATA LEAKAGE\")\n",
    "print(\"El scaler vio informaci√≥n del test set antes del split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 La soluci√≥n CON Pipeline\n",
    "\n",
    "‚úÖ **C√≥digo robusto sin data leakage:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ BUEN ENFOQUE - Pipeline unificado\n",
    "\n",
    "# Definir columnas\n",
    "numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', \n",
    "                    'NumOfProducts', 'EstimatedSalary']\n",
    "categorical_features = ['Geography', 'Gender']\n",
    "binary_features = ['HasCrCard', 'IsActiveMember']\n",
    "\n",
    "# Preprocessor con ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), categorical_features),\n",
    "        ('bin', 'passthrough', binary_features)\n",
    "    ],\n",
    "    remainder='drop'  # Elimina columnas no especificadas\n",
    ")\n",
    "\n",
    "# Pipeline completo\n",
    "pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Pipeline creado:\")\n",
    "print(pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separar datos ANTES de cualquier transformaci√≥n\n",
    "X = data.drop('Exited', axis=1)\n",
    "y = data['Exited']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Entrenar pipeline (fit solo en train)\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar\n",
    "y_pred = pipe.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"\\n‚úÖ Accuracy: {accuracy:.3f}\")\n",
    "print(f\"\\nüìä Classification Report:\\n{classification_report(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Cross-Validation con Pipeline\n",
    "\n",
    "El pipeline garantiza que cada fold se procesa correctamente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation con pipeline\n",
    "cv_scores = cross_val_score(pipe, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "print(f\"CV Scores: {cv_scores}\")\n",
    "print(f\"Mean CV Accuracy: {cv_scores.mean():.3f} (+/- {cv_scores.std()*2:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Custom Transformer (M√≥dulo 08)\n",
    "\n",
    "Crear transformers personalizados para feature engineering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeGroupTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Agrupa edades en categor√≠as.\"\"\"\n",
    "    \n",
    "    def __init__(self, bins=[0, 25, 35, 50, 65, 100], \n",
    "                 labels=['Young', 'Adult', 'Middle', 'Senior', 'Elderly']):\n",
    "        self.bins = bins\n",
    "        self.labels = labels\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        # No necesita aprender nada de los datos\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X['AgeGroup'] = pd.cut(X['Age'], bins=self.bins, labels=self.labels)\n",
    "        return X\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        return list(input_features) + ['AgeGroup'] if input_features else ['AgeGroup']\n",
    "\n",
    "\n",
    "# Probar el transformer\n",
    "age_transformer = AgeGroupTransformer()\n",
    "transformed = age_transformer.fit_transform(X_train[['Age']])\n",
    "print(\"\\n‚úÖ AgeGroup distribution:\")\n",
    "print(transformed['AgeGroup'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Custom transformer para crear features derivadas.\n",
    "    \n",
    "    Similar al FeatureEngineer del portafolio CarVision.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, create_balance_salary_ratio=True):\n",
    "        self.create_balance_salary_ratio = create_balance_salary_ratio\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        # Guardar columnas originales\n",
    "        self.feature_names_in_ = X.columns.tolist()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        \n",
    "        # Feature 1: Ratio Balance/Salary\n",
    "        if self.create_balance_salary_ratio:\n",
    "            X['BalanceSalaryRatio'] = X['Balance'] / (X['EstimatedSalary'] + 1)\n",
    "        \n",
    "        # Feature 2: Tenure por producto\n",
    "        X['TenurePerProduct'] = X['Tenure'] / (X['NumOfProducts'] + 0.1)\n",
    "        \n",
    "        # Feature 3: Cliente maduro (tenure > 5 y activo)\n",
    "        X['MatureClient'] = ((X['Tenure'] > 5) & (X['IsActiveMember'] == 1)).astype(int)\n",
    "        \n",
    "        return X\n",
    "    \n",
    "    def get_feature_names_out(self, input_features=None):\n",
    "        new_features = ['BalanceSalaryRatio', 'TenurePerProduct', 'MatureClient']\n",
    "        if input_features is not None:\n",
    "            return list(input_features) + new_features\n",
    "        return self.feature_names_in_ + new_features\n",
    "\n",
    "\n",
    "# Probar el FeatureEngineer\n",
    "fe = FeatureEngineer()\n",
    "X_engineered = fe.fit_transform(X_train)\n",
    "print(\"\\n‚úÖ Nuevas features creadas:\")\n",
    "print(X_engineered[['Balance', 'EstimatedSalary', 'BalanceSalaryRatio', \n",
    "                    'TenurePerProduct', 'MatureClient']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pipeline Completo con Custom Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline con FeatureEngineer incluido\n",
    "numeric_features_extended = numeric_features + ['BalanceSalaryRatio', 'TenurePerProduct']\n",
    "binary_features_extended = binary_features + ['MatureClient']\n",
    "\n",
    "# Nuevo preprocessor\n",
    "preprocessor_v2 = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='median')),\n",
    "            ('scaler', StandardScaler())\n",
    "        ]), numeric_features_extended),\n",
    "        ('cat', Pipeline([\n",
    "            ('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')),\n",
    "            ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "        ]), categorical_features),\n",
    "        ('bin', 'passthrough', binary_features_extended)\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Pipeline completo con feature engineering\n",
    "pipe_v2 = Pipeline([\n",
    "    ('features', FeatureEngineer()),\n",
    "    ('preprocessor', preprocessor_v2),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Pipeline v2 creado con FeatureEngineer\")\n",
    "print(pipe_v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenar y evaluar pipeline v2\n",
    "pipe_v2.fit(X_train, y_train)\n",
    "y_pred_v2 = pipe_v2.predict(X_test)\n",
    "accuracy_v2 = accuracy_score(y_test, y_pred_v2)\n",
    "\n",
    "print(f\"\\nüìä Comparaci√≥n:\")\n",
    "print(f\"Pipeline v1 (sin FeatureEngineer): {accuracy:.3f}\")\n",
    "print(f\"Pipeline v2 (con FeatureEngineer): {accuracy_v2:.3f}\")\n",
    "print(f\"Mejora: {(accuracy_v2 - accuracy)*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Detecci√≥n de Data Leakage (M√≥dulo 08)\n",
    "\n",
    "### üî¥ Ejemplo de Data Leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚ùå EJEMPLO DE DATA LEAKAGE\n",
    "# Crear feature que usa informaci√≥n del target\n",
    "\n",
    "data_with_leakage = data.copy()\n",
    "\n",
    "# ‚ö†Ô∏è Esta feature usa el target indirectamente\n",
    "data_with_leakage['AvgExitByGeo'] = data_with_leakage.groupby('Geography')['Exited'].transform('mean')\n",
    "\n",
    "print(\"‚ö†Ô∏è LEAKAGE: AvgExitByGeo calculado con el target\")\n",
    "print(data_with_leakage[['Geography', 'Exited', 'AvgExitByGeo']].head(10))\n",
    "\n",
    "print(\"\\nüî¥ Esta feature tiene informaci√≥n del futuro (el target).\")\n",
    "print(\"El modelo aprender√° a 'hacer trampa' usando esta informaci√≥n.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ‚úÖ C√≥mo evitar el leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úÖ CORRECTO: Calcular estad√≠sticas solo en el training set\n",
    "\n",
    "class TargetEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Target encoding SIN data leakage.\"\"\"\n",
    "    \n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "        self.encoding_map_ = {}\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"Calcula encoding solo con datos de training.\"\"\"\n",
    "        df = X.copy()\n",
    "        df['__target__'] = y\n",
    "        \n",
    "        for col in self.columns:\n",
    "            self.encoding_map_[col] = df.groupby(col)['__target__'].mean().to_dict()\n",
    "            \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        \"\"\"Aplica encoding aprendido (sin ver y de test).\"\"\"\n",
    "        X = X.copy()\n",
    "        for col in self.columns:\n",
    "            global_mean = np.mean(list(self.encoding_map_[col].values()))\n",
    "            X[f'{col}_encoded'] = X[col].map(self.encoding_map_[col]).fillna(global_mean)\n",
    "        return X\n",
    "\n",
    "# Uso correcto\n",
    "encoder = TargetEncoder(columns=['Geography'])\n",
    "encoder.fit(X_train, y_train)  # Solo usa y_train\n",
    "\n",
    "X_test_encoded = encoder.transform(X_test)  # No ve y_test\n",
    "print(\"‚úÖ Target encoding correcto (sin leakage)\")\n",
    "print(X_test_encoded[['Geography', 'Geography_encoded']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Guardar y Cargar Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Guardar pipeline entrenado\n",
    "joblib.dump(pipe_v2, 'pipeline_demo.joblib')\n",
    "print(\"‚úÖ Pipeline guardado en 'pipeline_demo.joblib'\")\n",
    "\n",
    "# Cargar pipeline\n",
    "loaded_pipe = joblib.load('pipeline_demo.joblib')\n",
    "\n",
    "# Verificar que funciona igual\n",
    "y_pred_loaded = loaded_pipe.predict(X_test)\n",
    "assert (y_pred_v2 == y_pred_loaded).all()\n",
    "print(\"‚úÖ Pipeline cargado y verificado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Ejercicios para Practicar\n",
    "\n",
    "### Ejercicio 1: A√±ade un nuevo transformer\n",
    "Crea un transformer que agrupe `CreditScore` en categor√≠as (Poor, Fair, Good, Excellent).\n",
    "\n",
    "### Ejercicio 2: Detecta el leakage\n",
    "¬øQu√© pasa si a√±ades `X['ExitedPrediction'] = y` antes del split?\n",
    "\n",
    "### Ejercicio 3: Compara modelos\n",
    "Reemplaza `RandomForestClassifier` por `GradientBoostingClassifier` y compara.\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Recursos\n",
    "\n",
    "- [M√≥dulo 07: sklearn Pipelines](../07_SKLEARN_PIPELINES.md)\n",
    "- [M√≥dulo 08: Feature Engineering](../08_INGENIERIA_FEATURES.md)\n",
    "- [EJERCICIOS.md](../EJERCICIOS.md) - Ejercicios 7.1, 7.2, 8.1, 8.2\n",
    "- [RECURSOS_POR_MODULO.md](../RECURSOS_POR_MODULO.md) - Videos recomendados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Limpieza\n",
    "import os\n",
    "if os.path.exists('pipeline_demo.joblib'):\n",
    "    os.remove('pipeline_demo.joblib')\n",
    "    print(\"üßπ Archivo temporal eliminado\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
