# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EJERCICIOS PRÃCTICOS - GUÃA MLOps
# PrÃ¡cticas por MÃ³dulo con MetodologÃ­a Explorar â†’ Reproducir â†’ Extender
# GuÃ­a MLOps v3.0 | DuqueOM | Noviembre 2025
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

<div align="center">

# ğŸ“ EJERCICIOS PRÃCTICOS

**GuÃ­a Completa de Ejercicios MLOps**

*MetodologÃ­a: Explorar â†’ Reproducir â†’ Extender*

| Total Ejercicios | Dificultad Progresiva | Tiempo Estimado |
|:----------------:|:---------------------:|:---------------:|
| 45+ ejercicios   | BÃ¡sico â†’ Avanzado     | 40-60 horas     |

</div>

---

## ğŸ“‹ Tabla de Contenidos

1. [Instrucciones Generales](#instrucciones-generales)
2. [MÃ³dulo 01: Fundamentos](#mÃ³dulo-01-fundamentos-mlops)
3. [MÃ³dulo 02: DiseÃ±o del Proyecto](#mÃ³dulo-02-diseÃ±o-del-proyecto)
4. [MÃ³dulo 03: Estructura del Repositorio](#mÃ³dulo-03-estructura-del-repositorio)
5. [MÃ³dulo 04: Git y GitHub](#mÃ³dulo-04-git-y-github)
6. [MÃ³dulo 05: DVC](#mÃ³dulo-05-dvc)
7. [MÃ³dulo 06: Pipeline ML](#mÃ³dulo-06-pipeline-ml)
8. [MÃ³dulo 07: MLflow](#mÃ³dulo-07-mlflow)
9. [MÃ³dulo 08: Testing](#mÃ³dulo-08-testing)
10. [MÃ³dulo 09: CI/CD](#mÃ³dulo-09-cicd)
11. [MÃ³dulo 10: Docker](#mÃ³dulo-10-docker)
12. [MÃ³dulo 11: FastAPI](#mÃ³dulo-11-fastapi)
13. [MÃ³dulo 12: Kubernetes](#mÃ³dulo-12-kubernetes)
14. [MÃ³dulo 13: Terraform](#mÃ³dulo-13-terraform)
15. [MÃ³dulo 14: Monitoreo](#mÃ³dulo-14-monitoreo)
16. [MÃ³dulo 15-17: DocumentaciÃ³n y Demo](#mÃ³dulos-15-17-documentaciÃ³n-y-demo)
17. [Proyecto Integrador Final](#proyecto-integrador-final)

---

## Instrucciones Generales

### MetodologÃ­a de Cada Ejercicio

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         ESTRUCTURA DE EJERCICIOS                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   ğŸ” EXPLORAR (20% del tiempo)                                                â•‘
â•‘   â€¢ Leer la documentaciÃ³n indicada                                            â•‘
â•‘   â€¢ Analizar ejemplos existentes                                              â•‘
â•‘   â€¢ Responder preguntas de comprensiÃ³n                                        â•‘
â•‘                                                                               â•‘
â•‘   ğŸ”„ REPRODUCIR (40% del tiempo)                                              â•‘
â•‘   â€¢ Seguir el tutorial paso a paso                                            â•‘
â•‘   â€¢ Ejecutar comandos y verificar outputs                                     â•‘
â•‘   â€¢ Documentar errores encontrados                                            â•‘
â•‘                                                                               â•‘
â•‘   ğŸš€ EXTENDER (40% del tiempo)                                                â•‘
â•‘   â€¢ Aplicar a un caso propio                                                  â•‘
â•‘   â€¢ Resolver retos adicionales                                                â•‘
â•‘   â€¢ Crear variaciones y mejoras                                               â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### CÃ³mo Usar Este Documento

1. **Lee el ejercicio completo** antes de comenzar
2. **Prepara tu entorno** segÃºn los prerrequisitos
3. **Sigue la metodologÃ­a** Explorar â†’ Reproducir â†’ Extender
4. **Verifica con el script** de validaciÃ³n cuando estÃ© disponible
5. **Consulta las soluciones** en [EJERCICIOS_SOLUCIONES.md](EJERCICIOS_SOLUCIONES.md) solo despuÃ©s de intentarlo

### Niveles de Dificultad

| SÃ­mbolo | Nivel       | Tiempo Estimado |
|:--------|:------------|:----------------|
| ğŸŸ¢      | BÃ¡sico      | 30-60 min       |
| ğŸŸ¡      | Intermedio  | 1-2 horas       |
| ğŸ”´      | Avanzado    | 2-4 horas       |
| â­      | Reto Extra  | Variable        |

---

## MÃ³dulo 01: Fundamentos MLOps

### Ejercicio 1.1 ğŸŸ¢ - Identificar Nivel de Madurez MLOps

**Objetivo:** Evaluar el nivel de madurez MLOps de un proyecto existente.

#### ğŸ” Explorar
1. Lee la secciÃ³n 1.3 del MÃ³dulo 01 sobre niveles de madurez
2. Revisa el checklist de cada nivel (0-3)

#### ğŸ”„ Reproducir
1. Descarga o clona un proyecto ML pÃºblico (ej: un repositorio de Kaggle)
2. Completa la siguiente tabla de evaluaciÃ³n:

```markdown
| Criterio                      | Nivel 0 | Nivel 1 | Nivel 2 | Nivel 3 |
|:------------------------------|:-------:|:-------:|:-------:|:-------:|
| Control de versiones (Git)    |   â–¡     |   â–¡     |   â–¡     |   â–¡     |
| Versionado de datos           |   â–¡     |   â–¡     |   â–¡     |   â–¡     |
| Experimentos trackeados       |   â–¡     |   â–¡     |   â–¡     |   â–¡     |
| Tests automatizados           |   â–¡     |   â–¡     |   â–¡     |   â–¡     |
| CI/CD configurado             |   â–¡     |   â–¡     |   â–¡     |   â–¡     |
| Containerizado                |   â–¡     |   â–¡     |   â–¡     |   â–¡     |
| Monitoreo en producciÃ³n       |   â–¡     |   â–¡     |   â–¡     |   â–¡     |
```

3. Determina el nivel actual y quÃ© falta para subir al siguiente

#### ğŸš€ Extender
1. **Reto 1:** EvalÃºa 3 proyectos diferentes y compara sus niveles
2. **Reto 2:** Crea un plan de acciÃ³n para llevar un proyecto de Nivel 0 a Nivel 2
3. **Reto 3:** DiseÃ±a un script que automatice parte de esta evaluaciÃ³n

**Criterios de AceptaciÃ³n:**
- [ ] Tabla completada con justificaciones
- [ ] Nivel identificado correctamente
- [ ] Plan de mejora documentado

---

### Ejercicio 1.2 ğŸŸ¡ - DiseÃ±ar Ciclo de Vida MLOps

**Objetivo:** DiseÃ±ar el ciclo de vida completo para un caso de uso especÃ­fico.

#### ğŸ” Explorar
1. Lee la secciÃ³n sobre el ciclo de vida MLOps (Data â†’ Dev â†’ Deploy â†’ Monitor)
2. Analiza el diagrama del portafolio de referencia

#### ğŸ”„ Reproducir
Dado el siguiente caso de uso:
> "Predictor de abandono de clientes (churn) para un banco con 100K clientes activos"

1. Dibuja el diagrama del ciclo de vida especÃ­fico
2. Lista las herramientas que usarÃ­as en cada fase
3. Identifica los checkpoints de calidad

#### ğŸš€ Extender
1. **Reto 1:** Adapta el ciclo para un caso de NLP (anÃ¡lisis de sentimiento)
2. **Reto 2:** DiseÃ±a el ciclo para un modelo de visiÃ³n por computador
3. **Reto 3:** AÃ±ade consideraciones de escalabilidad (1M+ predicciones/dÃ­a)

**Entregable:** Documento markdown con diagramas ASCII y justificaciones

---

### Ejercicio 1.3 ğŸ”´ - AnÃ¡lisis de Trade-offs TecnolÃ³gicos

**Objetivo:** Evaluar y justificar decisiones tecnolÃ³gicas.

#### ğŸ”„ Reproducir
Completa la tabla comparativa para cada categorÃ­a:

**Tracking de Experimentos:**

| Criterio            | MLflow | W&B    | Neptune | Comet  |
|:--------------------|:------:|:------:|:-------:|:------:|
| Open Source         |        |        |         |        |
| Self-hosted         |        |        |         |        |
| UI/UX               |        |        |         |        |
| IntegraciÃ³n sklearn |        |        |         |        |
| Costo               |        |        |         |        |
| **RecomendaciÃ³n**   |        |        |         |        |

**Versionado de Datos:**

| Criterio            | DVC    | Git LFS | Delta Lake | LakeFS |
|:--------------------|:------:|:-------:|:----------:|:------:|
| Curva aprendizaje   |        |         |            |        |
| Pipelines ML        |        |         |            |        |
| Big Data            |        |         |            |        |
| IntegraciÃ³n Git     |        |         |            |        |
| **RecomendaciÃ³n**   |        |         |            |        |

#### ğŸš€ Extender
Escribe un ADR (Architecture Decision Record) justificando tus elecciones.

---

## MÃ³dulo 02: DiseÃ±o del Proyecto

### Ejercicio 2.1 ğŸŸ¢ - Completar ML Canvas

**Objetivo:** DiseÃ±ar un proyecto ML usando el framework ML Canvas.

#### ğŸ”„ Reproducir
Para el proyecto "Predictor de Precios de Casas":

```yaml
# ml_canvas.yaml
proyecto: "House Price Predictor"

1_prediccion:
  que_predecir: ""  # Completar
  tipo_problema: "" # clasificaciÃ³n/regresiÃ³n/clustering

2_datos:
  fuente: ""
  volumen: ""
  calidad: ""

3_features:
  principales:
    - ""
  derivadas:
    - ""

4_modelo:
  baseline: ""
  candidatos:
    - ""

5_evaluacion:
  metrica_principal: ""
  metricas_secundarias:
    - ""

6_integracion:
  como_se_usara: ""
  latencia_requerida: ""

7_feedback:
  como_mejorar: ""
```

#### ğŸš€ Extender
1. **Reto 1:** Crea un ML Canvas para un sistema de recomendaciÃ³n
2. **Reto 2:** Crea un ML Canvas para detecciÃ³n de fraude
3. **Reto 3:** Presenta tu ML Canvas en formato visual (diagrama)

---

### Ejercicio 2.2 ğŸŸ¡ - Definir MÃ©tricas de Ã‰xito

**Objetivo:** Seleccionar y justificar mÃ©tricas apropiadas.

#### ğŸ”„ Reproducir
Para cada escenario, define:
- MÃ©trica tÃ©cnica principal
- MÃ©tricas secundarias
- MÃ©trica de negocio

| Escenario                        | MÃ©trica TÃ©cnica | Secundarias | Negocio |
|:---------------------------------|:----------------|:------------|:--------|
| DetecciÃ³n de spam                |                 |             |         |
| PredicciÃ³n de ventas             |                 |             |         |
| DiagnÃ³stico mÃ©dico               |                 |             |         |
| Sistema de recomendaciÃ³n         |                 |             |         |
| PredicciÃ³n de churn              |                 |             |         |

#### ğŸš€ Extender
Implementa una funciÃ³n Python que calcule todas las mÃ©tricas para un clasificador:

```python
def evaluate_classifier(y_true, y_pred, y_prob):
    """
    Calcula mÃ©tricas completas para clasificaciÃ³n binaria.
    
    Returns:
        dict con accuracy, precision, recall, f1, auc, etc.
    """
    # Tu implementaciÃ³n aquÃ­
    pass
```

---

## MÃ³dulo 03: Estructura del Repositorio

### Ejercicio 3.1 ğŸŸ¢ - Crear Estructura Profesional

**Objetivo:** Inicializar un proyecto con estructura profesional.

#### ğŸ”„ Reproducir
Ejecuta los siguientes comandos para crear la estructura:

```bash
# Crear proyecto
mkdir mi_proyecto_ml && cd mi_proyecto_ml

# Crear estructura
mkdir -p {data/{raw,processed,external},src/{data,features,models,visualization},tests,notebooks,configs,docs}

# Crear archivos base
touch README.md requirements.txt setup.py .gitignore
touch src/__init__.py src/data/__init__.py src/models/__init__.py
touch tests/__init__.py tests/test_data.py tests/test_model.py

# Verificar estructura
tree -L 2
```

**Output Esperado:**
```
mi_proyecto_ml/
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ setup.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ configs/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ external/
â”‚   â”œâ”€â”€ processed/
â”‚   â””â”€â”€ raw/
â”œâ”€â”€ docs/
â”œâ”€â”€ notebooks/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ features/
â”‚   â”œâ”€â”€ models/
â”‚   â””â”€â”€ visualization/
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_data.py
    â””â”€â”€ test_model.py
```

#### ğŸš€ Extender
1. **Reto 1:** AÃ±ade un Makefile con comandos Ãºtiles
2. **Reto 2:** Crea un script `create_project.sh` que automatice esto
3. **Reto 3:** AÃ±ade pre-commit hooks para linting

**Script de ValidaciÃ³n:**
```bash
#!/bin/bash
# validate_structure.sh
REQUIRED_DIRS=("data/raw" "data/processed" "src" "tests" "notebooks" "configs")
REQUIRED_FILES=("README.md" "requirements.txt" ".gitignore")

echo "Validando estructura..."
for dir in "${REQUIRED_DIRS[@]}"; do
    if [ -d "$dir" ]; then
        echo "âœ… $dir"
    else
        echo "âŒ $dir - FALTA"
    fi
done

for file in "${REQUIRED_FILES[@]}"; do
    if [ -f "$file" ]; then
        echo "âœ… $file"
    else
        echo "âŒ $file - FALTA"
    fi
done
```

---

## MÃ³dulo 04: Git y GitHub

### Ejercicio 4.1 ğŸŸ¢ - Flujo de Trabajo Git BÃ¡sico

**Objetivo:** Dominar el flujo bÃ¡sico de Git.

#### ğŸ”„ Reproducir
```bash
# 1. Inicializar repositorio
git init
git config user.name "Tu Nombre"
git config user.email "tu@email.com"

# 2. Primer commit
echo "# Mi Proyecto ML" > README.md
git add README.md
git commit -m "feat: initial commit with README"

# 3. Crear branch de desarrollo
git checkout -b develop

# 4. AÃ±adir feature
git checkout -b feature/add-requirements
echo "pandas==2.0.0" > requirements.txt
git add requirements.txt
git commit -m "feat: add initial requirements"

# 5. Merge a develop
git checkout develop
git merge feature/add-requirements

# 6. Ver historial
git log --oneline --graph --all
```

#### ğŸš€ Extender
1. **Reto 1:** Simula un conflicto de merge y resuÃ©lvelo
2. **Reto 2:** Usa `git rebase` en lugar de merge
3. **Reto 3:** Configura un hook pre-commit que verifique el formato de commits

---

### Ejercicio 4.2 ğŸŸ¡ - Pull Request Profesional

**Objetivo:** Crear un Pull Request con descripciÃ³n profesional.

#### ğŸ”„ Reproducir
1. Crea un fork del repositorio de ejemplo (o usa el tuyo)
2. Crea una rama `feature/improve-readme`
3. Realiza cambios y haz commit
4. Crea un PR con esta plantilla:

```markdown
## ğŸ“ DescripciÃ³n
[Breve descripciÃ³n del cambio]

## ğŸ¯ Tipo de Cambio
- [ ] Bug fix
- [ ] Nueva feature
- [ ] Mejora de documentaciÃ³n
- [ ] Refactoring

## âœ… Checklist
- [ ] El cÃ³digo sigue las guÃ­as de estilo
- [ ] He aÃ±adido tests
- [ ] La documentaciÃ³n estÃ¡ actualizada
- [ ] Todos los tests pasan

## ğŸ“¸ Screenshots (si aplica)
[Capturas de pantalla]

## ğŸ”— Issues Relacionados
Closes #XX
```

---

## MÃ³dulo 05: DVC

### Ejercicio 5.1 ğŸŸ¢ - Inicializar DVC

**Objetivo:** Configurar DVC en un proyecto existente.

#### ğŸ”„ Reproducir
```bash
# 1. Instalar DVC
pip install dvc dvc-s3

# 2. Inicializar
cd mi_proyecto_ml
dvc init

# 3. Configurar remote local (para prÃ¡ctica)
mkdir -p /tmp/dvc-storage
dvc remote add -d myremote /tmp/dvc-storage

# 4. Trackear un dataset
# Primero descarga un dataset de ejemplo
curl -o data/raw/iris.csv https://raw.githubusercontent.com/mwaskom/seaborn-data/master/iris.csv

# AÃ±adir a DVC
dvc add data/raw/iris.csv

# 5. Commit cambios
git add data/raw/iris.csv.dvc data/raw/.gitignore
git commit -m "data: add iris dataset with DVC"

# 6. Push datos
dvc push

# 7. Verificar
dvc status
```

#### ğŸš€ Extender
1. **Reto 1:** Configura un remote en S3 o GCS
2. **Reto 2:** Crea un pipeline DVC con `dvc.yaml`
3. **Reto 3:** Implementa versionado de datasets (v1, v2) con tags

---

### Ejercicio 5.2 ğŸŸ¡ - Pipeline DVC

**Objetivo:** Crear un pipeline reproducible con DVC.

#### ğŸ”„ Reproducir
Crea los siguientes archivos:

**dvc.yaml:**
```yaml
stages:
  prepare:
    cmd: python src/data/prepare.py
    deps:
      - src/data/prepare.py
      - data/raw/iris.csv
    outs:
      - data/processed/iris_clean.csv

  train:
    cmd: python src/models/train.py
    deps:
      - src/models/train.py
      - data/processed/iris_clean.csv
    outs:
      - models/model.pkl
    metrics:
      - metrics/scores.json:
          cache: false

  evaluate:
    cmd: python src/models/evaluate.py
    deps:
      - src/models/evaluate.py
      - models/model.pkl
      - data/processed/iris_clean.csv
    metrics:
      - metrics/evaluation.json:
          cache: false
```

```bash
# Ejecutar pipeline
dvc repro

# Ver mÃ©tricas
dvc metrics show

# Comparar con versiÃ³n anterior
dvc metrics diff
```

---

## MÃ³dulo 06: Pipeline ML

### Ejercicio 6.1 ğŸŸ¢ - Pipeline sklearn BÃ¡sico

**Objetivo:** Crear un pipeline de preprocessing + modelo.

#### ğŸ”„ Reproducir
```python
# src/models/pipeline.py
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import pandas as pd
import joblib

def create_pipeline():
    """Crea pipeline de preprocessing + modelo."""
    
    # Definir transformadores
    numeric_features = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']
    
    preprocessor = ColumnTransformer(
        transformers=[
            ('num', StandardScaler(), numeric_features),
        ])
    
    # Pipeline completo
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))
    ])
    
    return pipeline

def train(data_path: str, model_path: str):
    """Entrena y guarda el modelo."""
    # Cargar datos
    df = pd.read_csv(data_path)
    X = df.drop('species', axis=1)
    y = df['species']
    
    # Split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=42
    )
    
    # Entrenar
    pipeline = create_pipeline()
    pipeline.fit(X_train, y_train)
    
    # Evaluar
    score = pipeline.score(X_test, y_test)
    print(f"Test accuracy: {score:.4f}")
    
    # Guardar
    joblib.dump(pipeline, model_path)
    print(f"Model saved to {model_path}")
    
    return pipeline, score

if __name__ == "__main__":
    train("data/processed/iris_clean.csv", "models/model.pkl")
```

#### ğŸš€ Extender
1. **Reto 1:** AÃ±ade validaciÃ³n cruzada al pipeline
2. **Reto 2:** Implementa bÃºsqueda de hiperparÃ¡metros con GridSearchCV
3. **Reto 3:** Crea un pipeline para datos con features categÃ³ricas y numÃ©ricas

---

### Ejercicio 6.2 ğŸ”´ - Evitar Data Leakage

**Objetivo:** Identificar y corregir data leakage.

#### ğŸ”„ Reproducir
El siguiente cÃ³digo tiene data leakage. Identifica el problema y corrÃ­gelo:

```python
# âŒ CÃ“DIGO CON LEAKAGE - CORRÃGELO
import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier

# Cargar datos
df = pd.read_csv("data.csv")
X = df.drop('target', axis=1)
y = df['target']

# Normalizar ANTES del split (LEAKAGE!)
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# Split
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2
)

# Entrenar
model = RandomForestClassifier()
model.fit(X_train, y_train)
print(f"Score: {model.score(X_test, y_test)}")
```

**Preguntas:**
1. Â¿DÃ³nde estÃ¡ el data leakage?
2. Â¿Por quÃ© es un problema?
3. Â¿CÃ³mo lo corriges?

---

## MÃ³dulo 07: MLflow

### Ejercicio 7.1 ğŸŸ¢ - Tracking BÃ¡sico

**Objetivo:** Registrar un experimento en MLflow.

#### ğŸ”„ Reproducir
```python
# src/experiments/train_with_mlflow.py
import mlflow
import mlflow.sklearn
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, f1_score

# Configurar tracking
mlflow.set_tracking_uri("mlruns")
mlflow.set_experiment("iris-classification")

# Cargar datos
iris = load_iris()
X_train, X_test, y_train, y_test = train_test_split(
    iris.data, iris.target, test_size=0.2, random_state=42
)

# Experimento
with mlflow.start_run(run_name="rf-baseline"):
    # ParÃ¡metros
    n_estimators = 100
    max_depth = 5
    
    mlflow.log_param("n_estimators", n_estimators)
    mlflow.log_param("max_depth", max_depth)
    
    # Entrenar
    model = RandomForestClassifier(
        n_estimators=n_estimators,
        max_depth=max_depth,
        random_state=42
    )
    model.fit(X_train, y_train)
    
    # Evaluar
    y_pred = model.predict(X_test)
    accuracy = accuracy_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    mlflow.log_metric("accuracy", accuracy)
    mlflow.log_metric("f1_score", f1)
    
    # Guardar modelo
    mlflow.sklearn.log_model(model, "model")
    
    print(f"Run ID: {mlflow.active_run().info.run_id}")
    print(f"Accuracy: {accuracy:.4f}")

# Ver UI
# mlflow ui --port 5000
```

#### ğŸš€ Extender
1. **Reto 1:** Compara 3 modelos diferentes en el mismo experimento
2. **Reto 2:** Usa autologging: `mlflow.sklearn.autolog()`
3. **Reto 3:** Registra un modelo en el Model Registry

---

## MÃ³dulo 08: Testing

### Ejercicio 8.1 ğŸŸ¢ - Tests Unitarios BÃ¡sicos

**Objetivo:** Escribir tests para funciones de data processing.

#### ğŸ”„ Reproducir
```python
# tests/test_data.py
import pytest
import pandas as pd
import numpy as np
from src.data.prepare import clean_data, validate_schema

class TestDataCleaning:
    """Tests para funciones de limpieza de datos."""
    
    def test_clean_data_removes_nulls(self):
        """Verifica que clean_data elimina filas con nulls."""
        df = pd.DataFrame({
            'a': [1, 2, np.nan],
            'b': [4, 5, 6]
        })
        result = clean_data(df)
        assert result.isnull().sum().sum() == 0
    
    def test_clean_data_preserves_valid_rows(self):
        """Verifica que no se eliminan filas vÃ¡lidas."""
        df = pd.DataFrame({
            'a': [1, 2, 3],
            'b': [4, 5, 6]
        })
        result = clean_data(df)
        assert len(result) == 3
    
    def test_validate_schema_correct(self):
        """Verifica schema vÃ¡lido."""
        df = pd.DataFrame({
            'feature1': [1.0, 2.0],
            'feature2': [3.0, 4.0],
            'target': [0, 1]
        })
        expected_schema = ['feature1', 'feature2', 'target']
        assert validate_schema(df, expected_schema) == True
    
    def test_validate_schema_missing_column(self):
        """Verifica que detecta columnas faltantes."""
        df = pd.DataFrame({
            'feature1': [1.0, 2.0]
        })
        expected_schema = ['feature1', 'feature2', 'target']
        with pytest.raises(ValueError):
            validate_schema(df, expected_schema)
```

```bash
# Ejecutar tests
pytest tests/test_data.py -v

# Con coverage
pytest tests/ --cov=src --cov-report=html
```

---

### Ejercicio 8.2 ğŸŸ¡ - Tests de Modelo

**Objetivo:** Escribir tests para el modelo ML.

#### ğŸ”„ Reproducir
```python
# tests/test_model.py
import pytest
import numpy as np
from sklearn.datasets import make_classification
from src.models.pipeline import create_pipeline

class TestModel:
    """Tests para el modelo ML."""
    
    @pytest.fixture
    def sample_data(self):
        """Genera datos de ejemplo."""
        X, y = make_classification(
            n_samples=100,
            n_features=4,
            n_classes=2,
            random_state=42
        )
        return X, y
    
    def test_pipeline_fits(self, sample_data):
        """Verifica que el pipeline entrena sin errores."""
        X, y = sample_data
        pipeline = create_pipeline()
        pipeline.fit(X, y)
        assert hasattr(pipeline, 'predict')
    
    def test_predictions_valid_shape(self, sample_data):
        """Verifica shape de predicciones."""
        X, y = sample_data
        pipeline = create_pipeline()
        pipeline.fit(X, y)
        predictions = pipeline.predict(X)
        assert predictions.shape == y.shape
    
    def test_predictions_valid_values(self, sample_data):
        """Verifica que predicciones son clases vÃ¡lidas."""
        X, y = sample_data
        pipeline = create_pipeline()
        pipeline.fit(X, y)
        predictions = pipeline.predict(X)
        assert set(predictions).issubset(set(y))
    
    def test_model_accuracy_above_baseline(self, sample_data):
        """Verifica que accuracy supera baseline random."""
        X, y = sample_data
        pipeline = create_pipeline()
        pipeline.fit(X, y)
        accuracy = pipeline.score(X, y)
        # Baseline para clasificaciÃ³n binaria = 0.5
        assert accuracy > 0.5
```

---

## MÃ³dulo 09: CI/CD

### Ejercicio 9.1 ğŸŸ¢ - GitHub Actions BÃ¡sico

**Objetivo:** Configurar CI bÃ¡sico con GitHub Actions.

#### ğŸ”„ Reproducir
Crea el archivo `.github/workflows/ci.yml`:

```yaml
name: CI Pipeline

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install pytest pytest-cov flake8
      
      - name: Lint with flake8
        run: |
          flake8 src/ tests/ --max-line-length=100
      
      - name: Run tests
        run: |
          pytest tests/ -v --cov=src --cov-report=xml
      
      - name: Upload coverage
        uses: codecov/codecov-action@v3
        with:
          file: ./coverage.xml
```

#### ğŸš€ Extender
1. **Reto 1:** AÃ±ade job para construir Docker image
2. **Reto 2:** AÃ±ade matriz de versiones de Python
3. **Reto 3:** Configura deploy automÃ¡tico a staging

---

## MÃ³dulo 10: Docker

### Ejercicio 10.1 ğŸŸ¢ - Dockerfile para ML

**Objetivo:** Crear un Dockerfile optimizado para modelos ML.

#### ğŸ”„ Reproducir
```dockerfile
# Dockerfile
FROM python:3.10-slim

WORKDIR /app

# Instalar dependencias del sistema
RUN apt-get update && apt-get install -y \
    gcc \
    && rm -rf /var/lib/apt/lists/*

# Copiar requirements primero (para cache)
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copiar cÃ³digo
COPY src/ ./src/
COPY models/ ./models/

# Variables de entorno
ENV PYTHONPATH=/app
ENV MODEL_PATH=/app/models/model.pkl

# Puerto
EXPOSE 8000

# Comando por defecto
CMD ["python", "-m", "src.api.main"]
```

```bash
# Build
docker build -t ml-model:v1 .

# Run
docker run -p 8000:8000 ml-model:v1

# Verificar tamaÃ±o
docker images ml-model:v1
```

#### ğŸš€ Extender
1. **Reto 1:** Reduce el tamaÃ±o de la imagen a < 500MB
2. **Reto 2:** Implementa multi-stage build
3. **Reto 3:** AÃ±ade healthcheck

---

## MÃ³dulo 11: FastAPI

### Ejercicio 11.1 ğŸŸ¢ - API REST BÃ¡sica

**Objetivo:** Crear una API para servir predicciones.

#### ğŸ”„ Reproducir
```python
# src/api/main.py
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import joblib
import numpy as np

app = FastAPI(
    title="ML Model API",
    description="API para predicciones de Iris",
    version="1.0.0"
)

# Cargar modelo
model = joblib.load("models/model.pkl")

class PredictionInput(BaseModel):
    sepal_length: float
    sepal_width: float
    petal_length: float
    petal_width: float

class PredictionOutput(BaseModel):
    prediction: str
    probability: float

@app.get("/health")
def health_check():
    return {"status": "healthy"}

@app.post("/predict", response_model=PredictionOutput)
def predict(input_data: PredictionInput):
    try:
        features = np.array([[
            input_data.sepal_length,
            input_data.sepal_width,
            input_data.petal_length,
            input_data.petal_width
        ]])
        
        prediction = model.predict(features)[0]
        probability = model.predict_proba(features).max()
        
        return PredictionOutput(
            prediction=str(prediction),
            probability=float(probability)
        )
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8000)
```

```bash
# Ejecutar
uvicorn src.api.main:app --reload

# Probar
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{"sepal_length": 5.1, "sepal_width": 3.5, "petal_length": 1.4, "petal_width": 0.2}'
```

---

## MÃ³dulo 14: Monitoreo

### Ejercicio 14.1 ğŸŸ¡ - Logging Estructurado

**Objetivo:** Implementar logging profesional.

#### ğŸ”„ Reproducir
```python
# src/utils/logger.py
import logging
import json
from datetime import datetime

class JSONFormatter(logging.Formatter):
    def format(self, record):
        log_record = {
            "timestamp": datetime.utcnow().isoformat(),
            "level": record.levelname,
            "message": record.getMessage(),
            "module": record.module,
            "function": record.funcName,
        }
        if hasattr(record, 'extra'):
            log_record.update(record.extra)
        return json.dumps(log_record)

def get_logger(name: str) -> logging.Logger:
    logger = logging.getLogger(name)
    logger.setLevel(logging.INFO)
    
    handler = logging.StreamHandler()
    handler.setFormatter(JSONFormatter())
    logger.addHandler(handler)
    
    return logger

# Uso
logger = get_logger("ml-api")
logger.info("Prediction made", extra={"model": "rf", "latency_ms": 45})
```

---

## MÃ³dulos 15-17: DocumentaciÃ³n y Demo

### Ejercicio 15.1 ğŸŸ¢ - README Profesional

**Objetivo:** Crear un README siguiendo best practices.

#### ğŸ”„ Reproducir
Usa la plantilla en [templates/README_TEMPLATE.md](templates/README_TEMPLATE.md) y completa todas las secciones para tu proyecto.

**Checklist del README:**
- [ ] TÃ­tulo y descripciÃ³n clara
- [ ] Badges (CI, coverage, license)
- [ ] Tabla de contenidos
- [ ] InstalaciÃ³n paso a paso
- [ ] Uso con ejemplos
- [ ] Estructura del proyecto
- [ ] ContribuciÃ³n
- [ ] Licencia
- [ ] Contacto

---

## Proyecto Integrador Final

### DescripciÃ³n

Desarrolla un portafolio MLOps completo desde cero que incluya:

1. **Proyecto 1:** ClasificaciÃ³n (ej: Churn Prediction)
2. **Proyecto 2:** RegresiÃ³n (ej: Price Prediction)
3. **Proyecto 3:** NLP o CV (ej: Sentiment Analysis)

### Requisitos MÃ­nimos

| Componente         | Requisito                                |
|:-------------------|:-----------------------------------------|
| Repositorio        | Estructura profesional                   |
| Versionado         | Git + DVC configurados                   |
| Pipeline           | sklearn pipeline reproducible            |
| Tracking           | MLflow con al menos 5 experimentos       |
| Testing            | > 70% coverage                           |
| CI/CD              | GitHub Actions funcional                 |
| ContainerizaciÃ³n   | Dockerfile optimizado                    |
| API                | FastAPI con /health y /predict           |
| DocumentaciÃ³n      | README + Model Card                      |
| Demo               | Video 3-5 minutos                        |

### Entrega

1. URL del repositorio GitHub pÃºblico
2. Link al video demo (YouTube/Loom)
3. Link a la documentaciÃ³n desplegada (opcional)

### EvaluaciÃ³n

Ver [RUBRICA_EVALUACION.md](RUBRICA_EVALUACION.md) para criterios detallados.

---

<div align="center">

**ğŸ“ Soluciones disponibles en:** [EJERCICIOS_SOLUCIONES.md](EJERCICIOS_SOLUCIONES.md)

[ğŸ“š Ãndice](00_INDICE.md) | [ğŸ“Š RÃºbrica](RUBRICA_EVALUACION.md) | [ğŸ“– Syllabus](SYLLABUS.md)

</div>
