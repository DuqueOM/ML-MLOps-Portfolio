# üîß Ejercicios Pr√°cticos ‚Äî Gu√≠a MLOps

> **Ejercicios organizados por m√≥dulo para practicar cada concepto**

---

## üìã √çndice de Ejercicios

| M√≥dulo | Tema | Dificultad |
|:-------|:-----|:----------:|
| 01 | Python Moderno | ‚≠ê‚≠ê |
| 07 | sklearn Pipelines | ‚≠ê‚≠ê‚≠ê |
| 08 | Feature Engineering | ‚≠ê‚≠ê‚≠ê |
| 11 | Testing ML | ‚≠ê‚≠ê‚≠ê |
| 12 | CI/CD | ‚≠ê‚≠ê |
| 13 | Docker | ‚≠ê‚≠ê |
| 14 | FastAPI | ‚≠ê‚≠ê‚≠ê |

---

## üìù M√≥dulo 01: Python Moderno

### Ejercicio 1.1: Type Hints
**Objetivo**: A√±adir type hints a funciones existentes.

```python
# ANTES (sin tipos)
def load_data(path):
    return pd.read_csv(path)

def train_model(X, y, params):
    model = RandomForestClassifier(**params)
    return model.fit(X, y)

# TU TAREA: A√±adir type hints completos
# Hint: usa pd.DataFrame, np.ndarray, dict[str, Any]
```

### Ejercicio 1.2: Pydantic Config
**Objetivo**: Crear configuraci√≥n validada con Pydantic.

```python
# Crear una clase ModelConfig que valide:
# - n_estimators: int entre 10 y 500
# - max_depth: int opcional, entre 1 y 50
# - random_state: int, default 42

# TU C√ìDIGO AQU√ç
from pydantic import BaseModel, Field

class ModelConfig(BaseModel):
    # ...
    pass
```

### Ejercicio 1.3: src/ Layout
**Objetivo**: Reorganizar c√≥digo en estructura profesional.

```
# Dado este c√≥digo en un solo archivo main.py:
# - load_data()
# - preprocess()
# - train()
# - predict()
# - FastAPI app

# TU TAREA: Crear estructura src/ con:
# src/myproject/data.py
# src/myproject/training.py
# src/myproject/prediction.py
# app/fastapi_app.py
```

---

## üìù M√≥dulo 07: sklearn Pipelines

### Ejercicio 7.1: Pipeline B√°sico
**Objetivo**: Crear un pipeline con preprocesamiento.

```python
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier

# TU TAREA: Crear pipeline con:
# 1. StandardScaler para features num√©ricas
# 2. RandomForestClassifier

pipe = Pipeline([
    # TU C√ìDIGO
])
```

### Ejercicio 7.2: ColumnTransformer
**Objetivo**: Procesar columnas num√©ricas y categ√≥ricas por separado.

```python
# Dado un DataFrame con:
# - numeric_cols = ['age', 'balance', 'salary']
# - categorical_cols = ['geography', 'gender']

# TU TAREA: Crear ColumnTransformer que:
# - Aplique StandardScaler a num√©ricas
# - Aplique OneHotEncoder a categ√≥ricas

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

preprocessor = ColumnTransformer([
    # TU C√ìDIGO
])
```

### Ejercicio 7.3: Custom Transformer
**Objetivo**: Crear un transformer personalizado.

```python
from sklearn.base import BaseEstimator, TransformerMixin

# TU TAREA: Crear AgeGroupTransformer que:
# - A√±ada columna 'age_group' basada en rangos de edad
# - 0-30: 'young', 31-50: 'middle', 51+: 'senior'

class AgeGroupTransformer(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None):
        # TU C√ìDIGO
        return self
    
    def transform(self, X):
        # TU C√ìDIGO
        pass
```

---

## üìù M√≥dulo 08: Feature Engineering

### Ejercicio 8.1: Detectar Data Leakage
**Objetivo**: Identificar leakage en un pipeline.

```python
# C√ìDIGO CON LEAKAGE - Encuentra los 3 errores:

df = pd.read_csv('data.csv')

# Error 1: ¬øD√≥nde est√°?
df['price_category'] = pd.cut(df['price'], bins=3, labels=['low', 'mid', 'high'])

# Error 2: ¬øD√≥nde est√°?
scaler = StandardScaler()
df[numeric_cols] = scaler.fit_transform(df[numeric_cols])

X_train, X_test, y_train, y_test = train_test_split(df.drop('target', axis=1), df['target'])

# Error 3: ¬øD√≥nde est√°?
model = RandomForestClassifier()
model.fit(X_train, y_train)
```

### Ejercicio 8.2: Pipeline Sin Leakage
**Objetivo**: Reescribir el c√≥digo anterior sin leakage.

```python
# TU TAREA: Reescribir el ejercicio 8.1 sin data leakage
# Hint: El scaler debe estar DENTRO del pipeline
# Hint: No crear features basadas en el target antes del split
```

---

## üìù M√≥dulo 11: Testing ML

### Ejercicio 11.1: Test de Datos
**Objetivo**: Escribir tests para validar datos.

```python
# TU TAREA: Escribir tests que verifiquen:
# 1. No hay valores nulos en columnas cr√≠ticas
# 2. Valores de 'age' est√°n entre 18 y 100
# 3. 'target' solo contiene 0 y 1

import pytest

def test_no_nulls(sample_data):
    # TU C√ìDIGO
    pass

def test_age_range(sample_data):
    # TU C√ìDIGO
    pass

def test_target_binary(sample_data):
    # TU C√ìDIGO
    pass
```

### Ejercicio 11.2: Test de Modelo
**Objetivo**: Testear que el modelo funciona correctamente.

```python
# TU TAREA: Escribir tests que verifiquen:
# 1. El modelo puede hacer fit sin errores
# 2. Las predicciones tienen el shape correcto
# 3. El accuracy es mayor que un baseline (ej: 0.5)

def test_model_fit(trained_model, sample_data):
    # TU C√ìDIGO
    pass

def test_predictions_shape(trained_model, sample_data):
    # TU C√ìDIGO
    pass

def test_accuracy_above_baseline(trained_model, sample_data):
    # TU C√ìDIGO
    pass
```

### Ejercicio 11.3: Fixture con conftest.py
**Objetivo**: Crear fixtures reutilizables.

```python
# tests/conftest.py

import pytest
import pandas as pd

# TU TAREA: Crear fixtures para:
# 1. sample_data: DataFrame con datos de prueba
# 2. trained_model: Modelo ya entrenado
# 3. config: Configuraci√≥n de prueba

@pytest.fixture
def sample_data():
    # TU C√ìDIGO
    pass

@pytest.fixture
def trained_model(sample_data):
    # TU C√ìDIGO
    pass
```

---

## üìù M√≥dulo 12: CI/CD

### Ejercicio 12.1: GitHub Actions B√°sico
**Objetivo**: Crear workflow de CI.

```yaml
# .github/workflows/ci.yml

# TU TAREA: Crear workflow que:
# 1. Se ejecute en push y PR a main
# 2. Use Python 3.11
# 3. Instale dependencias
# 4. Ejecute tests con coverage
# 5. Falle si coverage < 80%

name: CI

on:
  # TU C√ìDIGO

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      # TU C√ìDIGO
```

---

## üìù M√≥dulo 13: Docker

### Ejercicio 13.1: Dockerfile Multi-stage
**Objetivo**: Crear Dockerfile optimizado.

```dockerfile
# TU TAREA: Crear Dockerfile que:
# 1. Use multi-stage build
# 2. Stage 1: instalar dependencias
# 3. Stage 2: copiar solo lo necesario
# 4. Use usuario non-root
# 5. Exponga puerto 8000

# Stage 1: Builder
FROM python:3.11-slim AS builder
# TU C√ìDIGO

# Stage 2: Runtime
FROM python:3.11-slim
# TU C√ìDIGO
```

---

## üìù M√≥dulo 14: FastAPI

### Ejercicio 14.1: Schemas Pydantic
**Objetivo**: Crear schemas de request/response.

```python
# TU TAREA: Crear schemas para API de predicci√≥n

from pydantic import BaseModel, Field

class PredictionRequest(BaseModel):
    # Features del modelo
    # TU C√ìDIGO
    pass

class PredictionResponse(BaseModel):
    # prediction: int
    # probability: float
    # TU C√ìDIGO
    pass
```

### Ejercicio 14.2: Endpoint de Predicci√≥n
**Objetivo**: Implementar /predict endpoint.

```python
from fastapi import FastAPI, HTTPException

app = FastAPI()

# TU TAREA: Implementar endpoint que:
# 1. Reciba PredictionRequest
# 2. Valide los datos
# 3. Haga predicci√≥n con modelo cargado
# 4. Retorne PredictionResponse
# 5. Maneje errores con HTTPException

@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    # TU C√ìDIGO
    pass
```

---

## ‚úÖ Soluciones

Ver [EJERCICIOS_SOLUCIONES.md](EJERCICIOS_SOLUCIONES.md) para las soluciones detalladas.

---

<div align="center">

[‚Üê Volver al √çndice](00_INDICE.md)

</div>
