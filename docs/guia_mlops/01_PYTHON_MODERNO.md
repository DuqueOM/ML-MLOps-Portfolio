# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 01: PYTHON MODERNO PARA MLOps
# El Puente de Scripter a Ingeniero de Software
# GuÃ­a MLOps v5.0: Senior Edition | DuqueOM | Noviembre 2025
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

<div align="center">

# ğŸ MÃ“DULO 01: Python Moderno para MLOps

### De Scripts que "Funcionan" a CÃ³digo que Pasa Code Review

*"La diferencia entre un Junior y un Senior no es la complejidad del algoritmo,*
*es la calidad del cÃ³digo que lo rodea."*

| DuraciÃ³n             | TeorÃ­a               | PrÃ¡ctica             |
| :------------------: | :------------------: | :------------------: |
| **6-8 horas**        | 30%                  | 70%                  |

</div>

---

## ğŸ¯ Por QuÃ© Este MÃ³dulo Existe

### El Problema

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         âš ï¸ LA BRECHA DEL INGENIERO                            â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   Data Scientist tÃ­pico:                                                      â•‘
â•‘   âœ… Sabe ML (sklearn, pandas, etc.)                                          â•‘
â•‘   âœ… Sabe Python bÃ¡sico (funciones, loops, clases simples)                    â•‘
â•‘   âŒ NO sabe estructurar cÃ³digo en paquetes                                   â•‘
â•‘   âŒ NO usa type hints (mypy lo odia)                                         â•‘
â•‘   âŒ NO valida inputs con Pydantic                                            â•‘
â•‘   âŒ NO aplica principios SOLID                                               â•‘
â•‘                                                                               â•‘
â•‘   RESULTADO: CÃ³digo que funciona en notebooks pero es                         â•‘
â•‘              IMPOSIBLE de mantener, testear o escalar.                        â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Lo Que LograrÃ¡s en Este MÃ³dulo

Al terminar, tu cÃ³digo:
1. **PasarÃ¡ mypy** sin errores (tipado estÃ¡tico)
2. **ValidarÃ¡ inputs** automÃ¡ticamente (Pydantic)
3. **SerÃ¡ instalable** como paquete (`pip install -e .`)
4. **SeguirÃ¡ SOLID** (especialmente Single Responsibility y Dependency Injection)
5. **TendrÃ¡ estructura profesional** (src layout)

---

## 1.1 Type Hints: Tu Contrato con el Futuro

### Â¿Por QuÃ© Tipar?

```python
# âŒ ANTES: Â¿QuÃ© recibe? Â¿QuÃ© retorna? ğŸ¤·
def process_data(data, config):
    # ... 200 lÃ­neas despuÃ©s ...
    return result

# âœ… DESPUÃ‰S: Contrato claro, IDE autocompleta, errores detectados ANTES de ejecutar
def process_data(data: pd.DataFrame, config: TrainingConfig) -> ProcessedData:
    # ... 200 lÃ­neas despuÃ©s ...
    return result
```

### Los Tipos Esenciales para ML

```python
from typing import (
    List, Dict, Tuple, Optional, Union,
    Any, Callable, TypeVar, Generic,
    Literal, TypedDict
)
from pathlib import Path
import pandas as pd
import numpy as np
from numpy.typing import NDArray

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS BÃSICOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Primitivos
name: str = "BankChurn"
n_estimators: int = 100
learning_rate: float = 0.01
is_trained: bool = False

# Colecciones
features: List[str] = ["age", "balance", "tenure"]
params: Dict[str, Any] = {"n_estimators": 100, "max_depth": 5}
shape: Tuple[int, int] = (1000, 10)

# Optional = puede ser None
model_path: Optional[Path] = None  # Path | None en Python 3.10+

# Union = mÃºltiples tipos posibles
target: Union[str, List[str]] = "Exited"  # str | List[str] en 3.10+

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS PARA ML
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# DataFrames (pandas-stubs requerido para mypy)
def load_data(path: Path) -> pd.DataFrame:
    return pd.read_csv(path)

# Arrays NumPy
def compute_predictions(X: NDArray[np.float64]) -> NDArray[np.float64]:
    return model.predict_proba(X)[:, 1]

# Literal = valores especÃ­ficos permitidos
ModelType = Literal["random_forest", "logistic", "xgboost"]

def train_model(model_type: ModelType) -> BaseEstimator:
    if model_type == "random_forest":
        return RandomForestClassifier()
    # mypy SABE que model_type solo puede ser estos 3 valores

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIPOS AVANZADOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# TypedDict = diccionarios con estructura conocida
class MetricsDict(TypedDict):
    auc_roc: float
    precision: float
    recall: float
    f1: float

def evaluate(y_true: NDArray, y_pred: NDArray) -> MetricsDict:
    return {
        "auc_roc": roc_auc_score(y_true, y_pred),
        "precision": precision_score(y_true, y_pred),
        "recall": recall_score(y_true, y_pred),
        "f1": f1_score(y_true, y_pred),
    }

# Generic + TypeVar = funciones que preservan tipos
T = TypeVar("T", bound=BaseEstimator)

def clone_and_fit(model: T, X: NDArray, y: NDArray) -> T:
    """Clona el modelo, lo entrena, y retorna el mismo tipo."""
    cloned = clone(model)
    cloned.fit(X, y)
    return cloned  # mypy sabe que retorna el mismo tipo que entrÃ³
```

### Configurar mypy para ML

```toml
# pyproject.toml
[tool.mypy]
python_version = "3.11"
warn_return_any = true
warn_unused_ignores = true
disallow_untyped_defs = true
ignore_missing_imports = true  # Para librerÃ­as sin stubs (sklearn, etc.)

[[tool.mypy.overrides]]
module = [
    "sklearn.*",
    "pandas.*",
    "numpy.*",
    "mlflow.*",
]
ignore_missing_imports = true
```

### Ejercicio 1.1: Tipar una FunciÃ³n Real

```python
# âŒ CÃ³digo sin tipos (tÃ­pico de notebooks)
def prepare_features(df, num_cols, cat_cols, target):
    X = df.drop(columns=[target])
    y = df[target]
    
    preprocessor = ColumnTransformer([
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(), cat_cols)
    ])
    
    X_transformed = preprocessor.fit_transform(X)
    return X_transformed, y, preprocessor

# âœ… TU TAREA: AÃ±ade type hints completos
# Pista: usa NDArray, pd.DataFrame, List[str], ColumnTransformer, etc.
```

<details>
<summary>ğŸ“ Ver SoluciÃ³n</summary>

```python
from typing import Tuple, List
import pandas as pd
import numpy as np
from numpy.typing import NDArray
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder

def prepare_features(
    df: pd.DataFrame,
    num_cols: List[str],
    cat_cols: List[str],
    target: str
) -> Tuple[NDArray[np.float64], pd.Series, ColumnTransformer]:
    """
    Prepara features para entrenamiento.
    
    Args:
        df: DataFrame con datos crudos
        num_cols: Columnas numÃ©ricas a escalar
        cat_cols: Columnas categÃ³ricas a encodear
        target: Nombre de la columna objetivo
        
    Returns:
        Tuple con (X transformado, y, preprocessor ajustado)
    """
    X = df.drop(columns=[target])
    y = df[target]
    
    preprocessor = ColumnTransformer([
        ('num', StandardScaler(), num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)
    ])
    
    X_transformed: NDArray[np.float64] = preprocessor.fit_transform(X)
    return X_transformed, y, preprocessor
```
</details>

---

## 1.2 Pydantic: ValidaciÃ³n de Datos que No Perdona

### El Problema de Configs sin Validar

```python
# âŒ ANTES: Diccionario sin validaciÃ³n
config = {
    "n_estimators": "100",  # Oops, es string
    "max_depth": -5,        # Valor invÃ¡lido
    "random_state": None,   # Â¿Es intencional?
    # "learning_rate" falta
}

model = RandomForestClassifier(**config)  # BOOM en runtime ğŸ’¥
```

### Pydantic al Rescate

```python
from pydantic import BaseModel, Field, field_validator, model_validator
from typing import Literal, Optional
from pathlib import Path

class ModelConfig(BaseModel):
    """ConfiguraciÃ³n validada para modelos de clasificaciÃ³n."""
    
    # Campos con valores por defecto y restricciones
    n_estimators: int = Field(
        default=100,
        ge=10,      # >= 10
        le=1000,    # <= 1000
        description="NÃºmero de Ã¡rboles en el ensemble"
    )
    
    max_depth: Optional[int] = Field(
        default=None,
        ge=1,
        le=50,
        description="Profundidad mÃ¡xima. None = sin lÃ­mite"
    )
    
    learning_rate: float = Field(
        default=0.1,
        gt=0,       # > 0
        le=1,       # <= 1
    )
    
    model_type: Literal["random_forest", "xgboost", "lightgbm"] = "random_forest"
    
    random_state: int = Field(default=42, description="Seed para reproducibilidad")
    
    # Validador personalizado
    @field_validator("n_estimators")
    @classmethod
    def validate_n_estimators(cls, v: int) -> int:
        if v < 10:
            raise ValueError("n_estimators debe ser >= 10 para resultados estables")
        return v
    
    # Validador que usa mÃºltiples campos
    @model_validator(mode="after")
    def validate_model_params(self) -> "ModelConfig":
        if self.model_type == "xgboost" and self.learning_rate > 0.3:
            raise ValueError("XGBoost funciona mejor con learning_rate <= 0.3")
        return self


class DataConfig(BaseModel):
    """ConfiguraciÃ³n para rutas de datos."""
    
    raw_data_path: Path
    processed_data_path: Path
    model_output_path: Path = Path("models/")
    
    target_column: str = "Exited"
    test_size: float = Field(default=0.2, ge=0.1, le=0.5)
    
    @field_validator("raw_data_path")
    @classmethod
    def validate_raw_path_exists(cls, v: Path) -> Path:
        if not v.exists():
            raise ValueError(f"El archivo de datos no existe: {v}")
        return v


class TrainingConfig(BaseModel):
    """ConfiguraciÃ³n completa de entrenamiento."""
    
    model: ModelConfig = Field(default_factory=ModelConfig)
    data: DataConfig
    
    experiment_name: str = "bankchurn"
    run_name: Optional[str] = None
    
    class Config:
        # Permite crear desde archivo YAML/JSON
        extra = "forbid"  # Error si hay campos desconocidos
```

### Uso en la PrÃ¡ctica

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CARGAR DESDE YAML
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import yaml

# configs/config.yaml
"""
model:
  n_estimators: 200
  max_depth: 10
  model_type: random_forest

data:
  raw_data_path: data/raw/churn.csv
  processed_data_path: data/processed/
  target_column: Exited
  test_size: 0.2

experiment_name: bankchurn-v2
"""

def load_config(path: Path) -> TrainingConfig:
    """Carga y valida configuraciÃ³n desde YAML."""
    with open(path) as f:
        raw_config = yaml.safe_load(f)
    
    # Pydantic valida automÃ¡ticamente
    return TrainingConfig(**raw_config)

# Si hay CUALQUIER error de validaciÃ³n, Pydantic lo detecta
config = load_config(Path("configs/config.yaml"))

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTEGRACIÃ“N CON CLI (typer + pydantic)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
import typer
from typing import Annotated

app = typer.Typer()

@app.command()
def train(
    config_path: Annotated[Path, typer.Argument(help="Ruta al config YAML")],
    override_n_estimators: Annotated[Optional[int], typer.Option("--n-estimators")] = None,
):
    """Entrena el modelo con configuraciÃ³n validada."""
    config = load_config(config_path)
    
    # Override desde CLI si se proporciona
    if override_n_estimators:
        config.model.n_estimators = override_n_estimators
    
    trainer = ChurnTrainer(config)
    trainer.run()
```

### Pydantic para Validar Requests de API

```python
from pydantic import BaseModel, Field
from typing import Optional
from fastapi import FastAPI

class PredictionRequest(BaseModel):
    """Request para predicciÃ³n de churn."""
    
    credit_score: int = Field(..., ge=300, le=850, description="Score crediticio")
    age: int = Field(..., ge=18, le=100)
    tenure: int = Field(..., ge=0, le=50, description="AÃ±os como cliente")
    balance: float = Field(..., ge=0)
    num_of_products: int = Field(..., ge=1, le=4)
    has_cr_card: bool
    is_active_member: bool
    estimated_salary: float = Field(..., ge=0)
    geography: Literal["France", "Germany", "Spain"]
    gender: Literal["Male", "Female"]
    
    class Config:
        json_schema_extra = {
            "example": {
                "credit_score": 650,
                "age": 35,
                "tenure": 5,
                "balance": 50000.0,
                "num_of_products": 2,
                "has_cr_card": True,
                "is_active_member": True,
                "estimated_salary": 75000.0,
                "geography": "France",
                "gender": "Female"
            }
        }


class PredictionResponse(BaseModel):
    """Response de predicciÃ³n."""
    
    churn_probability: float = Field(..., ge=0, le=1)
    prediction: Literal["churn", "no_churn"]
    confidence: float = Field(..., ge=0, le=1)
    model_version: str


app = FastAPI(title="BankChurn API")

@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest) -> PredictionResponse:
    # FastAPI + Pydantic validan automÃ¡ticamente el input
    # Si el JSON no cumple el schema, retorna 422 con detalles del error
    ...
```

---

## 1.3 Estructura de Paquetes: El `src/` Layout

### El Problema del "Script Spaghetti"

```
âŒ ESTRUCTURA TÃPICA DE DATA SCIENTIST:

project/
â”œâ”€â”€ train_model_v2_final.py
â”œâ”€â”€ train_model_v2_final_REAL.py
â”œâ”€â”€ utils.py
â”œâ”€â”€ utils_new.py
â”œâ”€â”€ notebook_exploration.ipynb
â”œâ”€â”€ notebook_final.ipynb
â”œâ”€â”€ data/
â””â”€â”€ requirements.txt

PROBLEMAS:
- Â¿CuÃ¡l es el archivo correcto?
- Â¿CÃ³mo importo `utils.py` desde otro directorio?
- No es instalable con pip
- Tests no encuentran los mÃ³dulos
```

### La Estructura Profesional: `src/` Layout

```
âœ… ESTRUCTURA PROFESIONAL:

bankchurn-predictor/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ bankchurn/                 # ğŸ“¦ El paquete instalable
â”‚       â”œâ”€â”€ __init__.py            # Expone API pÃºblica
â”‚       â”œâ”€â”€ config.py              # ConfiguraciÃ³n Pydantic
â”‚       â”œâ”€â”€ data/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ loader.py          # Carga de datos
â”‚       â”‚   â””â”€â”€ preprocessing.py   # Transformaciones
â”‚       â”œâ”€â”€ models/
â”‚       â”‚   â”œâ”€â”€ __init__.py
â”‚       â”‚   â”œâ”€â”€ trainer.py         # Clase ChurnTrainer
â”‚       â”‚   â””â”€â”€ inference.py       # PredicciÃ³n
â”‚       â””â”€â”€ utils/
â”‚           â”œâ”€â”€ __init__.py
â”‚           â”œâ”€â”€ logger.py
â”‚           â””â”€â”€ metrics.py
â”‚
â”œâ”€â”€ app/
â”‚   â””â”€â”€ fastapi_app.py             # ğŸŒ API (no es parte del paquete)
â”‚
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ conftest.py                # Fixtures de pytest
â”‚   â”œâ”€â”€ unit/
â”‚   â”‚   â”œâ”€â”€ test_config.py
â”‚   â”‚   â””â”€â”€ test_preprocessing.py
â”‚   â””â”€â”€ integration/
â”‚       â””â”€â”€ test_pipeline.py
â”‚
â”œâ”€â”€ notebooks/                     # ğŸ““ Solo para exploraciÃ³n
â”‚   â””â”€â”€ 01_eda.ipynb
â”‚
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                       # DVC-tracked
â”‚   â””â”€â”€ processed/
â”‚
â”œâ”€â”€ pyproject.toml                 # ğŸ“„ ConfiguraciÃ³n moderna
â”œâ”€â”€ Makefile
â””â”€â”€ README.md
```

### `pyproject.toml` Moderno (reemplaza setup.py)

```toml
[build-system]
requires = ["setuptools>=61.0", "wheel"]
build-backend = "setuptools.build_meta"

[project]
name = "bankchurn"
version = "0.1.0"
description = "Predictor de churn bancario con MLOps completo"
readme = "README.md"
license = {text = "MIT"}
authors = [
    {name = "Tu Nombre", email = "tu@email.com"}
]
requires-python = ">=3.10"

dependencies = [
    "pandas>=2.0.0",
    "scikit-learn>=1.3.0",
    "pydantic>=2.0.0",
    "pyyaml>=6.0",
    "mlflow>=2.8.0",
    "fastapi>=0.104.0",
    "uvicorn>=0.24.0",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-cov>=4.1.0",
    "mypy>=1.6.0",
    "ruff>=0.1.0",
    "pre-commit>=3.5.0",
]
docs = [
    "mkdocs>=1.5.0",
    "mkdocs-material>=9.4.0",
]

[project.scripts]
# CLI commands
bankchurn-train = "bankchurn.cli:train"
bankchurn-predict = "bankchurn.cli:predict"

[tool.setuptools.packages.find]
where = ["src"]

[tool.ruff]
line-length = 100
select = ["E", "F", "I", "W", "B", "C4", "UP"]
ignore = ["E501"]  # Line too long (handled by formatter)

[tool.pytest.ini_options]
testpaths = ["tests"]
addopts = "-v --cov=src/bankchurn --cov-report=term-missing"

[tool.mypy]
python_version = "3.11"
warn_return_any = true
disallow_untyped_defs = true
ignore_missing_imports = true
```

### `__init__.py` que Expone API PÃºblica

```python
# src/bankchurn/__init__.py
"""
BankChurn Predictor
==================

Un sistema MLOps completo para predicciÃ³n de churn bancario.

Uso bÃ¡sico:
    from bankchurn import ChurnTrainer, TrainingConfig
    
    config = TrainingConfig.from_yaml("configs/config.yaml")
    trainer = ChurnTrainer(config)
    trainer.run()
"""

from bankchurn.config import TrainingConfig, ModelConfig, DataConfig
from bankchurn.models.trainer import ChurnTrainer
from bankchurn.models.inference import ChurnPredictor

__version__ = "0.1.0"
__all__ = [
    "TrainingConfig",
    "ModelConfig", 
    "DataConfig",
    "ChurnTrainer",
    "ChurnPredictor",
    "__version__",
]
```

### InstalaciÃ³n en Modo Editable

```bash
# Desde la raÃ­z del proyecto
pip install -e ".[dev]"

# Ahora puedes importar desde cualquier lugar:
from bankchurn import ChurnTrainer, TrainingConfig

# Y ejecutar CLI:
bankchurn-train configs/config.yaml
```

---

## 1.4 OOP para ML: Patrones que Funcionan

### El Anti-PatrÃ³n: Funciones Sueltas

```python
# âŒ ANTI-PATRÃ“N: Todo son funciones sueltas que dependen de globals
RANDOM_STATE = 42
MODEL_PATH = "models/model.pkl"

def load_data():
    global data  # ğŸ˜±
    data = pd.read_csv("data/raw/churn.csv")

def preprocess():
    global X, y  # ğŸ˜±ğŸ˜±
    X = data.drop("Exited", axis=1)
    y = data["Exited"]

def train():
    global model  # ğŸ˜±ğŸ˜±ğŸ˜±
    model = RandomForestClassifier(random_state=RANDOM_STATE)
    model.fit(X, y)
    joblib.dump(model, MODEL_PATH)

# PROBLEMAS:
# - Estado global = bugs difÃ­ciles de encontrar
# - Imposible de testear unitariamente
# - No puedes tener 2 configuraciones simultÃ¡neas
```

### El PatrÃ³n Correcto: Trainer Class

```python
# âœ… PATRÃ“N PROFESIONAL: Clases con Dependency Injection
from dataclasses import dataclass, field
from pathlib import Path
from typing import Optional, Protocol
import pandas as pd
import numpy as np
from sklearn.base import BaseEstimator, clone
from sklearn.model_selection import train_test_split
import joblib
import mlflow

from bankchurn.config import TrainingConfig
from bankchurn.data.preprocessing import FeatureEngineer


class DataLoader(Protocol):
    """Protocolo para cargadores de datos (Dependency Injection)."""
    def load(self) -> pd.DataFrame: ...


class CSVDataLoader:
    """ImplementaciÃ³n concreta para CSV."""
    def __init__(self, path: Path):
        self.path = path
    
    def load(self) -> pd.DataFrame:
        return pd.read_csv(self.path)


@dataclass
class ChurnTrainer:
    """
    Trainer para modelos de churn prediction.
    
    Sigue el principio de Single Responsibility:
    - Orquesta el entrenamiento
    - Delega preprocesamiento a FeatureEngineer
    - Delega tracking a MLflow
    
    Ejemplo:
        config = TrainingConfig.from_yaml("configs/config.yaml")
        trainer = ChurnTrainer(config)
        metrics = trainer.run()
    """
    
    config: TrainingConfig
    data_loader: Optional[DataLoader] = None
    _model: Optional[BaseEstimator] = field(default=None, init=False)
    _feature_engineer: Optional[FeatureEngineer] = field(default=None, init=False)
    
    def __post_init__(self):
        """Inicializa dependencias si no se inyectaron."""
        if self.data_loader is None:
            self.data_loader = CSVDataLoader(self.config.data.raw_data_path)
        
        self._feature_engineer = FeatureEngineer(
            num_features=self.config.data.numerical_features,
            cat_features=self.config.data.categorical_features,
        )
    
    def load_data(self) -> pd.DataFrame:
        """Carga datos usando el loader inyectado."""
        return self.data_loader.load()
    
    def prepare_data(
        self, 
        df: pd.DataFrame
    ) -> tuple[np.ndarray, np.ndarray, np.ndarray, np.ndarray]:
        """Prepara datos para entrenamiento."""
        X = df.drop(columns=[self.config.data.target_column])
        y = df[self.config.data.target_column].values
        
        return train_test_split(
            X, y,
            test_size=self.config.data.test_size,
            random_state=self.config.model.random_state,
            stratify=y
        )
    
    def train(
        self, 
        X_train: np.ndarray, 
        y_train: np.ndarray
    ) -> BaseEstimator:
        """Entrena el pipeline completo."""
        from sklearn.pipeline import Pipeline
        
        # Pipeline = FeatureEngineer + Modelo
        pipeline = Pipeline([
            ('features', self._feature_engineer.get_transformer()),
            ('model', self._build_model())
        ])
        
        pipeline.fit(X_train, y_train)
        self._model = pipeline
        return pipeline
    
    def _build_model(self) -> BaseEstimator:
        """Construye el modelo segÃºn configuraciÃ³n."""
        if self.config.model.model_type == "random_forest":
            from sklearn.ensemble import RandomForestClassifier
            return RandomForestClassifier(
                n_estimators=self.config.model.n_estimators,
                max_depth=self.config.model.max_depth,
                random_state=self.config.model.random_state,
                class_weight='balanced',
                n_jobs=-1,
            )
        # ... otros modelos
        raise ValueError(f"Modelo no soportado: {self.config.model.model_type}")
    
    def evaluate(
        self, 
        X_test: np.ndarray, 
        y_test: np.ndarray
    ) -> dict[str, float]:
        """EvalÃºa el modelo y retorna mÃ©tricas."""
        from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score
        
        y_pred = self._model.predict(X_test)
        y_proba = self._model.predict_proba(X_test)[:, 1]
        
        return {
            "auc_roc": roc_auc_score(y_test, y_proba),
            "precision": precision_score(y_test, y_pred),
            "recall": recall_score(y_test, y_pred),
            "f1": f1_score(y_test, y_pred),
        }
    
    def save_model(self, path: Optional[Path] = None) -> Path:
        """Guarda el modelo entrenado."""
        path = path or self.config.data.model_output_path / "pipeline.pkl"
        path.parent.mkdir(parents=True, exist_ok=True)
        joblib.dump(self._model, path)
        return path
    
    def run(self) -> dict[str, float]:
        """
        Ejecuta el pipeline completo de entrenamiento.
        
        Returns:
            Diccionario con mÃ©tricas de evaluaciÃ³n.
        """
        # MLflow tracking
        mlflow.set_experiment(self.config.experiment_name)
        
        with mlflow.start_run(run_name=self.config.run_name):
            # Log config
            mlflow.log_params(self.config.model.model_dump())
            
            # Pipeline
            df = self.load_data()
            X_train, X_test, y_train, y_test = self.prepare_data(df)
            self.train(X_train, y_train)
            metrics = self.evaluate(X_test, y_test)
            
            # Log metrics
            mlflow.log_metrics(metrics)
            
            # Save artifacts
            model_path = self.save_model()
            mlflow.log_artifact(str(model_path))
            
            return metrics
```

### Uso del Trainer

```python
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# USO BÃSICO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from bankchurn import ChurnTrainer, TrainingConfig

config = TrainingConfig.from_yaml("configs/config.yaml")
trainer = ChurnTrainer(config)
metrics = trainer.run()
print(f"AUC-ROC: {metrics['auc_roc']:.4f}")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CON DEPENDENCY INJECTION (para tests)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
class MockDataLoader:
    """Mock para tests unitarios."""
    def load(self) -> pd.DataFrame:
        return pd.DataFrame({
            "feature1": [1, 2, 3, 4, 5],
            "feature2": ["a", "b", "a", "b", "a"],
            "Exited": [0, 1, 0, 1, 0]
        })

# En test
def test_trainer_with_mock_data():
    config = TrainingConfig(...)
    mock_loader = MockDataLoader()
    
    trainer = ChurnTrainer(config, data_loader=mock_loader)
    metrics = trainer.run()
    
    assert "auc_roc" in metrics
    assert 0 <= metrics["auc_roc"] <= 1
```

---

## 1.5 Decoradores Ãštiles para ML

### Decoradores Esenciales

```python
from functools import wraps
from time import perf_counter
from typing import Callable, TypeVar, ParamSpec
import logging

P = ParamSpec("P")
R = TypeVar("R")

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TIMING: Medir tiempo de ejecuciÃ³n
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def timer(func: Callable[P, R]) -> Callable[P, R]:
    """Loguea el tiempo de ejecuciÃ³n de una funciÃ³n."""
    @wraps(func)
    def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:
        start = perf_counter()
        result = func(*args, **kwargs)
        elapsed = perf_counter() - start
        logging.info(f"{func.__name__} took {elapsed:.2f}s")
        return result
    return wrapper


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# RETRY: Reintentar en caso de fallo
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
def retry(max_attempts: int = 3, delay: float = 1.0):
    """Reintenta una funciÃ³n N veces antes de fallar."""
    def decorator(func: Callable[P, R]) -> Callable[P, R]:
        @wraps(func)
        def wrapper(*args: P.args, **kwargs: P.kwargs) -> R:
            last_exception = None
            for attempt in range(max_attempts):
                try:
                    return func(*args, **kwargs)
                except Exception as e:
                    last_exception = e
                    logging.warning(
                        f"{func.__name__} failed (attempt {attempt + 1}/{max_attempts}): {e}"
                    )
                    if attempt < max_attempts - 1:
                        import time
                        time.sleep(delay)
            raise last_exception
        return wrapper
    return decorator


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CACHE DE DATOS (Ãºtil para cargas pesadas)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
from functools import lru_cache
import hashlib

def cache_dataframe(func: Callable[P, pd.DataFrame]) -> Callable[P, pd.DataFrame]:
    """
    Cachea DataFrames basado en los argumentos.
    Ãštil para evitar recargar datos en desarrollo.
    """
    cache: dict[str, pd.DataFrame] = {}
    
    @wraps(func)
    def wrapper(*args: P.args, **kwargs: P.kwargs) -> pd.DataFrame:
        # Crear key Ãºnica basada en argumentos
        key = hashlib.md5(
            str((args, sorted(kwargs.items()))).encode()
        ).hexdigest()
        
        if key not in cache:
            cache[key] = func(*args, **kwargs)
            logging.info(f"Cached result for {func.__name__}")
        else:
            logging.info(f"Using cached result for {func.__name__}")
        
        return cache[key].copy()  # Retornar copia para evitar mutaciones
    
    wrapper.clear_cache = lambda: cache.clear()  # type: ignore
    return wrapper


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# USO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
@timer
@cache_dataframe
def load_training_data(path: Path) -> pd.DataFrame:
    """Carga datos de entrenamiento (cacheado)."""
    return pd.read_csv(path)

@retry(max_attempts=3, delay=2.0)
def download_from_s3(bucket: str, key: str) -> bytes:
    """Descarga archivo de S3 con reintentos."""
    import boto3
    s3 = boto3.client('s3')
    response = s3.get_object(Bucket=bucket, Key=key)
    return response['Body'].read()
```

---

## 1.6 Ejercicio Integrador: Refactorizar un Script

### CÃ³digo Original (TÃ­pico de Notebook)

```python
# âŒ train_model.py - CÃ³digo tÃ­pico de Data Scientist
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.metrics import roc_auc_score
import joblib

# ConfiguraciÃ³n hardcodeada
DATA_PATH = "/home/usuario/data/churn.csv"
MODEL_PATH = "model.pkl"
TEST_SIZE = 0.2
N_ESTIMATORS = 100
RANDOM_STATE = 42

# Cargar datos
data = pd.read_csv(DATA_PATH)

# Features
num_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']
cat_features = ['Geography', 'Gender']

X = data.drop('Exited', axis=1)
y = data['Exited']

# Split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_STATE)

# Preprocessing
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_features),
    ('cat', OneHotEncoder(), cat_features)
])

X_train_processed = preprocessor.fit_transform(X_train)
X_test_processed = preprocessor.transform(X_test)

# Train
model = RandomForestClassifier(n_estimators=N_ESTIMATORS, random_state=RANDOM_STATE)
model.fit(X_train_processed, y_train)

# Evaluate
y_pred_proba = model.predict_proba(X_test_processed)[:, 1]
auc = roc_auc_score(y_test, y_pred_proba)
print(f"AUC: {auc}")

# Save
joblib.dump(model, MODEL_PATH)
joblib.dump(preprocessor, "preprocessor.pkl")
```

### Tu Tarea: Refactorizarlo

Convierte el script anterior en una estructura profesional con:

1. **`src/bankchurn/config.py`**: ConfiguraciÃ³n Pydantic
2. **`src/bankchurn/data/preprocessing.py`**: Clase FeatureEngineer
3. **`src/bankchurn/models/trainer.py`**: Clase ChurnTrainer
4. **`pyproject.toml`**: ConfiguraciÃ³n del paquete
5. **Tests unitarios** para cada componente

<details>
<summary>ğŸ“ Ver Estructura de SoluciÃ³n</summary>

La soluciÃ³n completa estÃ¡ en el proyecto **BankChurn-Predictor** del portafolio. 
Los archivos clave son:

- `BankChurn-Predictor/src/bankchurn/config.py`
- `BankChurn-Predictor/src/bankchurn/training.py`
- `BankChurn-Predictor/pyproject.toml`
- `BankChurn-Predictor/tests/`

Analiza el cÃ³digo de referencia y replica la estructura.
</details>

---

## 1.7 AutoevaluaciÃ³n

Antes de pasar al siguiente mÃ³dulo, verifica:

### Checklist de Competencias

```
TYPE HINTS:
[ ] Puedo tipar funciones con tipos bÃ¡sicos (str, int, List, Dict)
[ ] SÃ© usar Optional, Union, Literal
[ ] Entiendo TypedDict y TypeVar
[ ] mypy pasa sin errores en mi cÃ³digo

PYDANTIC:
[ ] Puedo crear modelos Pydantic con validaciones
[ ] SÃ© usar Field con restricciones (ge, le, gt, etc.)
[ ] Puedo crear validadores personalizados (@field_validator)
[ ] SÃ© cargar configuraciÃ³n desde YAML

ESTRUCTURA:
[ ] Entiendo el src/ layout
[ ] Puedo crear un pyproject.toml funcional
[ ] SÃ© instalar mi paquete en modo editable
[ ] Entiendo quÃ© exportar en __init__.py

OOP:
[ ] Puedo crear una clase Trainer con __post_init__
[ ] Entiendo Dependency Injection
[ ] SÃ© usar dataclasses con field()
[ ] Puedo escribir cÃ³digo testeable (sin globals)
```

### Preguntas de ReflexiÃ³n

1. Â¿Por quÃ© es importante tipar el cÃ³digo en proyectos MLOps?
2. Â¿CuÃ¡l es la ventaja de Pydantic sobre validar con if/else?
3. Â¿Por quÃ© el `src/` layout es mejor que poner todo en la raÃ­z?
4. Â¿CÃ³mo facilita Dependency Injection el testing?

---

## ğŸ”œ Siguiente Paso

Con el conocimiento de Python moderno, estÃ¡s listo para **diseÃ±ar sistemas ML** a nivel arquitectÃ³nico.

**[Ir a MÃ³dulo 02: DiseÃ±o de Sistemas ML â†’](02_DISENO_SISTEMAS.md)**

---

<div align="center">

*MÃ³dulo 01 completado. Tu cÃ³digo ahora pasa code review de Senior.*

*Â© 2025 DuqueOM - GuÃ­a MLOps v5.0: Senior Edition*

</div>
