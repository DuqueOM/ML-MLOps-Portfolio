# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 21: GLOSARIO COMPLETO MLOps
# Diccionario Exhaustivo de A-Z con Explicaciones Profundas, AnalogÃ­as y Ejemplos
# GuÃ­a MLOps v5.0: Senior Edition | DuqueOM | Diciembre 2025
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

<div align="center">

# ğŸ“– MÃ“DULO 21: Glosario Completo MLOps

**Diccionario Exhaustivo con Explicaciones Profundas, AnalogÃ­as y Ejemplos del Portafolio**

*"Dominar el vocabulario tÃ©cnico es el primer paso para comunicarte como Senior."*

| Nivel        | DuraciÃ³n   |
|:------------:|:----------:|
| ğŸ“š Referencia | Consulta continua |

</div>

---

## ğŸ“š IntroducciÃ³n

Este glosario define **todos** los tÃ©rminos tÃ©cnicos utilizados en la GuÃ­a MLOps v5.0 y en los proyectos del portafolio (BankChurn, CarVision, TelecomAI). Cada tÃ©rmino incluye:

- **DefiniciÃ³n tÃ©cnica** precisa y completa
- **ExplicaciÃ³n conceptual** para entender el "por quÃ©"
- **AnalogÃ­a desarrollada** para facilitar comprensiÃ³n intuitiva
- **Ejemplo del portafolio** cuando aplica
- **TÃ©rminos relacionados** para profundizar

### CÃ³mo usar este glosario

1. **Primera lectura**: Lee las analogÃ­as para captar la intuiciÃ³n
2. **ProfundizaciÃ³n**: Lee la explicaciÃ³n conceptual completa
3. **AplicaciÃ³n**: Revisa los ejemplos del portafolio
4. **ConexiÃ³n**: Explora los tÃ©rminos relacionados

---

## A

### Accuracy (Exactitud)

**DefiniciÃ³n tÃ©cnica:** MÃ©trica de clasificaciÃ³n que mide el porcentaje de predicciones correctas sobre el total. Se calcula como `(TP + TN) / (TP + TN + FP + FN)` donde TP=True Positives, TN=True Negatives, FP=False Positives, FN=False Negatives.

**ExplicaciÃ³n conceptual:** Accuracy responde a la pregunta "Â¿quÃ© porcentaje de mis predicciones fueron correctas?". Es intuitiva pero **peligrosamente engaÃ±osa** con clases desbalanceadas. Si el 95% de tus clientes NO abandonan (no-churn), un modelo que siempre predice "no-churn" tiene 95% accuracy pero es completamente inÃºtil para detectar churners.

**AnalogÃ­a desarrollada:** Imagina un arquero que dispara 100 flechas a un blanco. Si 85 dan en el blanco, su accuracy es 85%. Pero si el blanco ocupa el 95% del muro, incluso disparando con los ojos cerrados acertarÃ­as 95%. Por eso en ML usamos mÃ©tricas adicionales (Precision, Recall) que nos dicen *quÃ© tan bien* acertamos a cada zona especÃ­fica.

**En el portafolio:** BankChurn tiene ~20% de churners. Un modelo "dummy" que siempre predice "no-churn" tendrÃ­a 80% accuracy. Por eso usamos ROC-AUC (86%) y Recall como mÃ©tricas principales.

**Relacionados:** Precision, Recall, F1 Score, ROC-AUC, Class Imbalance

---

### ADR (Architecture Decision Record)

**DefiniciÃ³n tÃ©cnica:** Documento estructurado que registra una decisiÃ³n de arquitectura significativa junto con su contexto, las alternativas consideradas, la decisiÃ³n tomada y sus consecuencias (positivas y negativas).

**ExplicaciÃ³n conceptual:** En proyectos de software, tomamos cientos de decisiones tÃ©cnicas. Meses despuÃ©s, nadie recuerda *por quÃ©* se eligiÃ³ PostgreSQL en vez de MongoDB, o por quÃ© el modelo usa RandomForest y no XGBoost. Los ADRs resuelven esto: son la "memoria institucional" del proyecto. Siguen un formato estÃ¡ndar (Estado, Contexto, DecisiÃ³n, Consecuencias) que facilita la lectura y bÃºsqueda.

**AnalogÃ­a desarrollada:** Piensa en un ADR como el acta de una reuniÃ³n de arquitectos. AÃ±os despuÃ©s de construir un edificio, si alguien pregunta "Â¿por quÃ© las vigas son de acero y no de madera?", el acta explica: "En 2020, consideramos madera (mÃ¡s barata) y acero (mÃ¡s resistente). Elegimos acero porque el edificio estÃ¡ en zona sÃ­smica. Consecuencia: costo 20% mayor pero certificaciÃ³n antisÃ­smica garantizada."

**Ejemplo del portafolio:**
```markdown
# ADR-001: Uso de RandomForest sobre XGBoost

## Estado: Aceptado

## Contexto
Necesitamos un modelo de clasificaciÃ³n para churn que sea interpretable 
para el equipo de negocio y robusto sin tuning extensivo.

## DecisiÃ³n
Usamos RandomForestClassifier con class_weight='balanced'.

## Consecuencias
+ Feature importances nativas (explicabilidad)
+ Robusto sin hiperparÃ¡metro tuning complejo
- Puede perder 1-2% AUC vs XGBoost optimizado
```

**Relacionados:** ML Canvas, C4 Model, DocumentaciÃ³n, DECISIONES_TECH.md

---

### API (Application Programming Interface)

**DefiniciÃ³n tÃ©cnica:** Contrato que define cÃ³mo dos sistemas de software se comunican. Especifica los endpoints disponibles, los formatos de entrada/salida, los mÃ©todos HTTP soportados y los cÃ³digos de respuesta. En MLOps, las APIs REST son el mecanismo principal para exponer modelos ML como servicios consumibles.

**ExplicaciÃ³n conceptual:** Un modelo ML entrenado es solo un archivo (.pkl, .joblib). Para que sea Ãºtil, otros sistemas deben poder enviarle datos y recibir predicciones. Una API actÃºa como la "ventana al mundo" del modelo: recibe requests HTTP con datos del cliente, los valida, los pasa al modelo, y devuelve la predicciÃ³n en formato estructurado (JSON). Esto desacopla el modelo de los consumidores: la app mÃ³vil, el dashboard, el sistema de CRM pueden todos usar la misma API sin conocer los detalles internos del modelo.

**AnalogÃ­a desarrollada:** Una API es como el mesero de un restaurante. TÃº (el cliente) no entras a la cocina a preparar tu comida (no cargas el modelo en tu cÃ³digo). En su lugar, le dices al mesero quÃ© quieres (envÃ­as un request), Ã©l lleva el pedido a la cocina (la API invoca al modelo), y te trae el plato preparado (la API devuelve la predicciÃ³n). El menÃº es la documentaciÃ³n de la API: te dice quÃ© puedes pedir y cÃ³mo.

**Ejemplo del portafolio (BankChurn FastAPI):**
```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel, Field

class PredictionRequest(BaseModel):
    CreditScore: int = Field(..., ge=300, le=850)
    Age: int = Field(..., ge=18, le=100)
    Balance: float = Field(..., ge=0)
    # ... mÃ¡s features

class PredictionResponse(BaseModel):
    prediction: int
    probability: float
    risk_level: str

@app.post("/predict", response_model=PredictionResponse)
async def predict(request: PredictionRequest):
    df = pd.DataFrame([request.model_dump()])
    proba = model.predict_proba(df)[0, 1]
    return PredictionResponse(
        prediction=int(proba > 0.5),
        probability=proba,
        risk_level="high" if proba > 0.7 else "medium" if proba > 0.3 else "low"
    )
```

**Relacionados:** REST, FastAPI, Endpoint, HTTP, Pydantic, OpenAPI/Swagger

---

### Artefacto (Artifact)

**DefiniciÃ³n tÃ©cnica:** Cualquier archivo generado durante el ciclo de vida de ML que necesita ser versionado, almacenado y potencialmente reproducido. Incluye: modelos serializados (.pkl, .joblib, .onnx), datasets procesados, grÃ¡ficos de evaluaciÃ³n, reportes de mÃ©tricas, logs de entrenamiento, y configuraciones.

**ExplicaciÃ³n conceptual:** Un proyecto ML no es solo cÃ³digoâ€”genera "productos intermedios" en cada etapa. El dataset limpio es un artefacto. El modelo entrenado es un artefacto. El reporte de mÃ©tricas es un artefacto. La gestiÃ³n profesional de artefactos permite: (1) reproducibilidadâ€”volver a cualquier versiÃ³n anterior, (2) trazabilidadâ€”saber quÃ© datos y cÃ³digo produjeron quÃ© modelo, (3) colaboraciÃ³nâ€”compartir resultados entre equipos.

**AnalogÃ­a desarrollada:** Piensa en una fÃ¡brica de autos. Los planos son artefactos (cÃ³digo). Las piezas moldeadas son artefactos (datasets procesados). El motor ensamblado es un artefacto (modelo entrenado). El auto terminado es un artefacto (pipeline completo). Cada pieza tiene un nÃºmero de serie y registro de quÃ© mÃ¡quina la produjo, cuÃ¡ndo, con quÃ© materiales. Si un auto tiene un defecto, puedes rastrear hacia atrÃ¡s hasta encontrar la pieza defectuosa y quÃ© lote de materiales causÃ³ el problema.

**Ejemplo del portafolio:**
```
artifacts/
â”œâ”€â”€ model.joblib          # Modelo serializado (pipeline completo)
â”œâ”€â”€ metrics.json          # {"roc_auc": 0.86, "recall": 0.75}
â”œâ”€â”€ feature_importance.png # GrÃ¡fico de importancia
â””â”€â”€ training_config.yaml  # ConfiguraciÃ³n usada
```

**Relacionados:** MLflow, Model Registry, DVC, Reproducibilidad

---

### ASGI (Asynchronous Server Gateway Interface)
**DefiniciÃ³n:** EspecificaciÃ³n para servidores web async en Python. Maneja mÃºltiples requests concurrentemente.

**AnalogÃ­a:** Mesero que anota pedido mesa 1, mientras espera va a mesa 2, etc. Maneja conversaciones "en paralelo".

**Relacionados:** Uvicorn, FastAPI, Async/Await

---

### AUC-ROC
**DefiniciÃ³n:** Ãrea bajo curva ROC. Mide capacidad de distinguir clases. 1.0 = perfecto, 0.5 = aleatorio.

**AnalogÃ­a:** Separando manzanas buenas de malas. AUC 0.9 = 90% de las veces asigna mayor score a la manzana buena.

**Relacionados:** ROC Curve, Precision, Recall, Threshold

---

### Auto-scaling
**DefiniciÃ³n:** Sistema que aumenta/disminuye recursos automÃ¡ticamente segÃºn demanda.

**AnalogÃ­a:** Restaurante contratando meseros temporales cuando hay mucha gente.

**Relacionados:** HPA, Kubernetes, Load Balancer

---

## B

### Backpropagation
**DefiniciÃ³n:** Algoritmo de entrenamiento de redes neuronales que propaga el error hacia atrÃ¡s calculando gradientes.

**AnalogÃ­a:** Equipo de relevos donde analizas hacia atrÃ¡s quiÃ©n contribuyÃ³ al fallo.

**Relacionados:** Gradient Descent, Learning Rate, Neural Network

---

### Baseline
**DefiniciÃ³n:** Modelo simple como referencia. Si tu modelo complejo no lo supera, algo estÃ¡ mal.

**AnalogÃ­a:** Antes de comprar auto deportivo, verifica que sea mÃ¡s rÃ¡pido que tu bicicleta.

**Relacionados:** Benchmark, Model Evaluation

---

### BaseEstimator
**DefiniciÃ³n:** Clase base sklearn con `get_params()` y `set_params()`. Todos los estimadores heredan de ella.

**AnalogÃ­a:** Contrato estÃ¡ndar que todos los constructores deben seguir para que el sistema funcione.

**Relacionados:** TransformerMixin, Custom Transformer, Pipeline

---

### Batch Prediction
**DefiniciÃ³n:** Procesar mÃºltiples muestras a la vez, programadamente. Contrasta con online/real-time.

**AnalogÃ­a:** Catering (cocinas todo de antemano) vs restaurante a la carta (cocinas cada plato al pedirlo).

**Relacionados:** Online Prediction, Latencia

---

### Black
**DefiniciÃ³n:** Formateador Python opinionado. Aplica estilo consistente automÃ¡ticamente.

**AnalogÃ­a:** Corrector que arregla gramÃ¡tica y estilo sin preguntarte.

```bash
black src/
```

**Relacionados:** Linting, Flake8, isort

---

### Branch (Rama)
**DefiniciÃ³n:** LÃ­nea de desarrollo paralela en Git.

**AnalogÃ­a:** Fotocopia del manuscrito para probar final alternativo sin afectar original.

```bash
git checkout -b feature/add-mlflow
```

**Relacionados:** Git, Merge, Pull Request

---

## C

### C4 Model
**DefiniciÃ³n:** VisualizaciÃ³n de arquitectura en 4 niveles: Context, Container, Component, Code.

**AnalogÃ­a:** Google Maps con zoom. Mundo â†’ PaÃ­s â†’ Ciudad â†’ Calle.

**Relacionados:** ADR, Arquitectura

---

### CI/CD
**DefiniciÃ³n:** Continuous Integration (tests automÃ¡ticos) + Continuous Deployment (deploy automÃ¡tico).

**AnalogÃ­a:** FÃ¡brica con control de calidad automatizado que envÃ­a autos aprobados al concesionario.

**Relacionados:** GitHub Actions, Pipeline, DevOps

---

### Classification
**DefiniciÃ³n:** Problema ML supervisado para predecir categorÃ­as discretas.

**AnalogÃ­a:** Doctor diagnosticando enfermedades (multiclase) o decidiendo operar/no operar (binaria).

**Relacionados:** Regression, Supervised Learning

---

### Class Imbalance (Desbalance de Clases)

**DefiniciÃ³n tÃ©cnica:** SituaciÃ³n donde una o mÃ¡s clases estÃ¡n significativamente subrepresentadas en el dataset de entrenamiento. Ratios como 95:5, 99:1 o peores son comunes en problemas reales (fraude, churn, enfermedades raras).

**ExplicaciÃ³n conceptual:** Los algoritmos de ML optimizan mÃ©tricas globales. Si el 95% de tus datos son "no-fraude", el modelo aprende que la estrategia mÃ¡s "segura" es predecir siempre "no-fraude"â€”obtiene 95% accuracy haciendo nada Ãºtil. El desbalance es quizÃ¡s el problema mÃ¡s comÃºn y subestimado en ML aplicado. Afecta tanto al entrenamiento (el modelo no ve suficientes ejemplos de la clase minoritaria) como a la evaluaciÃ³n (accuracy es engaÃ±osa).

**AnalogÃ­a desarrollada:** Imagina entrenar un perro buscador de trufas dÃ¡ndole 1000 piedras y solo 10 trufas. El perro aprende rÃ¡pidamente que decir "piedra" le da premio el 99% de las veces. Nunca aprende realmente a oler trufas. Para entrenarlo bien, necesitas: (1) darle mÃ¡s trufas (oversampling), (2) penalizarlo mÃ¡s cuando falla una trufa (class weights), o (3) medir su Ã©xito por trufas encontradas, no por piedras correctamente ignoradas (mÃ©tricas apropiadas).

**Soluciones tÃ©cnicas:**
```python
# 1. Class weights (penaliza mÃ¡s errores en clase minoritaria)
RandomForestClassifier(class_weight='balanced')

# 2. SMOTE (genera ejemplos sintÃ©ticos de clase minoritaria)
from imblearn.over_sampling import SMOTE
X_resampled, y_resampled = SMOTE().fit_resample(X, y)

# 3. Threshold adjustment (bajar umbral de decisiÃ³n)
proba = model.predict_proba(X)[:, 1]
predictions = (proba > 0.3).astype(int)  # En vez de 0.5

# 4. MÃ©tricas apropiadas
from sklearn.metrics import recall_score, roc_auc_score
# NO usar accuracy como mÃ©trica principal
```

**En el portafolio:** BankChurn tiene ~20% churners. Usamos `class_weight='balanced'` y priorizamos Recall sobre Accuracy.

**Relacionados:** class_weight, SMOTE, Recall, Precision, ROC-AUC, Threshold

---

### class_weight

**DefiniciÃ³n tÃ©cnica:** ParÃ¡metro de sklearn que asigna pesos diferentes a las clases durante el entrenamiento. Con `class_weight='balanced'`, los pesos se calculan automÃ¡ticamente como inversamente proporcionales a la frecuencia de cada clase.

**ExplicaciÃ³n conceptual:** Es la forma mÃ¡s simple de manejar desbalance. En lugar de modificar los datos (oversampling/undersampling), modificamos cÃ³mo el modelo "valora" los errores. Un error en la clase minoritaria "cuenta mÃ¡s" que un error en la clase mayoritaria. MatemÃ¡ticamente, es como si tuviÃ©ramos mÃ¡s ejemplos de la clase minoritaria sin realmente duplicarlos.

**FÃ³rmula:** `weight[i] = n_samples / (n_classes * n_samples_i)`

**Ejemplo del portafolio:**
```python
# BankChurn: 80% no-churn, 20% churn
# Sin class_weight: modelo ignora churners
# Con class_weight='balanced': churners valen 4x mÃ¡s

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(
    n_estimators=100,
    class_weight='balanced',  # CrÃ­tico para churn
    random_state=42
)
```

**Relacionados:** Class Imbalance, SMOTE, RandomForest

---

### Cold Start
**DefiniciÃ³n:** Tiempo para que servicio estÃ© listo tras iniciarse. Incluye cargar modelo en memoria.

**AnalogÃ­a:** Encender auto en invierno. Debes esperar que el motor se caliente.

**Relacionados:** Serverless, Lambda, Latencia

---

### ColumnTransformer
**DefiniciÃ³n:** Sklearn: aplica diferentes transformaciones a diferentes columnas.

**AnalogÃ­a:** LavanderÃ­a con mÃ¡quinas diferentes: colorâ†’encoder, blancaâ†’scaler, delicadosâ†’passthrough.

```python
preprocessor = ColumnTransformer([
    ('num', StandardScaler(), num_cols),
    ('cat', OneHotEncoder(), cat_cols),
])
```

**Relacionados:** Pipeline, Transformer

---

### Commit
**DefiniciÃ³n:** Snapshot de cambios en Git con hash Ãºnico y mensaje.

**AnalogÃ­a:** Foto de tu escritorio. Puedes volver a cualquier foto anterior.

```bash
git commit -m "feat: add probability calibration"
```

**Relacionados:** Git, Branch, Push, Conventional Commits

---

### conftest.py

**DefiniciÃ³n tÃ©cnica:** Archivo especial de pytest que contiene fixtures (funciones que proveen datos/recursos) compartidas entre todos los tests del directorio y subdirectorios. pytest lo descubre automÃ¡ticamente sin necesidad de imports.

**ExplicaciÃ³n conceptual:** Los tests necesitan datos de prueba, conexiones a bases de datos mock, modelos pre-entrenados, etc. Sin conftest.py, cada archivo de tests tendrÃ­a que definir o importar estos recursos. conftest.py centraliza esta lÃ³gica: defines las fixtures una vez, y estÃ¡n disponibles automÃ¡ticamente en todos los tests. Es el "almacÃ©n central de recursos de testing".

**AnalogÃ­a desarrollada:** Imagina un set de filmaciÃ³n. Antes de cada escena, alguien prepara el escenario: pone las luces, coloca los props, prepara el vestuario. conftest.py es ese equipo de preparaciÃ³n. Los actores (tests) llegan y todo estÃ¡ listo. No tienen que traer sus propios propsâ€”solo los piden por nombre y aparecen.

**Ejemplo del portafolio (CarVision):**
```python
# tests/conftest.py
import pytest
import pandas as pd
import numpy as np

@pytest.fixture
def sample_data():
    """Datos sintÃ©ticos para tests."""
    np.random.seed(42)
    return pd.DataFrame({
        'year': np.random.randint(2010, 2023, 100),
        'mileage': np.random.randint(10000, 150000, 100),
        'price': np.random.uniform(5000, 50000, 100),
    })

@pytest.fixture
def trained_pipeline(sample_data):
    """Pipeline entrenado para tests de inferencia."""
    from carvision.pipeline import build_pipeline
    pipe = build_pipeline()
    X = sample_data.drop('price', axis=1)
    y = sample_data['price']
    return pipe.fit(X, y)

@pytest.fixture
def config():
    """ConfiguraciÃ³n de test."""
    return {'model': {'n_estimators': 10}, 'random_state': 42}
```

**Relacionados:** pytest, Fixture, Unit Test, Integration Test

---

### Conventional Commits

**DefiniciÃ³n tÃ©cnica:** EspecificaciÃ³n para escribir mensajes de commit estandarizados. Formato: `<type>(<scope>): <description>`. Types incluyen: feat, fix, docs, style, refactor, test, chore.

**ExplicaciÃ³n conceptual:** Los mensajes de commit son la historia del proyecto. "fixed bug" o "updates" no dicen nada Ãºtil. Conventional Commits impone estructura: el tipo indica quÃ© cambiÃ³ (feature nueva, bug fix, documentaciÃ³n), el scope indica dÃ³nde (api, pipeline, tests), la descripciÃ³n explica quÃ©. Esto permite: (1) generar CHANGELOGs automÃ¡ticamente, (2) determinar versiones semÃ¡nticas, (3) entender la historia del proyecto rÃ¡pidamente.

**AnalogÃ­a desarrollada:** Imagina un libro de bitÃ¡cora de un barco. "Navegamos" no ayuda. "2024-01-15 14:00 - Cambio de rumbo: de Norte a Noroeste para evitar tormenta detectada a 50km" es Ãºtil. Conventional Commits son esa bitÃ¡cora estructurada para cÃ³digo.

**Ejemplos del portafolio:**
```bash
# Formato: <type>(<scope>): <description>

feat(api): add batch prediction endpoint
fix(pipeline): handle NaN values in categorical columns
docs(readme): add quick start guide and badges
test(training): add integration tests for cross-validation
refactor(features): extract FeatureEngineer to separate module
chore(deps): update scikit-learn to 1.3.0
```

**Relacionados:** Git, pre-commit, Semantic Versioning

---

### Concept Drift
**DefiniciÃ³n:** Cambio en relaciÃ³n features-target. Patrones aprendidos ya no son vÃ¡lidos.

**AnalogÃ­a:** Modelo entrenado pre-pandemia predice gustos de pelÃ­culas post-pandemia incorrectamente.

**vs Data Drift:** Data Drift = cambia X. Concept Drift = cambia P(Y|X).

---

### ConfigMap
**DefiniciÃ³n:** Kubernetes: almacena configuraciÃ³n no sensible como pares clave-valor.

**AnalogÃ­a:** TablÃ³n de anuncios de oficina. InformaciÃ³n pÃºblica que todos necesitan.

---

### Container (Contenedor)
**DefiniciÃ³n:** Software empaquetado con cÃ³digo y dependencias. Ejecuta igual en cualquier ambiente.

**AnalogÃ­a:** Contenedor de barco. Funciona igual en cualquier puerto.

**Relacionados:** Docker, Image, Kubernetes

---

### Coverage
**DefiniciÃ³n:** Porcentaje de cÃ³digo ejecutado por tests. No garantiza correcciÃ³n.

**AnalogÃ­a:** Inspector que revisÃ³ 80% de habitaciones. No significa que encontrÃ³ todos los problemas.

```bash
pytest --cov=src
```

**Target:** >80% para cÃ³digo crÃ­tico

---

### Cross-Validation
**DefiniciÃ³n:** Evaluar modelo dividiendo datos en K folds. Entrena K veces con diferentes splits.

**AnalogÃ­a:** 5 estudiantes, 5 rondas. En cada ronda, diferente estudiante es evaluado.

```python
scores = cross_val_score(model, X, y, cv=5, scoring='roc_auc')
```

**Relacionados:** K-Fold, Overfitting

---

### Custom Transformer
**DefiniciÃ³n:** Clase sklearn personalizada que hereda BaseEstimator + TransformerMixin.

**AnalogÃ­a:** Pieza LEGO personalizada con conexiones estÃ¡ndar (fit/transform).

```python
class RatioFeatures(BaseEstimator, TransformerMixin):
    def fit(self, X, y=None): return self
    def transform(self, X):
        X['ratio'] = X['Balance'] / (X['Products'] + 1)
        return X
```

---

## D

### DAG (Directed Acyclic Graph)
**DefiniciÃ³n:** Grafo dirigido sin ciclos. Representa dependencias entre tareas.

**AnalogÃ­a:** Instrucciones de receta. No puedes hornear antes de mezclar.

**Relacionados:** DVC, Pipeline, Airflow

---

### Data Drift

**DefiniciÃ³n tÃ©cnica:** Cambio en la distribuciÃ³n estadÃ­stica de las features (P(X)) entre el momento del entrenamiento y la inferencia en producciÃ³n. No implica necesariamente que la relaciÃ³n feature-target haya cambiado, solo que los datos de entrada son diferentes.

**ExplicaciÃ³n conceptual:** Tu modelo fue entrenado con datos de 2023. Llega 2025 y los patrones de los clientes han cambiado: son mÃ¡s jÃ³venes, usan mÃ¡s canales digitales, tienen balances diferentes. Aunque la "lÃ³gica" de quÃ© causa churn no haya cambiado, tu modelo recibe inputs que nunca vio y puede fallar. Data drift es como un mÃ©dico entrenado solo con pacientes adultos intentando diagnosticar niÃ±osâ€”la anatomÃ­a es diferente aunque las enfermedades sean las mismas.

**AnalogÃ­a desarrollada:** Imagina un modelo que predice si lloverÃ¡ basÃ¡ndose en la presiÃ³n atmosfÃ©rica. Fue entrenado en Madrid. Lo despliegas en Ciudad de MÃ©xico (altitud muy diferente). La presiÃ³n "normal" en CDMX es mucho menor que en Madrid. El modelo ve presiones que interpreta como "muy baja" y siempre predice lluvia. No es que el modelo estÃ© rotoâ€”es que los datos de entrada son muy diferentes a los de entrenamiento.

**Tipos de drift:**
- **Covariate shift**: Cambia P(X), pero P(Y|X) permanece igual
- **Prior probability shift**: Cambia P(Y), la proporciÃ³n de clases
- **Concept drift**: Cambia P(Y|X), la relaciÃ³n misma

**DetecciÃ³n tÃ©cnica:**
```python
# Kolmogorov-Smirnov test para cada feature
from scipy.stats import ks_2samp

for col in features:
    stat, pvalue = ks_2samp(train_data[col], prod_data[col])
    if pvalue < 0.05:
        print(f"Drift detectado en {col}: KS={stat:.3f}, p={pvalue:.4f}")

# Population Stability Index (PSI)
# PSI < 0.1: No drift
# PSI 0.1-0.2: Drift moderado
# PSI > 0.2: Drift significativo
```

**Herramientas:** Evidently, NannyML, Great Expectations

**Relacionados:** Concept Drift, Model Monitoring, Evidently, Retraining

---

### Data Leakage
**DefiniciÃ³n:** InformaciÃ³n del futuro o test filtra al entrenamiento. MÃ©tricas infladas.

**AnalogÃ­a:** Estudiar con las respuestas del mismo examen. 100% en prÃ¡ctica, 0% en real.

**Ejemplos:** `price_per_mile = price / miles`, normalizar antes de split.

---

### Dependency Injection
**DefiniciÃ³n:** Dependencias se pasan desde afuera en lugar de crearse internamente.

**AnalogÃ­a:** CafeterÃ­a recibe leche de proveedor en vez de tener vacas propias.

```python
# Con DI: fÃ¡cil de testear
class Predictor:
    def __init__(self, model: BaseEstimator):
        self.model = model  # Inyectado
```

**Relacionados:** SOLID, Testing

---

### Deployment
**DefiniciÃ³n:** Poner modelo/aplicaciÃ³n en ambiente donde usuarios reales lo usan.

**AnalogÃ­a:** Abrir restaurante al pÃºblico despuÃ©s de cocinar en casa y probar con amigos.

**Tipos:** Batch, REST API, Edge, Streaming

---

### Docker
**DefiniciÃ³n:** Plataforma para aplicaciones en contenedores. CÃ³digo + dependencias portables.

**AnalogÃ­a:** MÃ¡quina del tiempo para cÃ³digo. Congelas ambiente exacto.

```dockerfile
FROM python:3.11-slim
COPY . /app
RUN pip install -r requirements.txt
CMD ["uvicorn", "app:app"]
```

---

### Docstring
**DefiniciÃ³n:** String de documentaciÃ³n al inicio de funciones/clases.

**AnalogÃ­a:** Instrucciones en la caja de un producto.

```python
def predict(data: pd.DataFrame) -> np.ndarray:
    """
    Genera predicciones de churn.
    
    Args:
        data: DataFrame con features.
    Returns:
        Array de probabilidades 0-1.
    """
```

---

### DVC (Data Version Control)
**DefiniciÃ³n:** Versiona datasets y pipelines ML. Datos grandes en storage remoto, metadatos en Git.

**AnalogÃ­a:** Git = Ã¡lbum con miniaturas. DVC = almacÃ©n con fotos originales grandes.

```bash
dvc add data/dataset.csv
dvc push
git add data/dataset.csv.dvc
```

---

## E

### E2E Test
**DefiniciÃ³n:** Test del sistema completo, desde entrada hasta salida final.

**AnalogÃ­a:** Test drive de auto completo, no motor aislado.

---

### Early Stopping
**DefiniciÃ³n:** Detiene entrenamiento cuando validaciÃ³n deja de mejorar. Evita overfitting.

**AnalogÃ­a:** Sacar galletas del horno cuando estÃ¡n doradas, antes de que se quemen.

```python
EarlyStopping(monitor='val_loss', patience=5)
```

---

### Embedding
**DefiniciÃ³n:** RepresentaciÃ³n vectorial densa de datos de alta dimensionalidad.

**AnalogÃ­a:** Mapear ciudades del mundo en papel 2D. Similares quedan cerca.

**Uso:** Word2Vec, Entity embeddings

---

### Endpoint
**DefiniciÃ³n:** URL especÃ­fica de API que realiza operaciÃ³n particular.

**AnalogÃ­a:** Ventanillas de banco. Cada una hace algo diferente.

```python
@app.get("/health")
@app.post("/predict")
```

---

### Ensemble
**DefiniciÃ³n:** Combina mÃºltiples modelos para mejores predicciones.

**AnalogÃ­a:** 100 doctores opinando en vez de 1. OpiniÃ³n agregada suele ser mejor.

**Tipos:** Bagging (Random Forest), Boosting (XGBoost), Stacking

---

### Environment
**DefiniciÃ³n:** Conjunto aislado de dependencias donde ejecuta cÃ³digo.

**AnalogÃ­a:** Diferentes cocinas para diferentes tipos de comida.

**Tipos:** Desarrollo, Staging, ProducciÃ³n

---

### Evidently

**DefiniciÃ³n tÃ©cnica:** LibrerÃ­a open-source de Python para monitoreo de modelos ML en producciÃ³n. Genera reportes interactivos de data drift, target drift, data quality, y performance del modelo comparando datasets de referencia con datasets actuales.

**ExplicaciÃ³n conceptual:** Cuando despliegas un modelo, necesitas saber si sigue funcionando bien. Evidently automatiza esta vigilancia: compara los datos que ve el modelo en producciÃ³n con los datos de entrenamiento, detecta cambios estadÃ­sticos (drift), genera alertas, y produce reportes visuales. Es como tener un "chequeo mÃ©dico" continuo para tu modelo.

**AnalogÃ­a desarrollada:** Imagina que tienes un carro. Evidently es el tablero de instrumentos que te dice si la presiÃ³n de las llantas bajÃ³, si el aceite necesita cambio, si el motor estÃ¡ sobrecalentando. No esperas a que el carro se descompongaâ€”el tablero te avisa antes de que el problema sea grave.

**Ejemplo prÃ¡ctico:**
```python
from evidently.report import Report
from evidently.metric_preset import DataDriftPreset, DataQualityPreset

# Comparar datos de training vs producciÃ³n
report = Report(metrics=[
    DataDriftPreset(),
    DataQualityPreset(),
])

report.run(
    reference_data=train_df,
    current_data=production_df
)

# Generar reporte HTML interactivo
report.save_html("drift_report.html")

# O extraer mÃ©tricas programÃ¡ticamente
drift_results = report.as_dict()
if drift_results['metrics'][0]['result']['dataset_drift']:
    print("âš ï¸ Drift significativo detectado!")
```

**Capacidades:**
- Data Drift: Detecta cambios en distribuciones de features
- Target Drift: Detecta cambios en distribuciÃ³n del target
- Data Quality: Valores faltantes, outliers, correlaciones
- Model Performance: Accuracy, precision, recall en producciÃ³n
- Regression Performance: MAE, RMSE, error distribution

**Relacionados:** Data Drift, Model Monitoring, Observabilidad, NannyML

---

### Experiment Tracking
**DefiniciÃ³n:** Registrar parÃ¡metros, mÃ©tricas, artefactos de cada experimento ML.

**AnalogÃ­a:** Cuaderno de laboratorio de cientÃ­fico.

**Herramientas:** MLflow, W&B, Neptune

---

## F

### F1 Score
**DefiniciÃ³n:** Media armÃ³nica de Precision y Recall. Balance entre ambas.

**FÃ³rmula:** `F1 = 2 Ã— (Precision Ã— Recall) / (Precision + Recall)`

**AnalogÃ­a:** Buscador de trufas. No sirve encontrar pocas muy precisamente ni todas con muchas falsas.

---

### FastAPI
**DefiniciÃ³n:** Framework Python para APIs de alto rendimiento con validaciÃ³n automÃ¡tica.

**AnalogÃ­a:** Mesero eficiente que valida pedidos, da menÃº descriptivo, atiende muchas mesas.

```python
from fastapi import FastAPI
from pydantic import BaseModel

app = FastAPI()

@app.post("/predict")
async def predict(data: PredictionInput):
    return {"probability": model.predict_proba([data])[0, 1]}
```

**Relacionados:** Pydantic, Uvicorn, REST

---

### Feature
**DefiniciÃ³n:** Variable de entrada para predicciones.

**AnalogÃ­a:** Ingredientes de receta. Para predecir si pastel sale bien: harina, azÃºcar, temperatura.

**Tipos:** NumÃ©ricas, CategÃ³ricas, Binarias, Derivadas

---

### Feature Engineering
**DefiniciÃ³n:** Crear/transformar/seleccionar features para mejorar modelo.

**AnalogÃ­a:** Chef preparando ingredientes. Ingredientes crudos se transforman en algo digerible.

```python
df['balance_per_product'] = df['Balance'] / (df['NumOfProducts'] + 1)
```

---

### Feature Store
**DefiniciÃ³n:** Sistema centralizado para almacenar y servir features consistentemente.

**AnalogÃ­a:** AlmacÃ©n central de ingredientes preparados para cadena de restaurantes.

**Herramientas:** Feast, Tecton

---

### Fixture (pytest)
**DefiniciÃ³n:** FunciÃ³n que provee datos/recursos reutilizables para tests.

**AnalogÃ­a:** Setup de set de filmaciÃ³n antes de cada escena.

```python
@pytest.fixture
def sample_customer():
    return {"Age": 35, "Balance": 50000}
```

---

### Flake8
**DefiniciÃ³n:** Linting para Python: errores lÃ³gicos, estilo PEP8, complejidad.

**AnalogÃ­a:** Corrector de estilo de periÃ³dico.

```bash
flake8 src/
```

---

## G

### Git
**DefiniciÃ³n:** Control de versiones distribuido.

**AnalogÃ­a:** "Deshacer" infinito. Volver a cualquier momento, ver quÃ© cambiÃ³ y por quÃ©.

```bash
git add . && git commit -m "mensaje" && git push
```

---

### GitHub Actions
**DefiniciÃ³n:** CI/CD integrado en GitHub.

**AnalogÃ­a:** Mayordomo robot que ejecuta instrucciones automÃ¡ticamente.

```yaml
on: [push]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - run: pytest tests/
```

---

### Gitleaks
**DefiniciÃ³n:** Detecta secrets accidentalmente commiteados.

**AnalogÃ­a:** Detector de metales en aeropuerto para cÃ³digo.

---

### Gradient Descent
**DefiniciÃ³n:** Algoritmo que encuentra parÃ¡metros que minimizan pÃ©rdida.

**AnalogÃ­a:** En montaÃ±a con niebla, das pasos pequeÃ±os siempre cuesta abajo.

**Relacionados:** Learning Rate, Loss Function

---

### Grafana
**DefiniciÃ³n:** VisualizaciÃ³n y dashboards para mÃ©tricas.

**AnalogÃ­a:** Tablero de instrumentos de aviÃ³n.

**Relacionados:** Prometheus, Observabilidad

---

## H

### Health Check
**DefiniciÃ³n:** Endpoint que verifica si servicio funciona.

**AnalogÃ­a:** MÃ©dico preguntando "Â¿cÃ³mo te sientes?".

```python
@app.get("/health")
def health():
    return {"status": "healthy"}
```

---

### HPA (Horizontal Pod Autoscaler)
**DefiniciÃ³n:** Kubernetes: escala pods automÃ¡ticamente segÃºn mÃ©tricas.

**AnalogÃ­a:** Gerente de restaurante que llama mÃ¡s meseros si hay muchas mesas ocupadas.

---

### Hyperparameter
**DefiniciÃ³n:** ParÃ¡metro configurado ANTES del entrenamiento.

**AnalogÃ­a:** Decisiones antes de hornear: temperatura, tiempo, tamaÃ±o de molde.

**Ejemplos:** n_estimators, learning_rate, max_depth

---

### Hyperparameter Tuning
**DefiniciÃ³n:** Encontrar combinaciÃ³n Ã³ptima de hiperparÃ¡metros.

**AnalogÃ­a:** Afinar guitarra. Probar perillas hasta mejor sonido.

**TÃ©cnicas:** Grid Search, Random Search, Bayesian Optimization

---

## I

### Image (Docker)
**DefiniciÃ³n:** Template inmutable para crear contenedores.

**AnalogÃ­a:** Receta + ingredientes pre-empaquetados. Imagen es el kit, contenedor es el pastel horneado.

---

### Imputer
**DefiniciÃ³n:** Rellena valores faltantes (NaN).

**AnalogÃ­a:** Restaurador de pinturas rellenando huecos.

```python
SimpleImputer(strategy='median')
```

---

### Inference
**DefiniciÃ³n:** Usar modelo entrenado para predicciones sobre datos nuevos.

**AnalogÃ­a:** Entrenamiento = estudiar. Inferencia = tomar el examen.

---

### Ingress
**DefiniciÃ³n:** Kubernetes: gestiona acceso HTTP externo al cluster.

**AnalogÃ­a:** RecepciÃ³n de edificio que dirige trÃ¡fico.

---

### Integration Test
**DefiniciÃ³n:** Verifica que mÃºltiples componentes funcionan juntos.

**AnalogÃ­a:** Probar que motor, transmisiÃ³n y ruedas funcionan juntos.

---

### isort
**DefiniciÃ³n:** Ordena imports de Python automÃ¡ticamente.

**AnalogÃ­a:** Organizador de armario que siempre pone ropa en mismo orden.

---

## J

### Job (GitHub Actions)
**DefiniciÃ³n:** Conjunto de steps en mismo runner.

**Relacionados:** Workflow, Step, Runner

---

### Joblib
**DefiniciÃ³n:** Serializa objetos Python, especialmente modelos sklearn.

```python
joblib.dump(model, "model.pkl")
model = joblib.load("model.pkl")
```

---

## K

### Kubernetes (K8s)
**DefiniciÃ³n:** Orquestador de contenedores para automatizar despliegue y escalado.

**AnalogÃ­a:** Director de orquesta coordinando muchos mÃºsicos (contenedores).

**Recursos:** Pod, Deployment, Service, Ingress

---

### K-Fold
**DefiniciÃ³n:** Dividir datos en K partes para cross-validation.

**Relacionados:** Cross-Validation, Stratified

---

## L

### Latency (Latencia)
**DefiniciÃ³n:** Tiempo de respuesta del sistema. En APIs ML: milisegundos.

**AnalogÃ­a:** Tiempo entre pedir comida y que llegue.

**P95:** El 95% de requests responden en menos de X ms.

---

### Learning Rate
**DefiniciÃ³n:** TamaÃ±o de paso en gradient descent.

**AnalogÃ­a:** Paso grande = llegas rÃ¡pido pero puedes pasar el mÃ­nimo. Paso pequeÃ±o = lento pero preciso.

---

### Linting
**DefiniciÃ³n:** AnÃ¡lisis estÃ¡tico para detectar errores y violaciones de estilo.

**Herramientas:** Flake8, pylint, mypy

---

### Load Balancer
**DefiniciÃ³n:** Distribuye trÃ¡fico entre mÃºltiples servidores.

**AnalogÃ­a:** Hostess de restaurante que asigna mesas equitativamente.

---

### Loss Function (FunciÃ³n de PÃ©rdida)
**DefiniciÃ³n:** Mide quÃ© tan mal son las predicciones. El entrenamiento la minimiza.

**Ejemplos:** MSE (regresiÃ³n), Cross-Entropy (clasificaciÃ³n)

---

## M

### Makefile
**DefiniciÃ³n:** Archivo con comandos abreviados para tareas comunes.

```makefile
test:
    pytest tests/ -v
lint:
    black src/ && flake8 src/
```

---

### Matrix (GitHub Actions)
**DefiniciÃ³n:** Ejecutar job con mÃºltiples combinaciones de parÃ¡metros.

```yaml
strategy:
  matrix:
    python-version: [3.10, 3.11]
```

---

### Metric (MÃ©trica)
**DefiniciÃ³n:** Valor numÃ©rico que mide rendimiento del modelo.

**ClasificaciÃ³n:** Accuracy, Precision, Recall, F1, AUC
**RegresiÃ³n:** MSE, RMSE, MAE, RÂ²

---

### Middleware
**DefiniciÃ³n:** CÃ³digo que intercepta requests/responses entre cliente y aplicaciÃ³n.

**AnalogÃ­a:** Portero que revisa credenciales antes de dejarte pasar.

---

### MLflow
**DefiniciÃ³n:** Plataforma open-source para gestionar ciclo de vida ML.

**Componentes:** Tracking, Projects, Models, Registry

```python
with mlflow.start_run():
    mlflow.log_params(params)
    mlflow.log_metrics(metrics)
    mlflow.sklearn.log_model(model, "model")
```

---

### MLOps

**DefiniciÃ³n tÃ©cnica:** Conjunto de prÃ¡cticas que unifican Machine Learning, DevOps y Data Engineering para automatizar y estandarizar el ciclo de vida completo de modelos ML: desde experimentaciÃ³n hasta producciÃ³n, incluyendo monitoreo, reentrenamiento y gobernanza.

**ExplicaciÃ³n conceptual:** Data Scientists saben entrenar modelos. DevOps sabe desplegar aplicaciones. Data Engineers saben mover datos. MLOps es el puente que conecta estos tres mundos. Sin MLOps, tienes "modelos en notebooks" que nunca llegan a producciÃ³n, o modelos desplegados que nadie monitorea y se degradan silenciosamente. MLOps trae madurez industrial al ML.

**AnalogÃ­a desarrollada:** Imagina que los Data Scientists son chefs que crean recetas increÃ­bles en su cocina experimental. DevOps es el equipo que opera restaurantes a escala. MLOps es el proceso que convierte esa receta experimental en un menÃº estandarizado, con control de calidad, ingredientes versionados, y alertas si la calidad baja. Sin MLOps, tienes un chef genial cuyas recetas nadie puede reproducir consistentemente.

**Pilares de MLOps:**
1. **Versionado**: CÃ³digo (Git), Datos (DVC), Modelos (MLflow)
2. **AutomatizaciÃ³n**: CI/CD, pipelines de entrenamiento
3. **Testing**: Datos, modelos, APIs, integraciÃ³n
4. **Monitoreo**: Drift, performance, latencia
5. **Reproducibilidad**: Ambientes, seeds, configuraciones

**Relacionados:** DevOps, CI/CD, MLflow, DVC, Model Monitoring

---

### Multi-stage Build (Docker)

**DefiniciÃ³n tÃ©cnica:** TÃ©cnica de construcciÃ³n de imÃ¡genes Docker que usa mÃºltiples `FROM` statements, permitiendo separar el ambiente de compilaciÃ³n/build del ambiente de ejecuciÃ³n. El resultado es una imagen final mÃ¡s pequeÃ±a y segura que solo contiene lo necesario para ejecutar la aplicaciÃ³n.

**ExplicaciÃ³n conceptual:** Cuando construyes una aplicaciÃ³n, necesitas herramientas de compilaciÃ³n, tests, dependencias de desarrollo. Pero en producciÃ³n, solo necesitas el binario final y las dependencias runtime. Multi-stage te permite "cocinar" en una cocina completa y luego servir solo el plato terminado, sin llevar todos los utensilios al comedor.

**AnalogÃ­a desarrollada:** Imagina construir un mueble IKEA. Necesitas martillo, destornillador, nivel, instrucciones, embalaje. Pero una vez terminado, solo quieres el mueble en tu salaâ€”no el taller completo. Multi-stage es exactamente eso: usas un container "taller" con todas las herramientas, construyes, y luego copias solo el resultado final a un container "sala" limpio y minimalista.

**Ejemplo del portafolio:**
```dockerfile
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 1: Builder - Tiene todas las herramientas
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM python:3.11-slim AS builder

WORKDIR /app

# Instalar dependencias de compilaciÃ³n (solo en builder)
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Instalar dependencias Python en directorio aislado
COPY requirements.txt .
RUN pip install --no-cache-dir --target=/app/deps -r requirements.txt

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# STAGE 2: Runtime - Solo lo necesario para ejecutar
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FROM python:3.11-slim

# Usuario no-root (seguridad)
RUN useradd --create-home appuser

WORKDIR /app

# Copiar SOLO las dependencias instaladas (no el toolchain)
COPY --from=builder /app/deps /usr/local/lib/python3.11/site-packages/

# Copiar cÃ³digo de aplicaciÃ³n
COPY --chown=appuser:appuser src/ ./src/
COPY --chown=appuser:appuser app/ ./app/
COPY --chown=appuser:appuser artifacts/ ./artifacts/

USER appuser

EXPOSE 8000
CMD ["uvicorn", "app.fastapi_app:app", "--host", "0.0.0.0", "--port", "8000"]
```

**Beneficios:**
- **Imagen mÃ¡s pequeÃ±a**: De ~1.5GB a ~500MB
- **MÃ¡s segura**: Sin compiladores ni herramientas de ataque
- **MÃ¡s rÃ¡pida de desplegar**: Menos bytes que transferir

**Relacionados:** Docker, Container, Dockerfile, Non-root User

---

### Model Card
**DefiniciÃ³n:** Documento describiendo modelo: propÃ³sito, datos, mÃ©tricas, limitaciones, Ã©tica.

**AnalogÃ­a:** Prospecto de medicamento. InformaciÃ³n completa sobre quÃ© hace y sus efectos.

---

### Model Registry
**DefiniciÃ³n:** Sistema para versionar y gestionar modelos ML.

**Estados:** Staging â†’ Production â†’ Archived

---

### mypy
**DefiniciÃ³n:** Type checking estÃ¡tico para Python.

```bash
mypy src/
```

**Relacionados:** Type Hints, Pydantic

---

## N

### NaN (Not a Number)
**DefiniciÃ³n:** Valor especial para datos faltantes o indefinidos.

```python
import numpy as np
np.nan
```

---

### Namespace
**DefiniciÃ³n:** Kubernetes: divisiÃ³n lÃ³gica del cluster para aislamiento.

**AnalogÃ­a:** Departamentos en una empresa. Cada uno tiene sus recursos.

---

## O

### Observability (Observabilidad)
**DefiniciÃ³n:** Capacidad de entender estado interno de sistema desde outputs externos.

**3 Pilares:** Logs, Metrics, Traces

**AnalogÃ­a:** Instrumentos de aviÃ³n. Si no puedes ver, no puedes arreglar.

---

### One-Hot Encoding
**DefiniciÃ³n:** Convierte variables categÃ³ricas en vectores binarios.

```
Country: [France, Spain, Germany]
France â†’ [1, 0, 0]
Spain  â†’ [0, 1, 0]
```

---

### Overfitting (Sobreajuste)
**DefiniciÃ³n:** Modelo memoriza datos de entrenamiento, no generaliza.

**AnalogÃ­a:** Estudiante que memoriza respuestas exactas pero no entiende conceptos.

**SeÃ±ales:** Train accuracy muy alta, validation accuracy baja.

**Soluciones:** MÃ¡s datos, regularizaciÃ³n, early stopping, dropout

---

## P

### Pipeline (sklearn)
**DefiniciÃ³n:** Secuencia de transformaciones y estimador final encadenados.

**AnalogÃ­a:** LÃ­nea de ensamblaje. Cada estaciÃ³n hace una transformaciÃ³n.

```python
pipeline = Pipeline([
    ('scaler', StandardScaler()),
    ('model', RandomForestClassifier())
])
```

---

### Pod
**DefiniciÃ³n:** Kubernetes: unidad de deployment mÃ¡s pequeÃ±a. Uno o mÃ¡s contenedores.

**AnalogÃ­a:** Apartamento en edificio. Contenedores son habitaciones del apartamento.

---

### Precision (PrecisiÃ³n)
**DefiniciÃ³n:** De predicciones positivas, Â¿cuÃ¡ntas son correctas? TP / (TP + FP)

**AnalogÃ­a:** De las personas que detuviste como sospechosas, Â¿cuÃ¡ntas eran realmente criminales?

---

### Pre-commit Hook
**DefiniciÃ³n:** Script que se ejecuta automÃ¡ticamente antes de cada commit.

**AnalogÃ­a:** Control de calidad que revisa tu trabajo antes de entregarlo.

```yaml
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/psf/black
    hooks:
      - id: black
```

---

### Prometheus
**DefiniciÃ³n:** Sistema de monitoreo y alertas. Recolecta mÃ©tricas de servicios.

**Relacionados:** Grafana, Metrics, Observabilidad

---

### Pull Request (PR)
**DefiniciÃ³n:** Solicitud para integrar cambios con revisiÃ³n de cÃ³digo.

**AnalogÃ­a:** Propuesta formal que requiere aprobaciÃ³n antes de aceptarse.

---

### Pydantic
**DefiniciÃ³n:** ValidaciÃ³n de datos en Python usando type hints.

```python
class Customer(BaseModel):
    age: int = Field(ge=18, le=100)
    name: str
```

**Relacionados:** Type Hints, FastAPI, Validation

---

### pytest
**DefiniciÃ³n:** Framework de testing para Python.

```python
def test_prediction():
    result = model.predict([[35, 50000]])
    assert result[0] in [0, 1]
```

---

## R

### Random Forest

**DefiniciÃ³n tÃ©cnica:** Algoritmo de ensemble learning que construye mÃºltiples Ã¡rboles de decisiÃ³n durante el entrenamiento y combina sus predicciones (votaciÃ³n mayoritaria para clasificaciÃ³n, promedio para regresiÃ³n). Cada Ã¡rbol se entrena con un subconjunto aleatorio de datos (bagging) y features (random subspace).

**ExplicaciÃ³n conceptual:** Un solo Ã¡rbol de decisiÃ³n puede sobreajustarse fÃ¡cilmente y es muy sensible a pequeÃ±os cambios en los datos. Random Forest resuelve esto con la "sabidurÃ­a de las multitudes": entrena cientos de Ã¡rboles "diversos" (cada uno ve datos diferentes) y promedia sus opiniones. Los errores individuales se cancelan, produciendo un modelo robusto y estable.

**AnalogÃ­a desarrollada:** Imagina 100 doctores, cada uno especializado en diferentes aspectos (algunos ven mÃ¡s casos de ciertas enfermedades, otros atienden diferentes demografÃ­as). Si cada doctor da su diagnÃ³stico individualmente, algunos acertarÃ¡n y otros fallarÃ¡n. Pero si los 100 votan y tomas la opiniÃ³n mayoritaria, casi siempre aciertas. Eso es Random Forest: democracia de Ã¡rboles donde los errores individuales se cancelan.

**Por quÃ© es popular en MLOps:**
- **Interpretabilidad**: Feature importances nativas
- **Robustez**: Funciona bien "out of the box" sin tuning extensivo
- **Versatilidad**: ClasificaciÃ³n y regresiÃ³n
- **Sin normalizaciÃ³n**: No requiere escalar features

**Ejemplo del portafolio (BankChurn):**
```python
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline

# ParÃ¡metros clave:
# - n_estimators: NÃºmero de Ã¡rboles (mÃ¡s = mÃ¡s estable, mÃ¡s lento)
# - max_depth: Profundidad mÃ¡xima (controla overfitting)
# - class_weight: Manejo de desbalance

pipeline = Pipeline([
    ('preprocessor', ColumnTransformer([
        ('num', SimpleImputer(strategy='median'), num_cols),
        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols),
    ])),
    ('classifier', RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        class_weight='balanced',  # CrÃ­tico para churn
        random_state=42,
        n_jobs=-1  # Paralelizar
    ))
])

# Feature importance despuÃ©s de entrenar
importances = pipeline.named_steps['classifier'].feature_importances_
```

**HiperparÃ¡metros importantes:**
| ParÃ¡metro | Default | Efecto |
|-----------|---------|--------|
| n_estimators | 100 | MÃ¡s Ã¡rboles = mÃ¡s estable pero mÃ¡s lento |
| max_depth | None | Limitar previene overfitting |
| min_samples_split | 2 | Mayor valor = Ã¡rboles mÃ¡s pequeÃ±os |
| class_weight | None | 'balanced' para clases desbalanceadas |

**Relacionados:** Ensemble, Bagging, Decision Tree, class_weight, Feature Importance

---

### Recall (Sensibilidad)

**DefiniciÃ³n tÃ©cnica:** MÃ©trica que mide quÃ© proporciÃ³n de los casos positivos reales fueron correctamente identificados. FÃ³rmula: `TP / (TP + FN)`. TambiÃ©n llamada Sensibilidad o True Positive Rate.

**ExplicaciÃ³n conceptual:** Recall responde: "De todos los casos positivos reales, Â¿cuÃ¡ntos logrÃ© detectar?". Es crÃ­tica cuando el costo de **no detectar** un positivo es alto: diagnÃ³stico de cÃ¡ncer (no detectar = paciente sin tratamiento), detecciÃ³n de fraude (no detectar = pÃ©rdida financiera), predicciÃ³n de churn (no detectar = cliente perdido).

**AnalogÃ­a desarrollada:** Imagina un detector de metales en un aeropuerto. Recall es: "De todas las armas reales que pasaron, Â¿cuÃ¡ntas detectÃ³?". Un Recall del 100% significa que detectÃ³ todas las armas (aunque haya generado muchas falsas alarmas con llaves y monedas). En seguridad, preferimos alta sensibilidad aunque suene mÃ¡s veces innecesariamente.

**En el portafolio:** BankChurn prioriza Recall porque el costo de no detectar un churner (perderlo) es mayor que el costo de ofrecerle retenciÃ³n a alguien que no iba a irse.

**Trade-off Precision vs Recall:**
```
                    PredicciÃ³n
                    Positivo    Negativo
Realidad Positivo   TP          FN (Recall falla aquÃ­)
         Negativo   FP          TN

Recall = TP / (TP + FN) â†’ Maximizar TP, minimizar FN
```

**Relacionados:** Precision, F1 Score, Threshold, ROC-AUC

---

### Regression (RegresiÃ³n)
**DefiniciÃ³n:** Problema ML para predecir valor numÃ©rico continuo.

**Ejemplos:** Precio de casa, temperatura, ventas

---

### Regularization (RegularizaciÃ³n)
**DefiniciÃ³n:** TÃ©cnicas para prevenir overfitting penalizando complejidad.

**Tipos:** L1 (Lasso), L2 (Ridge), Dropout, Early Stopping

---

### Replica
**DefiniciÃ³n:** Copia de un pod/servicio para alta disponibilidad.

**Relacionados:** Deployment, ReplicaSet

---

### Reproducibility (Reproducibilidad)
**DefiniciÃ³n:** Obtener mismos resultados con mismo cÃ³digo y datos.

**Clave:** Seeds, versionado de datos/cÃ³digo/ambiente

---

### REST API
**DefiniciÃ³n:** Estilo arquitectÃ³nico con HTTP methods: GET, POST, PUT, DELETE.

**Relacionados:** API, HTTP, Endpoint

---

### Runbook

**DefiniciÃ³n tÃ©cnica:** Documento operacional que contiene procedimientos paso a paso para manejar incidentes, alertas o tareas de mantenimiento de un sistema en producciÃ³n. Incluye informaciÃ³n del servicio, alertas comunes, y procedimientos de emergencia.

**Contenido tÃ­pico:**
- InformaciÃ³n del servicio (owner, criticidad, endpoints)
- Procedimientos para alertas comunes
- Comandos de diagnÃ³stico y recuperaciÃ³n
- Escalamiento y contactos

**En el portafolio:** Ver [17_DESPLIEGUE.md â†’ Operaciones y Runbooks](17_DESPLIEGUE.md#-operaciones-y-runbooks).

**Relacionados:** SLO, SLA, Incident Response, On-call

---

### Ruff

**DefiniciÃ³n tÃ©cnica:** Linter y formateador de cÃ³digo Python extremadamente rÃ¡pido, escrito en Rust. Reemplaza mÃºltiples herramientas (Flake8, Black, isort, pyupgrade, etc.) con una sola herramienta 10-100x mÃ¡s rÃ¡pida.

**ExplicaciÃ³n conceptual:** Tradicionalmente, un proyecto Python necesitaba mÃºltiples herramientas para mantener la calidad del cÃ³digo: Black para formatear, Flake8 para detectar errores, isort para ordenar imports, pyupgrade para sintaxis moderna. Cada herramienta tenÃ­a su configuraciÃ³n, versiÃ³n, y tiempo de ejecuciÃ³n. Ruff unifica todo esto: un solo binario que hace todo, instantÃ¡neamente. Es la herramienta moderna que estÃ¡ reemplazando al stack tradicional.

**AnalogÃ­a desarrollada:** Imagina tener una navaja suiza en vez de cargar tijeras, destornillador, cuchillo y abridor por separado. Ruff es esa navaja suiza: todas las herramientas de calidad de cÃ³digo en una, y ademÃ¡s es mÃ¡s ligera y rÃ¡pida que cualquiera de las individuales.

**Por quÃ© importa:**
- **Velocidad**: 10-100x mÃ¡s rÃ¡pido que Flake8+Black+isort
- **UnificaciÃ³n**: Una herramienta, una configuraciÃ³n
- **Compatibilidad**: Entiende las reglas de Flake8, Black, isort
- **Moderno**: Soporta Python 3.12+, type hints, f-strings

**Ejemplo de configuraciÃ³n (pyproject.toml):**
```toml
[tool.ruff]
line-length = 88
target-version = "py311"

[tool.ruff.lint]
select = [
    "E",    # pycodestyle errors
    "W",    # pycodestyle warnings
    "F",    # Pyflakes
    "I",    # isort
    "B",    # flake8-bugbear
    "C4",   # flake8-comprehensions
    "UP",   # pyupgrade
]
ignore = ["E501"]  # Line too long (handled by formatter)

[tool.ruff.lint.isort]
known-first-party = ["bankchurn", "carvision", "telecomai"]
```

**Uso:**
```bash
# Lint (detectar errores)
ruff check src/

# Lint con auto-fix
ruff check --fix src/

# Format (como Black)
ruff format src/

# Pre-commit hook
# .pre-commit-config.yaml
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.4.4
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
```

**Relacionados:** Linting, Black, Flake8, isort, pre-commit, Code Quality

---

## S

### Scaling (Escalado de Features)
**DefiniciÃ³n:** Normalizar features a rango similar.

**TÃ©cnicas:** StandardScaler (z-score), MinMaxScaler (0-1)

---

### Scikit-learn (sklearn)
**DefiniciÃ³n:** LibrerÃ­a Python para ML clÃ¡sico.

**MÃ³dulos:** preprocessing, model_selection, ensemble, metrics

---

### Secret
**DefiniciÃ³n:** Valor sensible (contraseÃ±a, API key) que no debe estar en cÃ³digo.

**Kubernetes:** Objeto Secret para almacenar datos sensibles encriptados.

---

### Seed (Random State)
**DefiniciÃ³n:** Valor para inicializar generadores aleatorios. Garantiza reproducibilidad.

```python
np.random.seed(42)
RandomForestClassifier(random_state=42)
```

---

### Service (Kubernetes)
**DefiniciÃ³n:** AbstracciÃ³n que expone pods como servicio de red.

**Tipos:** ClusterIP, NodePort, LoadBalancer

---

### SHAP

**DefiniciÃ³n tÃ©cnica:** SHapley Additive exPlanations. Framework de interpretabilidad basado en teorÃ­a de juegos que asigna a cada feature su contribuciÃ³n marginal a una predicciÃ³n especÃ­fica. Funciona con cualquier modelo (model-agnostic).

**ExplicaciÃ³n conceptual:** Cuando un modelo predice que un cliente va a abandonar, quieres saber *por quÃ©*. SHAP descompone la predicciÃ³n en contribuciones de cada feature: "El balance alto contribuyÃ³ +0.15 a la probabilidad de churn, la edad joven contribuyÃ³ -0.08, el nÃºmero de productos contribuyÃ³ +0.12...". Esto permite explicar cada predicciÃ³n individual, no solo el modelo en general.

**AnalogÃ­a desarrollada:** Imagina un jurado de 10 personas que decide un veredicto. SHAP es como analizar cuÃ¡nto influyÃ³ cada jurado en la decisiÃ³n final. "MarÃ­a estaba muy convencida (+0.3), Juan estaba indeciso (+0.05), Pedro iba en contra (-0.2)...". Sumando todas las contribuciones, obtienes el veredicto final.

**Relacionados:** Interpretabilidad, Feature Importance, Explainability

---

### SMOTE (Synthetic Minority Over-sampling Technique)

**DefiniciÃ³n tÃ©cnica:** TÃ©cnica de oversampling que genera ejemplos sintÃ©ticos de la clase minoritaria interpolando entre ejemplos existentes y sus k vecinos mÃ¡s cercanos. No duplica ejemplosâ€”crea nuevos puntos en el espacio de features.

**ExplicaciÃ³n conceptual:** Cuando tienes 95% de una clase y 5% de otra, el modelo aprende a ignorar la minoritaria. SMOTE resuelve esto generando ejemplos sintÃ©ticos "plausibles" de la clase minoritaria. Toma un ejemplo real, encuentra sus vecinos mÃ¡s cercanos (tambiÃ©n de la clase minoritaria), y crea nuevos puntos en la lÃ­nea que los conecta. AsÃ­ el modelo ve mÃ¡s variedad de la clase minoritaria sin simplemente copiar los mismos ejemplos.

**AnalogÃ­a desarrollada:** Imagina que tienes 10 fotos de gatos negros y 1000 de perros. Duplicar la foto del gato 100 veces no ayudaâ€”el modelo memoriza esa Ãºnica foto. SMOTE es como un artista que mira tus 10 fotos de gatos negros y pinta 90 fotos nuevas de gatos negros "plausibles" interpolando caracterÃ­sticas: "este tiene los ojos del gato 1, las orejas del gato 3, el tamaÃ±o del gato 7...".

**Ejemplo:**
```python
from imblearn.over_sampling import SMOTE
from sklearn.model_selection import train_test_split

# Siempre aplicar DESPUÃ‰S del split (evitar data leakage)
X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y)

# SMOTE solo en training
smote = SMOTE(random_state=42, k_neighbors=5)
X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)

# Ahora las clases estÃ¡n balanceadas en training
print(f"Original: {y_train.value_counts().to_dict()}")
print(f"Resampled: {pd.Series(y_train_resampled).value_counts().to_dict()}")
```

**CuÃ¡ndo usar SMOTE vs class_weight:**
- **SMOTE**: Cuando quieres mÃ¡s variedad en ejemplos minoritarios
- **class_weight**: MÃ¡s simple, no modifica datos, funciona bien en la mayorÃ­a de casos

**Relacionados:** Class Imbalance, Oversampling, class_weight, imblearn

---

### SOLID

**DefiniciÃ³n tÃ©cnica:** Cinco principios de diseÃ±o de software orientado a objetos que promueven cÃ³digo mantenible, extensible y testeable.

**Los 5 principios:**

1. **S - Single Responsibility**: Una clase debe tener una sola razÃ³n para cambiar
   ```python
   # âŒ Mal: Clase hace demasiado
   class ChurnPredictor:
       def load_data(self): ...
       def clean_data(self): ...
       def train(self): ...
       def save_to_s3(self): ...
   
   # âœ… Bien: Responsabilidades separadas
   class DataLoader: ...
   class FeatureEngineer: ...
   class ChurnTrainer: ...
   class S3Uploader: ...
   ```

2. **O - Open/Closed**: Abierto para extensiÃ³n, cerrado para modificaciÃ³n
   ```python
   # Puedes aÃ±adir nuevos modelos sin modificar cÃ³digo existente
   class BaseTrainer(ABC):
       @abstractmethod
       def train(self, X, y): ...
   
   class RandomForestTrainer(BaseTrainer): ...
   class XGBoostTrainer(BaseTrainer): ...  # ExtensiÃ³n, no modificaciÃ³n
   ```

3. **L - Liskov Substitution**: Subclases deben ser substituibles por sus padres

4. **I - Interface Segregation**: Interfaces pequeÃ±as y especÃ­ficas

5. **D - Dependency Inversion**: Depender de abstracciones, no de implementaciones

**En el portafolio:** `FeatureEngineer`, `ChurnTrainer` siguen Single Responsibility. El uso de sklearn Pipeline permite Open/Closed (cambiar modelo sin modificar pipeline).

**Relacionados:** Clean Code, Design Patterns, Testing

---

### src/ Layout

**DefiniciÃ³n tÃ©cnica:** Estructura de proyecto Python donde el cÃ³digo fuente reside en un subdirectorio `src/` en lugar de la raÃ­z. El paquete se instala con `pip install -e .` para desarrollo.

**ExplicaciÃ³n conceptual:** La estructura "flat" (cÃ³digo en raÃ­z) causa problemas: Python puede importar archivos locales en vez del paquete instalado, tests pueden pasar localmente pero fallar en CI, y es difÃ­cil distinguir cÃ³digo de proyecto de configuraciÃ³n. `src/` layout resuelve esto forzando que el cÃ³digo solo sea accesible como paquete instalado.

**AnalogÃ­a desarrollada:** Imagina una tienda donde los productos estÃ¡n tanto en el almacÃ©n como en el piso de venta. ConfusiÃ³n garantizada: Â¿el cliente estÃ¡ comprando del almacÃ©n o del piso? src/ layout es como tener una puerta clara entre almacÃ©n (desarrollo) y piso de venta (paquete instalado).

**Estructura del portafolio:**
```
BankChurn-Predictor/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ bankchurn/           # Paquete principal
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py        # ConfiguraciÃ³n Pydantic
â”‚       â”œâ”€â”€ pipeline.py      # Pipeline sklearn
â”‚       â””â”€â”€ trainer.py       # Clase de entrenamiento
â”œâ”€â”€ tests/                   # Tests (fuera de src/)
â”œâ”€â”€ app/                     # APIs (fuera de src/)
â”œâ”€â”€ configs/                 # Configuraciones YAML
â”œâ”€â”€ artifacts/               # Modelos entrenados
â””â”€â”€ pyproject.toml          # ConfiguraciÃ³n de paquete
```

**ConfiguraciÃ³n en pyproject.toml:**
```toml
[build-system]
requires = ["setuptools>=61.0"]
build-backend = "setuptools.build_meta"

[project]
name = "bankchurn"
version = "0.1.0"

[tool.setuptools.packages.find]
where = ["src"]
```

**Relacionados:** pyproject.toml, Package, Import, Project Structure

---

### Staging
**DefiniciÃ³n:** Ambiente que replica producciÃ³n para testing final.

**AnalogÃ­a:** Ensayo general antes del estreno.

---

### Stratified Split
**DefiniciÃ³n:** DivisiÃ³n que mantiene proporciÃ³n de clases en train y test.

```python
train_test_split(X, y, stratify=y)
```

---

### Streamlit

**DefiniciÃ³n tÃ©cnica:** Framework Python para crear aplicaciones web interactivas con cÃ³digo puro Python. Convierte scripts de anÃ¡lisis de datos en dashboards web sin necesidad de conocimientos de HTML, CSS o JavaScript.

**ExplicaciÃ³n conceptual:** Data Scientists crean anÃ¡lisis increÃ­bles en notebooks, pero compartirlos requiere que el receptor tenga Python instalado y sepa ejecutar notebooks. Streamlit permite convertir ese anÃ¡lisis en una aplicaciÃ³n web que cualquiera puede usar: aÃ±ades decoradores como `st.title()`, `st.button()`, `st.dataframe()` y Streamlit genera una UI web automÃ¡ticamente. Es la forma mÃ¡s rÃ¡pida de pasar de "script de anÃ¡lisis" a "aplicaciÃ³n interactiva".

**AnalogÃ­a desarrollada:** Imagina que eres un chef que crea recetas increÃ­bles. Jupyter notebooks es como escribir la receta en un cuaderno tÃ©cnicoâ€”otros chefs pueden seguirla, pero no el pÃºblico general. Streamlit es como montar un food truck donde la gente puede probar tus platos sin saber cocinar. Tu cÃ³digo Python sigue siendo la "cocina", pero ahora tiene una ventana de servicio bonita.

**Ejemplo del portafolio (CarVision Dashboard):**
```python
import streamlit as st
import pandas as pd
import joblib

st.set_page_config(page_title="CarVision Predictor", page_icon="ğŸš—")
st.title("ğŸš— CarVision Price Predictor")

# Sidebar para inputs
with st.sidebar:
    st.header("Vehicle Features")
    year = st.slider("Year", 2000, 2024, 2018)
    mileage = st.number_input("Mileage", 0, 300000, 50000)
    brand = st.selectbox("Brand", ["Toyota", "Honda", "Ford"])

# Cargar modelo (con cache para no recargar)
@st.cache_resource
def load_model():
    return joblib.load("artifacts/model.joblib")

model = load_model()

# BotÃ³n de predicciÃ³n
if st.button("ğŸ”® Predict Price"):
    input_df = pd.DataFrame([{"year": year, "mileage": mileage, "brand": brand}])
    prediction = model.predict(input_df)[0]
    
    st.success(f"Estimated Price: ${prediction:,.0f}")
    
    # MÃ©tricas visuales
    col1, col2 = st.columns(2)
    col1.metric("Predicted Price", f"${prediction:,.0f}")
    col2.metric("Confidence", "High" if prediction > 10000 else "Medium")
```

**Componentes clave:**
- `st.title()`, `st.header()`: TÃ­tulos
- `st.slider()`, `st.number_input()`, `st.selectbox()`: Inputs
- `st.button()`: Acciones
- `st.dataframe()`, `st.plotly_chart()`: VisualizaciÃ³n
- `@st.cache_resource`: Cache de modelos/datos pesados

**Relacionados:** Dashboard, FastAPI, Gradio, Panel

---

## T

### Target
**DefiniciÃ³n:** Variable que queremos predecir. TambiÃ©n llamada "label" o "y".

---

### Terraform
**DefiniciÃ³n:** Infrastructure as Code. Provisiona recursos en cloud con cÃ³digo.

```hcl
resource "aws_instance" "ml_server" {
  instance_type = "t3.medium"
}
```

---

### Test Coverage
**DefiniciÃ³n:** Porcentaje de cÃ³digo ejecutado durante tests.

**Relacionados:** Coverage, pytest

---

### Threshold (Umbral)
**DefiniciÃ³n:** Punto de corte para convertir probabilidades en clases.

**Default:** 0.5, pero ajustable segÃºn necesidades de negocio.

---

### Throughput
**DefiniciÃ³n:** Cantidad de predicciones/requests por unidad de tiempo.

**AnalogÃ­a:** CuÃ¡ntos platos puede servir el restaurante por hora.

---

### Traces
**DefiniciÃ³n:** Seguimiento de requests a travÃ©s de sistema distribuido.

**Herramientas:** Jaeger, OpenTelemetry

**Relacionados:** Observabilidad, Logs, Metrics

---

### TransformerMixin
**DefiniciÃ³n:** Mixin sklearn que aÃ±ade `fit_transform()` automÃ¡ticamente.

**Relacionados:** BaseEstimator, Custom Transformer

---

### Trivy
**DefiniciÃ³n:** EscÃ¡ner de vulnerabilidades para contenedores.

```bash
trivy image my-app:latest
```

---

### Type Hints
**DefiniciÃ³n:** Anotaciones en Python que indican tipos esperados.

```python
def predict(data: pd.DataFrame) -> np.ndarray:
    pass
```

**Relacionados:** mypy, Pydantic

---

## U

### Underfitting (Subajuste)
**DefiniciÃ³n:** Modelo demasiado simple. No captura patrones.

**SeÃ±ales:** Train y validation accuracy bajas.

---

### Unit Test
**DefiniciÃ³n:** Test de funciÃ³n/mÃ©todo individual en aislamiento.

```python
def test_feature_ratio():
    result = compute_ratio(100, 2)
    assert result == 50
```

---

### Uvicorn
**DefiniciÃ³n:** Servidor ASGI de alto rendimiento para FastAPI.

```bash
uvicorn app:app --host 0.0.0.0 --port 8000
```

---

## V

### Validation Set
**DefiniciÃ³n:** Datos para ajustar hiperparÃ¡metros, separado de train y test.

**Split tÃ­pico:** 60% train, 20% validation, 20% test

---

### Vendor Lock-in
**DefiniciÃ³n:** Dependencia de proveedor especÃ­fico que dificulta migraciÃ³n.

**AnalogÃ­a:** Comprar auto donde repuestos solo existen en una tienda.

---

### Version Control
**DefiniciÃ³n:** Sistema para rastrear cambios en archivos.

**Herramientas:** Git (cÃ³digo), DVC (datos), MLflow (modelos)

---

### Voting Classifier
**DefiniciÃ³n:** Ensemble que combina predicciones por votaciÃ³n.

```python
VotingClassifier([
    ('rf', RandomForestClassifier()),
    ('xgb', XGBClassifier())
], voting='soft')
```

---

## W

### Weights & Biases (W&B)
**DefiniciÃ³n:** Plataforma SaaS para experiment tracking con visualizaciones avanzadas.

**Relacionados:** MLflow, Experiment Tracking

---

### Workflow (GitHub Actions)
**DefiniciÃ³n:** Proceso automatizado definido en archivo YAML.

**Relacionados:** Job, Step, CI/CD

---

## X

### XGBoost
**DefiniciÃ³n:** ImplementaciÃ³n optimizada de gradient boosting. Muy popular en competencias.

```python
from xgboost import XGBClassifier
model = XGBClassifier(n_estimators=100, learning_rate=0.1)
```

---

## Y

### YAML
**DefiniciÃ³n:** Formato de serializaciÃ³n legible para configuraciÃ³n.

```yaml
model:
  type: ensemble
  n_estimators: 100
```

---

## Z

### Zero-Downtime Deployment
**DefiniciÃ³n:** Actualizar aplicaciÃ³n sin interrumpir servicio.

**TÃ©cnicas:** Rolling update, Blue-green deployment

---

## SÃ­mbolos y Abreviaciones

| SÃ­mbolo | Significado |
|---------|-------------|
| TP | True Positive |
| TN | True Negative |
| FP | False Positive |
| FN | False Negative |
| P95 | Percentil 95 |
| GHCR | GitHub Container Registry |
| IaC | Infrastructure as Code |
| DAG | Directed Acyclic Graph |
| OOM | Out of Memory |
| CRUD | Create, Read, Update, Delete |
| SLA | Service Level Agreement |
| SLO | Service Level Objective |
| TTL | Time To Live |

---

## ğŸ“Š Tablas de Referencia RÃ¡pida

### MÃ©tricas de ClasificaciÃ³n

| MÃ©trica | FÃ³rmula | Uso |
|---------|---------|-----|
| Accuracy | (TP+TN)/(Total) | Balance general (clases balanceadas) |
| Precision | TP/(TP+FP) | Minimizar falsos positivos |
| Recall | TP/(TP+FN) | Minimizar falsos negativos |
| F1 | 2Ã—PÃ—R/(P+R) | Balance P y R |
| AUC-ROC | Ãrea bajo curva | Capacidad discriminatoria |

### Tipos de Testing

| Tipo | Alcance | Ejemplo |
|------|---------|---------|
| Unit | FunciÃ³n individual | `test_compute_ratio()` |
| Integration | MÃºltiples componentes | `test_pipeline_fit()` |
| E2E | Sistema completo | `test_api_predict_flow()` |

### Ambientes

| Ambiente | PropÃ³sito | Datos |
|----------|-----------|-------|
| Development | Desarrollo | SintÃ©ticos/muestra |
| Staging | Testing final | RÃ©plica producciÃ³n |
| Production | Usuarios reales | Reales |

---

<div align="center">

### NavegaciÃ³n

| â—€ï¸ Anterior | ğŸ“‘ Ãndice | â–¶ï¸ Siguiente |
|:-----------|:---------:|:------------|
| [20_PROYECTO_INTEGRADOR.md](20_PROYECTO_INTEGRADOR.md) | [Ãndice](00_INDICE.md) | [22_CHECKLIST.md](22_CHECKLIST.md) |

---

*Â© 2025 DuqueOM - GuÃ­a MLOps v5.0: Senior Edition*

**MÃ³dulo 21 Completado** âœ…

</div>
