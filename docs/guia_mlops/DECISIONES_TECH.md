# ‚öñÔ∏è Decisiones T√©cnicas ‚Äî ADRs del Portafolio

> **Por qu√© elegimos cada herramienta y tecnolog√≠a**

---

## üìã √çndice de ADRs

| # | Decisi√≥n | Alternativas | Estado |
|:--|:---------|:-------------|:-------|
| 001 | Python 3.11+ | R, Julia | ‚úÖ Aceptada |
| 002 | scikit-learn | XGBoost, LightGBM | ‚úÖ Aceptada |
| 003 | Pydantic v2 | dataclasses, attrs | ‚úÖ Aceptada |
| 004 | FastAPI | Flask, Django | ‚úÖ Aceptada |
| 005 | pytest | unittest | ‚úÖ Aceptada |
| 006 | GitHub Actions | Jenkins, GitLab CI | ‚úÖ Aceptada |
| 007 | MLflow | W&B, Neptune | ‚úÖ Aceptada |
| 008 | Docker | Conda, Poetry | ‚úÖ Aceptada |

---

## ADR-001: Python 3.11+

### Contexto
Necesitamos un lenguaje para todo el stack ML.

### Decisi√≥n
Usar Python 3.11+ como lenguaje principal.

### Alternativas Consideradas
- **R**: Mejor para estad√≠stica, peor para APIs y producci√≥n
- **Julia**: M√°s r√°pido, ecosistema menos maduro

### Consecuencias
- ‚úÖ Ecosistema ML m√°s completo
- ‚úÖ FastAPI, Pydantic nativos
- ‚úÖ Mayor pool de talento
- ‚ùå M√°s lento que lenguajes compilados

---

## ADR-002: scikit-learn para Modelos

### Contexto
Necesitamos un framework ML para clasificaci√≥n/regresi√≥n tabular.

### Decisi√≥n
Usar scikit-learn como framework principal.

### Alternativas Consideradas
- **XGBoost/LightGBM**: M√°s performance, menos integraci√≥n con pipelines
- **PyTorch**: Overkill para datos tabulares

### Consecuencias
- ‚úÖ Pipelines unificados con `Pipeline` y `ColumnTransformer`
- ‚úÖ F√°cil de testear y serializar
- ‚úÖ Documentaci√≥n excelente
- ‚ùå Menos performance que gradient boosting dedicado

---

## ADR-003: Pydantic v2 para Configuraci√≥n

### Contexto
Necesitamos validar configuraci√≥n de forma robusta.

### Decisi√≥n
Usar Pydantic v2 para todas las configuraciones.

### Alternativas Consideradas
- **dataclasses**: Sin validaci√≥n built-in
- **attrs**: Menos popular, similar funcionalidad
- **Dict/YAML directo**: Sin validaci√≥n

### Consecuencias
- ‚úÖ Validaci√≥n autom√°tica de tipos
- ‚úÖ Errores claros en config inv√°lida
- ‚úÖ Integraci√≥n perfecta con FastAPI
- ‚ùå Dependencia adicional

**Ejemplo:**
```python
class ModelConfig(BaseModel):
    n_estimators: int = Field(ge=10, le=500)
    max_depth: int | None = Field(default=None, ge=1)
```

---

## ADR-004: FastAPI para APIs

### Contexto
Necesitamos servir modelos via HTTP.

### Decisi√≥n
Usar FastAPI para todas las APIs.

### Alternativas Consideradas
- **Flask**: M√°s simple, sin async, sin docs autom√°ticas
- **Django**: Overkill para APIs ML
- **gRPC**: M√°s complejo, mejor para microservicios internos

### Consecuencias
- ‚úÖ Async por defecto
- ‚úÖ Docs OpenAPI autom√°ticas
- ‚úÖ Validaci√≥n con Pydantic integrada
- ‚úÖ Rendimiento excelente
- ‚ùå Menos tutoriales que Flask

---

## ADR-005: pytest para Testing

### Contexto
Necesitamos un framework de testing.

### Decisi√≥n
Usar pytest con pytest-cov.

### Alternativas Consideradas
- **unittest**: M√°s verboso, menos features
- **nose2**: Abandonado

### Consecuencias
- ‚úÖ Fixtures potentes
- ‚úÖ Plugins (pytest-cov, pytest-mock)
- ‚úÖ Sintaxis simple con assert
- ‚úÖ Parametrizaci√≥n f√°cil

---

## ADR-006: GitHub Actions para CI/CD

### Contexto
Necesitamos CI/CD automatizado.

### Decisi√≥n
Usar GitHub Actions.

### Alternativas Consideradas
- **Jenkins**: Self-hosted, m√°s mantenimiento
- **GitLab CI**: Requiere migrar repos
- **CircleCI**: Costo adicional

### Consecuencias
- ‚úÖ Integrado con GitHub
- ‚úÖ Gratis para repos p√∫blicos
- ‚úÖ Matrix testing f√°cil
- ‚úÖ Marketplace de actions
- ‚ùå Vendor lock-in con GitHub

---

## ADR-007: MLflow para Tracking

### Contexto
Necesitamos tracking de experimentos y registry de modelos.

### Decisi√≥n
Usar MLflow (local + server).

### Alternativas Consideradas
- **W&B (Weights & Biases)**: Mejor UI, costo para equipos
- **Neptune**: Similar a W&B
- **DVC**: M√°s para datos que experimentos

### Consecuencias
- ‚úÖ Open source, sin vendor lock-in
- ‚úÖ Model Registry integrado
- ‚úÖ Funciona local sin servidor
- ‚ùå UI menos moderna que W&B

---

## ADR-008: Docker para Empaquetado

### Contexto
Necesitamos empaquetar aplicaciones para deploy.

### Decisi√≥n
Usar Docker con multi-stage builds.

### Alternativas Consideradas
- **Conda pack**: Solo Python, sin proceso completo
- **Poetry**: Solo dependencias, no containerizaci√≥n

### Consecuencias
- ‚úÖ Reproducibilidad total
- ‚úÖ Funciona en cualquier cloud
- ‚úÖ Compose para desarrollo local
- ‚ùå Overhead de imagen

---

## üìä Matriz de Decisiones Resumen

| √Årea | Herramienta | Por qu√© |
|:-----|:------------|:--------|
| Lenguaje | Python 3.11+ | Ecosistema ML |
| ML Framework | scikit-learn | Pipelines unificados |
| Config | Pydantic v2 | Validaci√≥n + FastAPI |
| API | FastAPI | Async + docs auto |
| Testing | pytest | Fixtures + plugins |
| CI/CD | GitHub Actions | Integraci√≥n nativa |
| Tracking | MLflow | Open source + local |
| Container | Docker | Reproducibilidad |

---

<div align="center">

[‚Üê Volver al √çndice](00_INDICE.md)

</div>
