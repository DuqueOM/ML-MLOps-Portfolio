# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MÃ“DULO 05: INGENIERÃA DE DATOS Y DVC
# Versionado de Datos, DAGs y Reproducibilidad
# GuÃ­a MLOps v5.0: Senior Edition | DuqueOM | Noviembre 2025
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

<div align="center">

# ğŸ“Š MÃ“DULO 05: IngenierÃ­a de Datos y DVC

### El Arte de Versionar lo que Git No Puede

*"Si no puedo recrear tus datos, no puedo reproducir tu modelo."*

| DuraciÃ³n             | TeorÃ­a               | PrÃ¡ctica             |
| :------------------: | :------------------: | :------------------: |
| **5-6 horas**        | 30%                  | 70%                  |

</div>

---

## ğŸ¯ ADR de Inicio: Â¿CuÃ¡ndo (NO) Usar DVC?

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ADR-006: Criterios para Usar DVC                                             â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘  âœ… USA DVC SI:                                                               â•‘
â•‘  â€¢ Datos > 100MB que no caben cÃ³modamente en Git                              â•‘
â•‘  â€¢ Necesitas reproducibilidad exacta de datasets                              â•‘
â•‘  â€¢ Equipo colabora en el mismo pipeline de datos                              â•‘
â•‘  â€¢ Quieres DAGs declarativos para pipelines                                   â•‘
â•‘  â€¢ Datos son batch (no streaming)                                             â•‘
â•‘                                                                               â•‘
â•‘  âŒ NO USES DVC SI:                                                           â•‘
â•‘  â€¢ Datos < 50MB y no cambian frecuentemente â†’ Git LFS o Git directo           â•‘
â•‘  â€¢ Datos son streaming (Kafka, Kinesis) â†’ No aplica versionado batch          â•‘
â•‘  â€¢ Ya tienes Data Lake con Delta Lake/Iceberg â†’ Usar versionado nativo        â•‘
â•‘  â€¢ Solo 1 persona trabaja en el proyecto â†’ Puede ser overkill                 â•‘
â•‘  â€¢ Pipeline ya estÃ¡ en Airflow/Prefect â†’ Evitar duplicaciÃ³n                   â•‘
â•‘                                                                               â•‘
â•‘  DECISIÃ“N PARA BANKCHURN:                                                     â•‘
â•‘  Usar DVC porque: datos ~50MB con potencial de crecer, equipo colabora,       â•‘
â•‘  queremos reproducibilidad completa, y el pipeline es batch.                  â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Lo Que LograrÃ¡s en Este MÃ³dulo

1. **Entender** el problema del versionado de datos en ML
2. **Configurar** DVC con remote storage
3. **Crear** pipelines reproducibles con `dvc.yaml`
4. **DiseÃ±ar** DAGs para proyectos complejos

### ğŸ§© CÃ³mo se aplica en este portafolio

- En `BankChurn-Predictor/` ya tienes configurado DVC con:
  - `dvc.yaml` y `params.yaml` en la raÃ­z del proyecto.
  - Carpeta `data/` con datasets y `.dvc/` con metadatos de versionado.
- Desde esa carpeta puedes practicar el flujo completo de este mÃ³dulo ejecutando:
  ```bash
  cd BankChurn-Predictor
  dvc status
  dvc repro
  dvc pull
  ```
- Aplica los mismos principios a futuros proyectos del portafolio para mantener datos y
  pipelines de forma reproducible, especialmente cuando crees el proyecto integrador.

---

## 5.1 El Problema: Git No Escala para Datos

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ˜± EL INFIERNO DEL VERSIONADO DE DATOS                     â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   SIN VERSIONADO:                                                             â•‘
â•‘                                                                               â•‘
â•‘   data/                                                                       â•‘
â•‘   â”œâ”€â”€ churn.csv                   # Â¿Original o procesado?                    â•‘
â•‘   â”œâ”€â”€ churn_v2.csv                # Â¿QuÃ© cambiÃ³?                              â•‘
â•‘   â”œâ”€â”€ churn_final.csv             # Â¿Es realmente el final?                   â•‘
â•‘   â”œâ”€â”€ churn_final_v2.csv          # ğŸ˜±                                        â•‘
â•‘   â”œâ”€â”€ churn_final_FINAL.csv       # ğŸ’€                                        â•‘
â•‘   â””â”€â”€ churn_20231115_backup.csv   # ???                                       â•‘
â•‘                                                                               â•‘
â•‘   PROBLEMAS:                                                                  â•‘
â•‘   â€¢ No sÃ© quÃ© datos usÃ³ el modelo v1.2.3                                      â•‘
â•‘   â€¢ No puedo reproducir resultados de hace 2 meses                            â•‘
â•‘   â€¢ Git se rompe con archivos grandes                                         â•‘
â•‘   â€¢ ColaboraciÃ³n es imposible ("Â¿tienes el CSV actualizado?")                 â•‘
â•‘                                                                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   CON DVC:                                                                    â•‘
â•‘                                                                               â•‘
â•‘   data/                                                                       â•‘
â•‘   â””â”€â”€ raw/                                                                    â•‘
â•‘       â””â”€â”€ churn.csv.dvc     # Metadatos en Git, datos en storage              â•‘
â•‘                                                                               â•‘
â•‘   git checkout v1.2.3 && dvc checkout                                         â•‘
â•‘   â†’ Tengo EXACTAMENTE los datos de esa versiÃ³n                                â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### Comparativa de Soluciones

| SoluciÃ³n | TamaÃ±o MÃ¡x | Versionado | Pipelines | Costo | Complejidad |
| :------- | :--------: | :--------: | :-------: | :---: | :---------: |
| Git directo | ~10MB | âœ… | âŒ | Gratis | Baja |
| Git LFS | ~2GB | âœ… | âŒ | $$$ | Baja |
| **DVC** | Ilimitado | âœ… | âœ… | Storage | Media |
| Delta Lake | Ilimitado | âœ… | âŒ | Spark | Alta |
| LakeFS | Ilimitado | âœ… | âŒ | Server | Alta |

---

## 5.2 ConfiguraciÃ³n Inicial de DVC

### InstalaciÃ³n

```bash
# Con pip
pip install dvc

# Con extras para storage
pip install "dvc[s3]"      # Amazon S3
pip install "dvc[gs]"      # Google Cloud Storage
pip install "dvc[azure]"   # Azure Blob Storage
pip install "dvc[gdrive]"  # Google Drive (para proyectos personales)
```

### InicializaciÃ³n

```bash
# En un repo Git existente
cd bankchurn-predictor
dvc init

# Esto crea:
# .dvc/           - Directorio de configuraciÃ³n
# .dvc/.gitignore
# .dvc/config
# .dvcignore      - QuÃ© ignorar (como .gitignore)
```

### Configurar Remote Storage

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 1: Local (para desarrollo)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d localremote /path/to/dvc-storage
# -d = default remote

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 2: Amazon S3
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d s3remote s3://my-bucket/dvc-storage
dvc remote modify s3remote region us-east-1
# Credenciales: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY en env

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 3: Google Cloud Storage
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d gcsremote gs://my-bucket/dvc-storage
# Credenciales: GOOGLE_APPLICATION_CREDENTIALS en env

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# OPCIÃ“N 4: Google Drive (Gratis, bueno para proyectos personales)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
dvc remote add -d gdriveremote gdrive://folder-id
# La primera vez pedirÃ¡ autenticaciÃ³n OAuth

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ver configuraciÃ³n
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
cat .dvc/config
```

### Estructura de Directorios Recomendada

```
bankchurn-predictor/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                    # Datos originales (DVC tracked)
â”‚   â”‚   â”œâ”€â”€ .gitkeep
â”‚   â”‚   â””â”€â”€ churn.csv          # â†’ churn.csv.dvc en Git
â”‚   â”œâ”€â”€ processed/             # Datos procesados (output de pipeline)
â”‚   â”‚   â””â”€â”€ .gitkeep
â”‚   â””â”€â”€ external/              # Datos de terceros
â”‚       â””â”€â”€ .gitkeep
â”œâ”€â”€ models/                    # Modelos entrenados (DVC tracked)
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ .dvc/
â”‚   â””â”€â”€ config
â”œâ”€â”€ .dvcignore
â””â”€â”€ dvc.yaml                   # Pipeline definition
```

---

## 5.3 Versionado BÃ¡sico de Archivos

### AÃ±adir Datos a DVC

```bash
# AÃ±adir archivo
dvc add data/raw/churn.csv

# Esto crea:
# data/raw/churn.csv.dvc   - Metadatos (hash, size)
# data/raw/.gitignore      - Ignora el CSV en Git

# Ver contenido del .dvc
cat data/raw/churn.csv.dvc
```

```yaml
# data/raw/churn.csv.dvc
outs:
- md5: abc123def456...
  size: 52428800
  hash: md5
  path: churn.csv
```

### Flujo de Trabajo

```bash
# 1. Modificar datos
# ... (actualizar churn.csv con nuevos registros)

# 2. Actualizar tracking
dvc add data/raw/churn.csv

# 3. Commit ambos cambios
git add data/raw/churn.csv.dvc data/raw/.gitignore
git commit -m "data(raw): update churn dataset with Q4 2024 data"

# 4. Push datos a remote
dvc push

# 5. Push cÃ³digo a Git
git push
```

### Recuperar Datos de VersiÃ³n Anterior

```bash
# Ver versiones del archivo
git log data/raw/churn.csv.dvc

# Checkout versiÃ³n especÃ­fica
git checkout v1.0.0 -- data/raw/churn.csv.dvc
dvc checkout data/raw/churn.csv

# O mÃ¡s simple: checkout todo
git checkout v1.0.0
dvc checkout
# â†’ Ahora tienes cÃ³digo Y datos de v1.0.0
```

---

## 5.4 Pipelines con dvc.yaml (El Poder Real)

### Â¿Por QuÃ© Pipelines?

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                         PIPELINES DVC: REPRODUCIBILIDAD                       â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘   SIN PIPELINE:                                                               â•‘
â•‘   "Para reproducir, ejecuta preprocess.py, luego train.py, luego..."          â•‘
â•‘   "Ah, pero primero asegÃºrate de tener los datos correctos..."                â•‘
â•‘   "Y usa los mismos hiperparÃ¡metros que estÃ¡n en... algÃºn lugar..."           â•‘
â•‘                                                                               â•‘
â•‘   CON PIPELINE DVC:                                                           â•‘
â•‘   $ dvc repro                                                                 â•‘
â•‘   â†’ Ejecuta TODO automÃ¡ticamente, en orden correcto,                          â•‘
â•‘     saltando stages que no cambiaron.                                         â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

### dvc.yaml Completo para BankChurn

```yaml
# dvc.yaml
stages:
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 1: PreparaciÃ³n de Datos
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  prepare:
    cmd: python src/bankchurn/data/prepare.py
    deps:
      - src/bankchurn/data/prepare.py
      - data/raw/churn.csv
      - configs/config.yaml
    params:
      - prepare.test_size
      - prepare.random_state
    outs:
      - data/processed/train.csv
      - data/processed/test.csv

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 2: Feature Engineering
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  featurize:
    cmd: python src/bankchurn/features/build.py
    deps:
      - src/bankchurn/features/build.py
      - data/processed/train.csv
      - data/processed/test.csv
      - configs/config.yaml
    params:
      - features.numerical
      - features.categorical
    outs:
      - data/processed/train_features.pkl
      - data/processed/test_features.pkl

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 3: Entrenamiento
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  train:
    cmd: python src/bankchurn/training.py
    deps:
      - src/bankchurn/training.py
      - data/processed/train_features.pkl
      - configs/config.yaml
    params:
      - train.n_estimators
      - train.max_depth
      - train.random_state
    outs:
      - models/pipeline.pkl
    metrics:
      - metrics/train_metrics.json:
          cache: false

  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  # STAGE 4: EvaluaciÃ³n
  # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
  evaluate:
    cmd: python src/bankchurn/evaluate.py
    deps:
      - src/bankchurn/evaluate.py
      - models/pipeline.pkl
      - data/processed/test_features.pkl
    metrics:
      - metrics/eval_metrics.json:
          cache: false
    plots:
      - metrics/roc_curve.json:
          x: fpr
          y: tpr
      - metrics/confusion_matrix.json:
          template: confusion
          x: predicted
          y: actual
```

### params.yaml (ConfiguraciÃ³n del Pipeline)

```yaml
# params.yaml
prepare:
  test_size: 0.2
  random_state: 42

features:
  numerical:
    - CreditScore
    - Age
    - Tenure
    - Balance
    - NumOfProducts
    - EstimatedSalary
  categorical:
    - Geography
    - Gender

train:
  n_estimators: 100
  max_depth: 10
  random_state: 42
```

### Comandos de Pipeline

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# REPRODUCIR PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ejecutar todo el pipeline
dvc repro

# Ejecutar stage especÃ­fico (y sus dependencias)
dvc repro train

# Forzar re-ejecuciÃ³n (aunque no haya cambios)
dvc repro --force

# Ver quÃ© se ejecutarÃ­a sin ejecutar
dvc repro --dry

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VISUALIZAR PIPELINE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ver DAG en terminal
dvc dag

# Generar imagen del DAG
dvc dag --dot | dot -Tpng -o pipeline.png

# Ver dependencias de un stage
dvc dag --outs train
```

### VisualizaciÃ³n del DAG

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                              DVC DAG: BANKCHURN                               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                                               â•‘
â•‘                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â•‘
â•‘                        â”‚  data/raw/*.csv â”‚                                    â•‘
â•‘                        â”‚  configs/*.yaml â”‚                                    â•‘
â•‘                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â•‘
â•‘                                 â”‚                                             â•‘
â•‘                                 â–¼                                             â•‘
â•‘                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â•‘
â•‘                        â”‚    prepare      â”‚                                    â•‘
â•‘                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â•‘
â•‘                                 â”‚                                             â•‘
â•‘                                 â–¼                                             â•‘
â•‘                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                    â•‘
â•‘                        â”‚   featurize     â”‚                                    â•‘
â•‘                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                    â•‘
â•‘                                 â”‚                                             â•‘
â•‘                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                 â•‘
â•‘                     â–¼                       â–¼                                 â•‘
â•‘            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                         â•‘
â•‘            â”‚     train       â”‚    â”‚    (test data)  â”‚                         â•‘
â•‘            â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                         â•‘
â•‘                     â”‚                      â”‚                                  â•‘
â•‘                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                  â•‘
â•‘                                â–¼                                              â•‘
â•‘                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â•‘
â•‘                       â”‚    evaluate     â”‚                                     â•‘
â•‘                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â•‘
â•‘                                â”‚                                              â•‘
â•‘                                â–¼                                              â•‘
â•‘                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                     â•‘
â•‘                       â”‚    metrics/     â”‚                                     â•‘
â•‘                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                                     â•‘
â•‘                                                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## 5.5 MÃ©tricas y Experimentos

### Tracking de MÃ©tricas

```bash
# Ver mÃ©tricas actuales
dvc metrics show

# Comparar con otra rama/commit
dvc metrics diff HEAD~1

# Output ejemplo:
# Path                     Metric    HEAD     HEAD~1   Change
# metrics/eval_metrics.json  auc_roc   0.8721   0.8534   0.0187
# metrics/eval_metrics.json  f1        0.7234   0.7012   0.0222
```

### Experimentos con DVC

```bash
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EJECUTAR EXPERIMENTOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Experimento con cambio de parÃ¡metro
dvc exp run --set-param train.n_estimators=200

# MÃºltiples experimentos en paralelo
dvc exp run --queue --set-param train.n_estimators=100
dvc exp run --queue --set-param train.n_estimators=200
dvc exp run --queue --set-param train.n_estimators=300
dvc exp run --run-all --parallel 3

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# COMPARAR EXPERIMENTOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Ver todos los experimentos
dvc exp show

# Output:
# â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
# â”ƒ Experiment    â”ƒ auc_roc     â”ƒ f1          â”ƒ n_estimators   â”ƒ
# â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©
# â”‚ main          â”‚ 0.8721      â”‚ 0.7234      â”‚ 100            â”‚
# â”‚ exp-abc123    â”‚ 0.8856      â”‚ 0.7421      â”‚ 200            â”‚
# â”‚ exp-def456    â”‚ 0.8812      â”‚ 0.7356      â”‚ 300            â”‚
# â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# APLICAR MEJOR EXPERIMENTO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Aplicar a workspace
dvc exp apply exp-abc123

# O crear branch
dvc exp branch exp-abc123 feature/best-model
```

---

## 5.6 Patrones Avanzados

### Multi-Output Stages

```yaml
# dvc.yaml
stages:
  split:
    cmd: python src/split.py
    deps:
      - data/raw/full_dataset.csv
    outs:
      - data/processed/train.csv
      - data/processed/val.csv
      - data/processed/test.csv
```

### Stages Condicionales (foreach)

```yaml
# dvc.yaml - Entrenar mÃºltiples modelos
stages:
  train:
    foreach:
      - random_forest
      - xgboost
      - lightgbm
    do:
      cmd: python src/train.py --model ${item}
      deps:
        - src/train.py
        - data/processed/train.csv
      params:
        - train.${item}
      outs:
        - models/${item}.pkl
      metrics:
        - metrics/${item}_metrics.json:
            cache: false
```

### IntegraciÃ³n con MLflow

```python
# src/bankchurn/training.py
import mlflow
import dvc.api
import yaml

def train():
    # Obtener parÃ¡metros de DVC
    params = dvc.api.params_show()
    
    with mlflow.start_run():
        # Log parÃ¡metros
        mlflow.log_params(params["train"])
        
        # Entrenar...
        model = train_model(params["train"])
        
        # Log mÃ©tricas
        metrics = evaluate(model)
        mlflow.log_metrics(metrics)
        
        # Guardar mÃ©tricas para DVC tambiÃ©n
        with open("metrics/train_metrics.json", "w") as f:
            json.dump(metrics, f)
        
        # Log modelo
        mlflow.sklearn.log_model(model, "model")
---

## ğŸ§¨ Errores habituales y cÃ³mo depurarlos en DVC

Aunque DVC parece â€œsolo aÃ±adir un comando mÃ¡sâ€, en la prÃ¡ctica los errores suelen venir de **desalineaciÃ³n entre Git, datos y configuraciÃ³n**.

### 1) Datos no aparecen al clonar el repo (`dvc pull`/`dvc checkout` olvidados)

**SÃ­ntomas tÃ­picos**

- Clonas el repositorio, ejecutas el cÃ³digo y obtienes errores como:
  ```text
  FileNotFoundError: data/raw/churn.csv not found
  ```
- La carpeta `data/` estÃ¡ vacÃ­a o solo tiene `.gitkeep`.

**CÃ³mo identificarlo**

- Ejecuta:
  ```bash
  dvc list .
  dvc status
  ```
  para ver quÃ© outs estÃ¡n trackeados.
- Mira si existen archivos `.dvc` (`data/raw/churn.csv.dvc`) pero no los datos reales.

**CÃ³mo corregirlo**

- DespuÃ©s de clonar o cambiar de rama/tag, **siempre** ejecuta:
  ```bash
  dvc pull      # trae los datos desde el remote
  dvc checkout  # sincroniza versiones de datos con los .dvc actuales
  ```
- Documenta esto en el README del proyecto y en este mÃ³dulo como parte del flujo estÃ¡ndar.

---

### 2) `.dvc` committeados pero remote sin configurar (`dvc push` fallando)

**SÃ­ntomas tÃ­picos**

- Haces `dvc push` y ves errores tipo:
  ```text
  ERROR: failed to push data to the cloud - config file error
  ```
  o credenciales faltantes.
- CompaÃ±eros de equipo tienen los `.dvc`, pero `dvc pull` no trae nada.

**CÃ³mo identificarlo**

- Revisa `.dvc/config` para ver quÃ© remote estÃ¡ configurado (`localremote`, `s3remote`, etc.).
- Ejecuta `dvc remote list` y valida que el remote por defecto (`-d`) exista y sea accesible.

**CÃ³mo corregirlo**

- AsegÃºrate de que todos usen **el mismo nombre de remote** y que estÃ© configurado en el repo (no solo en local).
- Para remotes cloud (S3, GCS): documenta las variables de entorno necesarias (`AWS_ACCESS_KEY_ID`, etc.).
- Haz un `dvc push` de prueba y luego un `dvc pull` desde otra mÃ¡quina para validar.

---

### 3) `dvc repro` no ejecuta stages que esperas (cambios no detectados)

**SÃ­ntomas tÃ­picos**

- Modificas cÃ³digo o parÃ¡metros, ejecutas `dvc repro` y ves:
  ```text
  Stage 'train' didn't change, skipping
  ```
  aunque esperabas que volviera a entrenar.

**CÃ³mo identificarlo**

- Mira el `dvc.yaml` y verifica que:
  - El script que cambiaste estÃ© en `deps:` del stage.
  - Los parÃ¡metros que tocaste estÃ©n en `params:`.

**CÃ³mo corregirlo**

- AsegÃºrate de listar **todas las dependencias reales** en `deps:` (scripts, configs, datos intermedios).
- Si cambiaste parÃ¡metros en `params.yaml`, agrÃ©galos a la lista `params:` del stage correspondiente.
- Si quieres forzar una re-ejecuciÃ³n puntual, usa `dvc repro --force train`.

---

### 4) Conflictos entre `.gitignore` y `.dvc` (datos en Git por accidente)

**SÃ­ntomas tÃ­picos**

- Ves archivos grandes (`data/raw/*.csv`, `models/*.pkl`) en `git status`.
- Existen `.dvc` pero los datos tambiÃ©n se han aÃ±adido a Git.

**CÃ³mo identificarlo**

- Revisa `data/raw/.gitignore` generado por `dvc add` y el `.gitignore` del proyecto principal; puede que se estÃ©n pisando.

**CÃ³mo corregirlo**

- Respeta el patrÃ³n DVC:
  - Los datos **no** se aÃ±aden a Git, solo los `.dvc`.
  - AsegÃºrate de que `.gitignore` incluya las carpetas de datos/artefactos y que no contradiga los `.gitignore` generados por DVC.
- Si ya has commiteado datos grandes, elimÃ­nalos del historial (o al menos del Ãºltimo commit) y deja solo los `.dvc`.

---

### 5) DVC + CI/CD: pipelines que fallan en GitHub Actions

**SÃ­ntomas tÃ­picos**

- En CI, `dvc repro` falla porque no encuentra datos o no tiene acceso al remote.

**CÃ³mo identificarlo**

- Revisa el workflow de CI y verifica si:
  - Has instalado DVC con los extras correctos (`dvc[s3]`, etc.).
  - Has configurado variables de entorno con credenciales.
  - EstÃ¡s ejecutando `dvc pull` **antes** de correr el pipeline.

**CÃ³mo corregirlo**

- AÃ±ade pasos en tu workflow:
  ```yaml
  - name: Install DVC
    run: pip install "dvc[s3]"

  - name: Pull data with DVC
    run: dvc pull

  - name: Run pipeline
    run: dvc repro
  ```
- Usa `dvc repro --dry` localmente para ver quÃ© deberÃ­a ejecutarse antes de llevarlo a CI.

---

### PatrÃ³n general de debugging en DVC

1. **Inspecciona el estado** con `dvc status` y `dvc dag`.
2. **Verifica remotes y credenciales** (`dvc remote list`, `.dvc/config`).
3. **Comprueba deps/outs/params** en `dvc.yaml` para el stage problemÃ¡tico.
4. **Sincroniza Git + DVC**: `git checkout <tag/branch>` seguido de `dvc checkout` y `dvc pull` si hace falta.

Con este checklist, DVC pasa de ser â€œcaja negra que fallaâ€ a una herramienta controlable para reproducir datos y pipelines.

---

## 5.7 Ejercicio Integrador

### Setup Completo de DVC

```bash
# 1. Inicializar DVC
cd bankchurn-predictor
dvc init

# 2. Configurar remote (local para empezar)
mkdir -p ~/dvc-storage
dvc remote add -d localremote ~/dvc-storage

# 3. Crear estructura de datos
mkdir -p data/{raw,processed} models metrics

# 4. AÃ±adir datos raw
# (asumiendo que tienes churn.csv)
cp /path/to/churn.csv data/raw/
dvc add data/raw/churn.csv

# 5. Crear dvc.yaml (copiar del ejemplo anterior)

# 6. Crear params.yaml

# 7. Commit todo
git add .
git commit -m "data(dvc): setup DVC pipeline"

# 8. Ejecutar pipeline
dvc repro

# 9. Push a remote
dvc push
git push
```

### Checklist de VerificaciÃ³n

```
CONFIGURACIÃ“N:
[ ] DVC inicializado
[ ] Remote configurado y funcionando
[ ] Datos raw tracked con DVC

PIPELINE:
[ ] dvc.yaml con stages definidos
[ ] params.yaml con parÃ¡metros
[ ] dvc repro ejecuta sin errores

VERSIONADO:
[ ] Puedo hacer git checkout + dvc checkout a versiones anteriores
[ ] dvc push/pull funcionan correctamente
[ ] MÃ©tricas se trackean con dvc metrics show
```

---

## 5.8 AutoevaluaciÃ³n

### Preguntas de ReflexiÃ³n

1. Â¿Por quÃ© DVC usa hashes MD5 en lugar de guardar los archivos?
2. Â¿QuÃ© pasa si cambio `params.yaml` pero no el cÃ³digo?
3. Â¿CuÃ¡ndo DVC salta un stage sin ejecutarlo?
4. Â¿CÃ³mo integrarÃ­as DVC con GitHub Actions para CI?

---

## ğŸ“¦ CÃ³mo se UsÃ³ en el Portafolio

El portafolio tiene DVC configurado a nivel global:

### Estructura DVC del Portafolio

```
ML-MLOps-Portfolio/
â”œâ”€â”€ .dvc/                  # ConfiguraciÃ³n DVC
â”‚   â””â”€â”€ config             # Remote storage config
â”œâ”€â”€ .dvc-storage/          # Remote local (para demo)
â”œâ”€â”€ .dvcignore            # Archivos a ignorar
â””â”€â”€ */data/raw/*.dvc       # Archivos .dvc en cada proyecto
```

### Archivos .dvc Reales

```bash
# BankChurn-Predictor/data/raw/bank_churn.csv.dvc
md5: abc123def456...
size: 1234567
path: bank_churn.csv

# CarVision-Market-Intelligence/data/raw/car_prices.csv.dvc
md5: xyz789ghi012...
size: 2345678
path: car_prices.csv
```

### Flujo de Datos en el Portafolio

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    FLUJO DE DATOS DVC                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  data/raw/*.csv    â†’    .dvc files    â†’    .dvc-storage/     â”‚
â”‚  (gitignored)           (tracked)          (remote local)    â”‚
â”‚                                                              â”‚
â”‚  Para CI/CD:                                                 â”‚
â”‚  git clone â†’ dvc pull â†’ datos disponibles                    â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Comandos DVC del Portafolio

```bash
# Ver quÃ© datos estÃ¡n trackeados
dvc status

# Obtener datos despuÃ©s de clonar
dvc pull

# Agregar nuevos datos
dvc add data/raw/nuevos_datos.csv
git add data/raw/nuevos_datos.csv.dvc data/raw/.gitignore
git commit -m "data(dvc): add nuevos_datos"
dvc push
```

### ğŸ”§ Ejercicio: Trabaja con DVC Real

```bash
# 1. Ve a la raÃ­z del portafolio
cd ML-MLOps-Portfolio

# 2. Verifica estado de DVC
dvc status

# 3. ObtÃ©n los datos (si no los tienes)
dvc pull

# 4. Verifica que los datos existen
ls -la BankChurn-Predictor/data/raw/
ls -la CarVision-Market-Intelligence/data/raw/

# 5. Experimenta: modifica params y reproduce
cd BankChurn-Predictor
dvc repro  # Si tienes dvc.yaml configurado
```

---

## ğŸ’¼ Consejos Profesionales

> **Recomendaciones para destacar en entrevistas y proyectos reales**

### Para Entrevistas

1. **DVC vs Git LFS**: Explica que DVC es especÃ­fico para ML (pipelines, mÃ©tricas), LFS es genÃ©rico para archivos grandes.

2. **Reproducibilidad**: Menciona que puedes recrear cualquier experimento con `dvc checkout` + `git checkout`.

3. **Data Lineage**: Explica cÃ³mo DVC trackea la procedencia de datos transformados.

### Para Proyectos Reales

| SituaciÃ³n | Consejo |
|-----------|---------|
| Datos sensibles | Usa DVC con storage encriptado (S3 + KMS) |
| Datasets grandes | Usa `dvc push/pull` selectivo por carpeta |
| CI/CD | Cachea datos en CI para evitar descargas repetidas |
| ColaboraciÃ³n | Documenta dÃ³nde estÃ¡ el remote storage |

### Flujo Profesional de Datos

1. Raw data â†’ nunca modificar, solo agregar
2. Processed data â†’ versionado con DVC
3. Features â†’ cacheados para reutilizaciÃ³n
4. Modelos â†’ versionados con mÃ©tricas


---

## ğŸ“º Recursos Externos Recomendados

> Ver [RECURSOS_POR_MODULO.md](RECURSOS_POR_MODULO.md) para la lista completa.

| ğŸ·ï¸ | Recurso | Tipo |
|:--:|:--------|:-----|
| ğŸ”´ | [DVC Tutorial - DataTalks](https://www.youtube.com/watch?v=kLKBcPonMYw) | Video |
| ğŸŸ¡ | [DVC Documentation](https://dvc.org/doc) | Docs |

---

## ğŸ”— Referencias del Glosario

Ver [21_GLOSARIO.md](21_GLOSARIO.md) para definiciones de:
- **DVC**: Data Version Control
- **Remote Storage**: Almacenamiento externo para datos
- **dvc.yaml**: DefiniciÃ³n de pipelines reproducibles

---

## âœ… Ejercicios

Ver [EJERCICIOS.md](EJERCICIOS.md) - MÃ³dulo 06:
- **6.1**: Configurar DVC en proyecto
- **6.2**: Push/pull de datos

---

## ğŸ¤ Checkpoint: Simulacro Junior

> ğŸ¯ **Â¡Has completado los fundamentos!** (MÃ³dulos 01-06)
> 
> Si buscas posiciones **Junior ML Engineer**, ahora es buen momento para practicar:
> 
> **[â†’ SIMULACRO_ENTREVISTA_JUNIOR.md](SIMULACRO_ENTREVISTA_JUNIOR.md)**
> - 50 preguntas de Python, ML bÃ¡sico, Git y estructura
> - Enfoque en fundamentos y capacidad de aprendizaje

---

## ğŸ”œ Siguiente Paso

Con datos versionados, es hora de construir **pipelines de sklearn avanzados**.

**[Ir a MÃ³dulo 07: sklearn Pipelines â†’](07_SKLEARN_PIPELINES.md)**

---

<div align="center">

[â† Git Profesional](05_GIT_PROFESIONAL.md) | [Siguiente: sklearn Pipelines â†’](07_SKLEARN_PIPELINES.md)

</div>
