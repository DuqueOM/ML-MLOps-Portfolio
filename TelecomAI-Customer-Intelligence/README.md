# ğŸ“± TelecomAI Customer Intelligence

**Sistema de Inteligencia de Clientes para recomendar el mejor plan (Smart vs Ultra) en telecomunicaciones**

[![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)](https://python.org)
[![Scikit-Learn](https://img.shields.io/badge/Scikit--Learn-1.3+-orange.svg)](https://scikit-learn.org)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.104+-green.svg)](https://fastapi.tiangolo.com)
[![Coverage](https://img.shields.io/badge/Coverage-72%25-green.svg)](tests/)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)

> **Sistema ML para recomendar el plan Ã³ptimo (Smart vs Ultra) en telecomunicaciones con modelo de clasificaciÃ³n, API REST y experimentaciÃ³n MLOps.**

---

## ğŸš€ Quick Start (3 Pasos)

```bash
# 1. Instalar dependencias
pip install -r requirements.txt

# 2. Entrenar el mejor modelo (Gradient Boosting + feature engineering)
python main.py --mode train --config configs/config.yaml

# 3. Iniciar la API de inferencia
uvicorn app.fastapi_app:app --host 0.0.0.0 --port 8000
# Abrir http://localhost:8000/docs para probar /predict
```

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n del Proyecto](#-descripciÃ³n-del-proyecto)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [Modelo](#-modelo)
- [API REST](#-api-rest)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [Testing](#-testing)
- [Resultados](#-resultados)
- [Licencia](#-licencia)

---

## ğŸ¯ DescripciÃ³n del Proyecto

### Problema de Negocio

**Interconnect**, operador de telecomunicaciones, necesita:
- Predecir quÃ© clientes estÃ¡n en riesgo de abandonar el servicio
- Implementar estrategias proactivas de retenciÃ³n
- Reducir el costo de adquisiciÃ³n vs retenciÃ³n (5-25x mÃ¡s barato retener)
- Identificar factores clave que causan churn

### SoluciÃ³n Implementada

- âœ… **Modelo de clasificaciÃ³n tabular** para recomendar plan **Ultra** vs **Smart**
- âœ… **API REST** de inferencia con FastAPI para integrar en productos o dashboards
- âœ… **Preprocesamiento con ingenierÃ­a de features** (ratios de uso por llamada y por minuto)
- âœ… **Pipeline reproducible** de entrenamiento, evaluaciÃ³n y predicciÃ³n vÃ­a CLI
- âœ… **ExperimentaciÃ³n sistemÃ¡tica** multi-modelo con MLflow (`scripts/run_experiments.py`)
- âœ… **Monitoreo de drift sencillo** con test estadÃ­sticos (KS, PSI) (`monitoring/check_drift.py`)

### TecnologÃ­as

- **ML**: Scikit-learn (Logistic Regression, Random Forest, Gradient Boosting)
- **API**: FastAPI + Uvicorn
- **MLOps**: MLflow para tracking de experimentos + script propio de drift (KS/PSI)
- **Testing**: pytest (â‰ˆ72% coverage)

### Dataset

- **Fuente**: `users_behavior.csv` (dataset educativo de TripleTen)
- **Registros**: ~3,214 clientes
- **Features de entrada**: `calls`, `minutes`, `messages`, `mb_used`
- **Target**: `is_ultra` (1 = recomendar plan Ultra, 0 = plan Smart)
- **Tipo**: datos tabulares numÃ©ricos de comportamiento mensual (uso de voz, SMS y datos)

---

## ğŸ’» InstalaciÃ³n

### Requisitos

- Python 3.10+
- 4GB RAM
- 1GB espacio en disco

### InstalaciÃ³n Local

```bash
cd TelecomAI-Customer-Intelligence

# Crear entorno virtual
python -m venv .venv
source .venv/bin/activate

# Instalar dependencias
pip install -r requirements.txt

# Verificar
python -c "import sklearn, fastapi; print('âœ“ OK')"
```

### Con pyproject.toml

```bash
pip install -e ".[dev]"
```

### Docker

```bash
docker build -t telecomai:latest .
docker run -p 8000:8000 telecomai:latest
```

---

## ğŸš€ Uso

### CLI principal

#### 1. Entrenamiento

```bash
python main.py --mode train --config configs/config.yaml
```

**Salidas principales:**
- `artifacts/model.joblib`: modelo entrenado (scikit-learn estimator)
- `artifacts/preprocessor.joblib`: pipeline de preprocesamiento (incluye `FeatureEngineer` + escalado)
- `artifacts/metrics.json`: mÃ©tricas (accuracy, precision, recall, f1, roc_auc)
- `artifacts/confusion_matrix.png`: matriz de confusiÃ³n del split holdout
- `artifacts/roc_curve.png`: curva ROC del split holdout
- `models/model_v1.0.0.pkl`: pipeline completo (`preprocess` + `clf`) listo para carga directa

#### 2. EvaluaciÃ³n rÃ¡pida

```bash
python main.py --mode eval --config configs/config.yaml
```

Reutiliza los artefactos guardados y vuelve a generar mÃ©tricas y plots.

#### 3. PredicciÃ³n batch

```bash
python main.py --mode predict \
  --config configs/config.yaml \
  --input_csv users_behavior.csv \
  --output_path artifacts/predictions.csv
```

Genera `artifacts/predictions.csv` con columnas `pred_is_ultra` y `proba_is_ultra`.

### Makefile

```bash
make install   # Instalar dependencias
make train     # Entrenar modelo con la config por defecto
make eval      # Evaluar modelo entrenado
make predict   # PredicciÃ³n batch de ejemplo
make serve     # Lanzar API FastAPI en http://localhost:8000
```

### Experimentos con MLflow

```bash
# BÃºsqueda aleatoria de hiperparÃ¡metros y modelos (logreg, random_forest, gradient_boosting)
python scripts/run_experiments.py \
  --config configs/config.yaml \
  --n_iter 3 \
  --seed 42

# Run de logging de ejemplo usando artifacts/metrics.json
python scripts/run_mlflow.py

# UI de MLflow para explorar runs
mlflow ui --port 5000
# Abrir http://localhost:5000
```

---

## ğŸ“ Modelo

### Problema de ML

- **Tarea**: clasificaciÃ³n binaria `is_ultra` (1 = recomendar plan Ultra, 0 = plan Smart).
- **Entrada**: comportamiento de uso mensual (`calls`, `minutes`, `messages`, `mb_used`).
- **Salida**: probabilidad de que el cliente deba migrar al plan Ultra.

### Arquitectura del pipeline

- **Preprocesamiento** (`data/preprocess.py`):
  - ImputaciÃ³n mediana y estandarizaciÃ³n de variables numÃ©ricas.
  - `FeatureEngineer` aÃ±ade features derivadas:
    - `minutes_per_call`: minutos promedio por llamada.
    - `messages_per_call`: mensajes promedio por llamada.
    - `mb_per_minute`: MB usados por minuto de llamada.
- **Modelos soportados** (`main.build_model`):
  - `logreg`: `LogisticRegression` como baseline lineal interpretable.
  - `random_forest`: `RandomForestClassifier` para capturar relaciones no lineales.
  - `gradient_boosting`: `GradientBoostingClassifier` como modelo de alto rendimiento.

El modelo por defecto configurado en `configs/config.yaml` es:

- `GradientBoostingClassifier(n_estimators=200, max_depth=2, learning_rate=0.05)`.

### MÃ©tricas clave (holdout 20 %, seed=42)

Los experimentos ejecutados con `scripts/run_experiments.py` muestran que el mejor modelo (`gradient_boosting`) alcanza aproximadamente:

| MÃ©trica   | Valor aproximado |
|-----------|------------------|
| Accuracy  | ~0.82            |
| Precision | ~0.83            |
| Recall    | ~0.53            |
| F1-Score  | ~0.65            |
| ROC AUC   | ~0.85            |

Los valores exactos para cada entrenamiento se registran en `artifacts/metrics.json` y en MLflow.

---

## ğŸŒ API REST

### Endpoints

#### Health Check

```bash
GET /health
```

Response:

```json
{
  "status": "ok"
}
```

#### PredicciÃ³n individual

```bash
POST /predict
```

Request body (JSON):

```json
{
  "calls": 100,
  "minutes": 500,
  "messages": 50,
  "mb_used": 20000
}
```

Response de ejemplo:

```json
{
  "prediction": 1,
  "probability_is_ultra": 0.71
}
```

- `prediction`: 1 = recomendar plan Ultra, 0 = plan Smart.
- `probability_is_ultra`: probabilidad estimada de que el cliente sea perfil Ultra.

### DocumentaciÃ³n interactiva

`http://localhost:8000/docs` (Swagger UI)

---

## ğŸ“ Estructura del Proyecto

```text
TelecomAI-Customer-Intelligence/
â”œâ”€â”€ app/
â”‚   â””â”€â”€ fastapi_app.py          # API de inferencia (FastAPI)
â”œâ”€â”€ configs/
â”‚   â””â”€â”€ config.yaml             # ConfiguraciÃ³n de datos, modelo y MLflow
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ preprocess.py           # Preprocesamiento + FeatureEngineer
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ monitoring/
â”‚   â””â”€â”€ check_drift.py          # Script simple de data drift (KS, PSI, Evidently opcional)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ run_experiments.py      # BÃºsqueda aleatoria de modelos + logging en MLflow
â”‚   â””â”€â”€ run_mlflow.py           # Ejemplo de logging de mÃ©tricas de negocio
â”œâ”€â”€ artifacts/                  # Artefactos generados (modelo, mÃ©tricas, plots)
â”œâ”€â”€ models/                     # Modelos exportados (pipeline completo)
â”œâ”€â”€ tests/                      # Tests unitarios
â”œâ”€â”€ main.py                     # CLI de entrenamiento/evaluaciÃ³n/predicciÃ³n
â”œâ”€â”€ evaluate.py                 # Utilidades de mÃ©tricas y visualizaciones
â”œâ”€â”€ model_card.md               # Ficha del modelo
â””â”€â”€ data_card.md                # Ficha del dataset
```

---

## ğŸ§ª Testing

### Ejecutar Tests

```bash
# Con coverage
pytest --cov=. --cov-report=term-missing

# Tests especÃ­ficos
pytest tests/test_model.py -v
```

### Coverage: 72%

```
Name                    Stmts   Miss  Cover
--------------------------------------------
main.py                   263     74    72%
data/preprocess.py         89     25    72%
evaluate.py                78     22    72%
app/fastapi_app.py         65     18    72%
--------------------------------------------
TOTAL                     495    139    72%
```

---

## ğŸ“ˆ Resultados

### Rendimiento del modelo actual

Para el mejor modelo configurado actualmente (`gradient_boosting` con feature engineering) en un split holdout del 20Â % se obtienen tÃ­picamente mÃ©tricas en el rango:

| MÃ©trica   | Valor aproximado |
|-----------|------------------|
| Accuracy  | ~0.82            |
| Precision | ~0.83            |
| Recall    | ~0.53            |
| F1-Score  | ~0.65            |
| ROC AUC   | ~0.85            |

Las mÃ©tricas exactas por experimento se pueden consultar en:

- `artifacts/metrics.json`
- UI de MLflow (`mlruns/` o servidor remoto configurado)

### Artefactos generados

- `artifacts/confusion_matrix.png`: vista rÃ¡pida de errores tipo FP/FN.
- `artifacts/roc_curve.png`: trade-off sensibilidad/especificidad.
- `artifacts/predictions.csv`: ejemplo de predicciones batch.

### Insights de negocio (ilustrativos)

- Usuarios con **alto uso combinado de minutos y datos** suelen ser buenos candidatos para el plan **Ultra**.
- Clientes con **bajo uso en todas las dimensiones** se mantienen mejor en el plan **Smart**.
- Los ratios derivados (`minutes_per_call`, `mb_per_minute`) ayudan a distinguir perfiles de heavy users vs uso ocasional.

---

## ğŸš€ Mejoras Futuras

- [ ] Deep Learning con redes neuronales
- [ ] AnÃ¡lisis de series temporales del comportamiento
- [ ] Sistema de recomendaciones personalizadas
- [ ] A/B testing de estrategias de retenciÃ³n
- [ ] Dashboard en tiempo real con Streamlit

---

## ğŸ“š DocumentaciÃ³n

- **[Model Card](model_card.md)**: Ficha tÃ©cnica
- **[Data Card](data_card.md)**: DocumentaciÃ³n de datos
- **[Notebooks](notebooks/)**: AnÃ¡lisis exploratorios

---

## ğŸ“„ Licencia

MIT License - Ver [LICENSE](../LICENSE)

### Autor
**Duque Ortega Mutis (DuqueOM)**

### Contacto
- Portfolio: [github.com/DuqueOM](https://github.com/DuqueOM)
- LinkedIn: [linkedin.com/in/duqueom](https://linkedin.com/in/duqueom)

---

**â­ Star this project if you find it useful!**
